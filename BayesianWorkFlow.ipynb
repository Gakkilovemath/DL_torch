{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo for the Bayesian statistics workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "R version 3.6.1 (2019-07-05)\n",
       "Platform: x86_64-w64-mingw32/x64 (64-bit)\n",
       "Running under: Windows 10 x64 (build 18362)\n",
       "\n",
       "Matrix products: default\n",
       "\n",
       "locale:\n",
       "[1] LC_COLLATE=English_United States.1252 \n",
       "[2] LC_CTYPE=English_United States.1252   \n",
       "[3] LC_MONETARY=English_United States.1252\n",
       "[4] LC_NUMERIC=C                          \n",
       "[5] LC_TIME=English_United States.1252    \n",
       "\n",
       "attached base packages:\n",
       "[1] stats     graphics  grDevices utils     datasets  methods   base     \n",
       "\n",
       "other attached packages:\n",
       "[1] jsonlite_1.6\n",
       "\n",
       "loaded via a namespace (and not attached):\n",
       " [1] compiler_3.6.1  IRdisplay_0.7.0 pbdZMQ_0.3-3    tools_3.6.1    \n",
       " [5] htmltools_0.3.6 base64enc_0.1-3 crayon_1.3.4    Rcpp_1.0.1     \n",
       " [9] uuid_0.1-2      IRkernel_0.8.15 digest_0.6.18   repr_0.19.2    \n",
       "[13] evaluate_0.13  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# check the model performance\n",
    "sessionInfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in library(brms): there is no package called 'brms'\n",
     "output_type": "error",
     "traceback": [
      "Error in library(brms): there is no package called 'brms'\nTraceback:\n",
      "1. library(brms)"
     ]
    }
   ],
   "source": [
    "# load the library needed\n",
    "library(tidyverse)\n",
    "library(brms)\n",
    "library(tidybayes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fit the model with binomial trails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "globe_qa_brms <-\n",
    "  brm(data = list(w = 24), \n",
    "      family = binomial(link = \"identity\"),\n",
    "      w | trials(36) ~ 1,\n",
    "      prior(beta(1, 1), class = Intercept),\n",
    "      iter = 4000, warmup = 1000,\n",
    "      control = list(adapt_delta = .9),\n",
    "      seed = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in print(globe_qa_brms): object 'globe_qa_brms' not found\n",
     "output_type": "error",
     "traceback": [
      "Error in print(globe_qa_brms): object 'globe_qa_brms' not found\nTraceback:\n",
      "1. print(globe_qa_brms)"
     ]
    }
   ],
   "source": [
    "# print the model\n",
    "print(globe_qa_brms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the posterior samples for parameters\n",
    "posterior_samples(globe_qa_brms) %>% \n",
    "  mutate(n = \"n = 36\") %>%\n",
    "\n",
    "  ggplot(aes(x = b_Intercept)) +\n",
    "  geom_density(fill = \"black\") +\n",
    "  labs(x = \"proportion water\") +\n",
    "  xlim(0, 1) +\n",
    "  theme(panel.grid = element_blank()) +\n",
    "  facet_wrap(~n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>p_grid</th><th scope=col>prior</th><th scope=col>likelihood</th><th scope=col>posterior</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>0.000       </td><td>1           </td><td>0.000000e+00</td><td>0.000000e+00</td></tr>\n",
       "\t<tr><td>0.001       </td><td>1           </td><td>8.374825e-17</td><td>8.374825e-19</td></tr>\n",
       "\t<tr><td>0.002       </td><td>1           </td><td>5.343808e-15</td><td>5.343808e-17</td></tr>\n",
       "\t<tr><td>0.003       </td><td>1           </td><td>6.068653e-14</td><td>6.068653e-16</td></tr>\n",
       "\t<tr><td>0.004       </td><td>1           </td><td>3.399517e-13</td><td>3.399517e-15</td></tr>\n",
       "\t<tr><td>0.005       </td><td>1           </td><td>1.292911e-12</td><td>1.292911e-14</td></tr>\n",
       "\t<tr><td>0.006       </td><td>1           </td><td>3.848983e-12</td><td>3.848983e-14</td></tr>\n",
       "\t<tr><td>0.007       </td><td>1           </td><td>9.676433e-12</td><td>9.676433e-14</td></tr>\n",
       "\t<tr><td>0.008       </td><td>1           </td><td>2.149583e-11</td><td>2.149583e-13</td></tr>\n",
       "\t<tr><td>0.009       </td><td>1           </td><td>4.344655e-11</td><td>4.344655e-13</td></tr>\n",
       "\t<tr><td>0.010       </td><td>1           </td><td>8.150512e-11</td><td>8.150512e-13</td></tr>\n",
       "\t<tr><td>0.011       </td><td>1           </td><td>1.439542e-10</td><td>1.439542e-12</td></tr>\n",
       "\t<tr><td>0.012       </td><td>1           </td><td>2.419010e-10</td><td>2.419010e-12</td></tr>\n",
       "\t<tr><td>0.013       </td><td>1           </td><td>3.898440e-10</td><td>3.898440e-12</td></tr>\n",
       "\t<tr><td>0.014       </td><td>1           </td><td>6.062870e-10</td><td>6.062870e-12</td></tr>\n",
       "\t<tr><td>0.015       </td><td>1           </td><td>9.143986e-10</td><td>9.143986e-12</td></tr>\n",
       "\t<tr><td>0.016       </td><td>1           </td><td>1.342717e-09</td><td>1.342717e-11</td></tr>\n",
       "\t<tr><td>0.017       </td><td>1           </td><td>1.925898e-09</td><td>1.925898e-11</td></tr>\n",
       "\t<tr><td>0.018       </td><td>1           </td><td>2.705508e-09</td><td>2.705508e-11</td></tr>\n",
       "\t<tr><td>0.019       </td><td>1           </td><td>3.730851e-09</td><td>3.730851e-11</td></tr>\n",
       "\t<tr><td>0.020       </td><td>1           </td><td>5.059848e-09</td><td>5.059848e-11</td></tr>\n",
       "\t<tr><td>0.021       </td><td>1           </td><td>6.759944e-09</td><td>6.759944e-11</td></tr>\n",
       "\t<tr><td>0.022       </td><td>1           </td><td>8.909061e-09</td><td>8.909061e-11</td></tr>\n",
       "\t<tr><td>0.023       </td><td>1           </td><td>1.159658e-08</td><td>1.159658e-10</td></tr>\n",
       "\t<tr><td>0.024       </td><td>1           </td><td>1.492438e-08</td><td>1.492438e-10</td></tr>\n",
       "\t<tr><td>0.025       </td><td>1           </td><td>1.900786e-08</td><td>1.900786e-10</td></tr>\n",
       "\t<tr><td>0.026       </td><td>1           </td><td>2.397708e-08</td><td>2.397708e-10</td></tr>\n",
       "\t<tr><td>0.027       </td><td>1           </td><td>2.997784e-08</td><td>2.997784e-10</td></tr>\n",
       "\t<tr><td>0.028       </td><td>1           </td><td>3.717289e-08</td><td>3.717289e-10</td></tr>\n",
       "\t<tr><td>0.029       </td><td>1           </td><td>4.574303e-08</td><td>4.574303e-10</td></tr>\n",
       "\t<tr><td>...</td><td>...</td><td>...</td><td>...</td></tr>\n",
       "\t<tr><td>0.971       </td><td>1           </td><td>1.717073e-03</td><td>1.717073e-05</td></tr>\n",
       "\t<tr><td>0.972       </td><td>1           </td><td>1.555074e-03</td><td>1.555074e-05</td></tr>\n",
       "\t<tr><td>0.973       </td><td>1           </td><td>1.402968e-03</td><td>1.402968e-05</td></tr>\n",
       "\t<tr><td>0.974       </td><td>1           </td><td>1.260530e-03</td><td>1.260530e-05</td></tr>\n",
       "\t<tr><td>0.975       </td><td>1           </td><td>1.127527e-03</td><td>1.127527e-05</td></tr>\n",
       "\t<tr><td>0.976       </td><td>1           </td><td>1.003718e-03</td><td>1.003718e-05</td></tr>\n",
       "\t<tr><td>0.977       </td><td>1           </td><td>8.888535e-04</td><td>8.888535e-06</td></tr>\n",
       "\t<tr><td>0.978       </td><td>1           </td><td>7.826732e-04</td><td>7.826732e-06</td></tr>\n",
       "\t<tr><td>0.979       </td><td>1           </td><td>6.849097e-04</td><td>6.849097e-06</td></tr>\n",
       "\t<tr><td>0.980       </td><td>1           </td><td>5.952861e-04</td><td>5.952861e-06</td></tr>\n",
       "\t<tr><td>0.981       </td><td>1           </td><td>5.135162e-04</td><td>5.135162e-06</td></tr>\n",
       "\t<tr><td>0.982       </td><td>1           </td><td>4.393046e-04</td><td>4.393046e-06</td></tr>\n",
       "\t<tr><td>0.983       </td><td>1           </td><td>3.723464e-04</td><td>3.723464e-06</td></tr>\n",
       "\t<tr><td>0.984       </td><td>1           </td><td>3.123272e-04</td><td>3.123272e-06</td></tr>\n",
       "\t<tr><td>0.985       </td><td>1           </td><td>2.589229e-04</td><td>2.589229e-06</td></tr>\n",
       "\t<tr><td>0.986       </td><td>1           </td><td>2.117995e-04</td><td>2.117995e-06</td></tr>\n",
       "\t<tr><td>0.987       </td><td>1           </td><td>1.706131e-04</td><td>1.706131e-06</td></tr>\n",
       "\t<tr><td>0.988       </td><td>1           </td><td>1.350096e-04</td><td>1.350096e-06</td></tr>\n",
       "\t<tr><td>0.989       </td><td>1           </td><td>1.046249e-04</td><td>1.046249e-06</td></tr>\n",
       "\t<tr><td>0.990       </td><td>1           </td><td>7.908433e-05</td><td>7.908433e-07</td></tr>\n",
       "\t<tr><td>0.991       </td><td>1           </td><td>5.800277e-05</td><td>5.800277e-07</td></tr>\n",
       "\t<tr><td>0.992       </td><td>1           </td><td>4.098447e-05</td><td>4.098447e-07</td></tr>\n",
       "\t<tr><td>0.993       </td><td>1           </td><td>2.762288e-05</td><td>2.762288e-07</td></tr>\n",
       "\t<tr><td>0.994       </td><td>1           </td><td>1.750054e-05</td><td>1.750054e-07</td></tr>\n",
       "\t<tr><td>0.995       </td><td>1           </td><td>1.018891e-05</td><td>1.018891e-07</td></tr>\n",
       "\t<tr><td>0.996       </td><td>1           </td><td>5.248259e-06</td><td>5.248259e-08</td></tr>\n",
       "\t<tr><td>0.997       </td><td>1           </td><td>2.227481e-06</td><td>2.227481e-08</td></tr>\n",
       "\t<tr><td>0.998       </td><td>1           </td><td>6.639762e-07</td><td>6.639762e-09</td></tr>\n",
       "\t<tr><td>0.999       </td><td>1           </td><td>8.349726e-08</td><td>8.349726e-10</td></tr>\n",
       "\t<tr><td>1.000       </td><td>1           </td><td>0.000000e+00</td><td>0.000000e+00</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|llll}\n",
       " p\\_grid & prior & likelihood & posterior\\\\\n",
       "\\hline\n",
       "\t 0.000        & 1            & 0.000000e+00 & 0.000000e+00\\\\\n",
       "\t 0.001        & 1            & 8.374825e-17 & 8.374825e-19\\\\\n",
       "\t 0.002        & 1            & 5.343808e-15 & 5.343808e-17\\\\\n",
       "\t 0.003        & 1            & 6.068653e-14 & 6.068653e-16\\\\\n",
       "\t 0.004        & 1            & 3.399517e-13 & 3.399517e-15\\\\\n",
       "\t 0.005        & 1            & 1.292911e-12 & 1.292911e-14\\\\\n",
       "\t 0.006        & 1            & 3.848983e-12 & 3.848983e-14\\\\\n",
       "\t 0.007        & 1            & 9.676433e-12 & 9.676433e-14\\\\\n",
       "\t 0.008        & 1            & 2.149583e-11 & 2.149583e-13\\\\\n",
       "\t 0.009        & 1            & 4.344655e-11 & 4.344655e-13\\\\\n",
       "\t 0.010        & 1            & 8.150512e-11 & 8.150512e-13\\\\\n",
       "\t 0.011        & 1            & 1.439542e-10 & 1.439542e-12\\\\\n",
       "\t 0.012        & 1            & 2.419010e-10 & 2.419010e-12\\\\\n",
       "\t 0.013        & 1            & 3.898440e-10 & 3.898440e-12\\\\\n",
       "\t 0.014        & 1            & 6.062870e-10 & 6.062870e-12\\\\\n",
       "\t 0.015        & 1            & 9.143986e-10 & 9.143986e-12\\\\\n",
       "\t 0.016        & 1            & 1.342717e-09 & 1.342717e-11\\\\\n",
       "\t 0.017        & 1            & 1.925898e-09 & 1.925898e-11\\\\\n",
       "\t 0.018        & 1            & 2.705508e-09 & 2.705508e-11\\\\\n",
       "\t 0.019        & 1            & 3.730851e-09 & 3.730851e-11\\\\\n",
       "\t 0.020        & 1            & 5.059848e-09 & 5.059848e-11\\\\\n",
       "\t 0.021        & 1            & 6.759944e-09 & 6.759944e-11\\\\\n",
       "\t 0.022        & 1            & 8.909061e-09 & 8.909061e-11\\\\\n",
       "\t 0.023        & 1            & 1.159658e-08 & 1.159658e-10\\\\\n",
       "\t 0.024        & 1            & 1.492438e-08 & 1.492438e-10\\\\\n",
       "\t 0.025        & 1            & 1.900786e-08 & 1.900786e-10\\\\\n",
       "\t 0.026        & 1            & 2.397708e-08 & 2.397708e-10\\\\\n",
       "\t 0.027        & 1            & 2.997784e-08 & 2.997784e-10\\\\\n",
       "\t 0.028        & 1            & 3.717289e-08 & 3.717289e-10\\\\\n",
       "\t 0.029        & 1            & 4.574303e-08 & 4.574303e-10\\\\\n",
       "\t ... & ... & ... & ...\\\\\n",
       "\t 0.971        & 1            & 1.717073e-03 & 1.717073e-05\\\\\n",
       "\t 0.972        & 1            & 1.555074e-03 & 1.555074e-05\\\\\n",
       "\t 0.973        & 1            & 1.402968e-03 & 1.402968e-05\\\\\n",
       "\t 0.974        & 1            & 1.260530e-03 & 1.260530e-05\\\\\n",
       "\t 0.975        & 1            & 1.127527e-03 & 1.127527e-05\\\\\n",
       "\t 0.976        & 1            & 1.003718e-03 & 1.003718e-05\\\\\n",
       "\t 0.977        & 1            & 8.888535e-04 & 8.888535e-06\\\\\n",
       "\t 0.978        & 1            & 7.826732e-04 & 7.826732e-06\\\\\n",
       "\t 0.979        & 1            & 6.849097e-04 & 6.849097e-06\\\\\n",
       "\t 0.980        & 1            & 5.952861e-04 & 5.952861e-06\\\\\n",
       "\t 0.981        & 1            & 5.135162e-04 & 5.135162e-06\\\\\n",
       "\t 0.982        & 1            & 4.393046e-04 & 4.393046e-06\\\\\n",
       "\t 0.983        & 1            & 3.723464e-04 & 3.723464e-06\\\\\n",
       "\t 0.984        & 1            & 3.123272e-04 & 3.123272e-06\\\\\n",
       "\t 0.985        & 1            & 2.589229e-04 & 2.589229e-06\\\\\n",
       "\t 0.986        & 1            & 2.117995e-04 & 2.117995e-06\\\\\n",
       "\t 0.987        & 1            & 1.706131e-04 & 1.706131e-06\\\\\n",
       "\t 0.988        & 1            & 1.350096e-04 & 1.350096e-06\\\\\n",
       "\t 0.989        & 1            & 1.046249e-04 & 1.046249e-06\\\\\n",
       "\t 0.990        & 1            & 7.908433e-05 & 7.908433e-07\\\\\n",
       "\t 0.991        & 1            & 5.800277e-05 & 5.800277e-07\\\\\n",
       "\t 0.992        & 1            & 4.098447e-05 & 4.098447e-07\\\\\n",
       "\t 0.993        & 1            & 2.762288e-05 & 2.762288e-07\\\\\n",
       "\t 0.994        & 1            & 1.750054e-05 & 1.750054e-07\\\\\n",
       "\t 0.995        & 1            & 1.018891e-05 & 1.018891e-07\\\\\n",
       "\t 0.996        & 1            & 5.248259e-06 & 5.248259e-08\\\\\n",
       "\t 0.997        & 1            & 2.227481e-06 & 2.227481e-08\\\\\n",
       "\t 0.998        & 1            & 6.639762e-07 & 6.639762e-09\\\\\n",
       "\t 0.999        & 1            & 8.349726e-08 & 8.349726e-10\\\\\n",
       "\t 1.000        & 1            & 0.000000e+00 & 0.000000e+00\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| p_grid | prior | likelihood | posterior |\n",
       "|---|---|---|---|\n",
       "| 0.000        | 1            | 0.000000e+00 | 0.000000e+00 |\n",
       "| 0.001        | 1            | 8.374825e-17 | 8.374825e-19 |\n",
       "| 0.002        | 1            | 5.343808e-15 | 5.343808e-17 |\n",
       "| 0.003        | 1            | 6.068653e-14 | 6.068653e-16 |\n",
       "| 0.004        | 1            | 3.399517e-13 | 3.399517e-15 |\n",
       "| 0.005        | 1            | 1.292911e-12 | 1.292911e-14 |\n",
       "| 0.006        | 1            | 3.848983e-12 | 3.848983e-14 |\n",
       "| 0.007        | 1            | 9.676433e-12 | 9.676433e-14 |\n",
       "| 0.008        | 1            | 2.149583e-11 | 2.149583e-13 |\n",
       "| 0.009        | 1            | 4.344655e-11 | 4.344655e-13 |\n",
       "| 0.010        | 1            | 8.150512e-11 | 8.150512e-13 |\n",
       "| 0.011        | 1            | 1.439542e-10 | 1.439542e-12 |\n",
       "| 0.012        | 1            | 2.419010e-10 | 2.419010e-12 |\n",
       "| 0.013        | 1            | 3.898440e-10 | 3.898440e-12 |\n",
       "| 0.014        | 1            | 6.062870e-10 | 6.062870e-12 |\n",
       "| 0.015        | 1            | 9.143986e-10 | 9.143986e-12 |\n",
       "| 0.016        | 1            | 1.342717e-09 | 1.342717e-11 |\n",
       "| 0.017        | 1            | 1.925898e-09 | 1.925898e-11 |\n",
       "| 0.018        | 1            | 2.705508e-09 | 2.705508e-11 |\n",
       "| 0.019        | 1            | 3.730851e-09 | 3.730851e-11 |\n",
       "| 0.020        | 1            | 5.059848e-09 | 5.059848e-11 |\n",
       "| 0.021        | 1            | 6.759944e-09 | 6.759944e-11 |\n",
       "| 0.022        | 1            | 8.909061e-09 | 8.909061e-11 |\n",
       "| 0.023        | 1            | 1.159658e-08 | 1.159658e-10 |\n",
       "| 0.024        | 1            | 1.492438e-08 | 1.492438e-10 |\n",
       "| 0.025        | 1            | 1.900786e-08 | 1.900786e-10 |\n",
       "| 0.026        | 1            | 2.397708e-08 | 2.397708e-10 |\n",
       "| 0.027        | 1            | 2.997784e-08 | 2.997784e-10 |\n",
       "| 0.028        | 1            | 3.717289e-08 | 3.717289e-10 |\n",
       "| 0.029        | 1            | 4.574303e-08 | 4.574303e-10 |\n",
       "| ... | ... | ... | ... |\n",
       "| 0.971        | 1            | 1.717073e-03 | 1.717073e-05 |\n",
       "| 0.972        | 1            | 1.555074e-03 | 1.555074e-05 |\n",
       "| 0.973        | 1            | 1.402968e-03 | 1.402968e-05 |\n",
       "| 0.974        | 1            | 1.260530e-03 | 1.260530e-05 |\n",
       "| 0.975        | 1            | 1.127527e-03 | 1.127527e-05 |\n",
       "| 0.976        | 1            | 1.003718e-03 | 1.003718e-05 |\n",
       "| 0.977        | 1            | 8.888535e-04 | 8.888535e-06 |\n",
       "| 0.978        | 1            | 7.826732e-04 | 7.826732e-06 |\n",
       "| 0.979        | 1            | 6.849097e-04 | 6.849097e-06 |\n",
       "| 0.980        | 1            | 5.952861e-04 | 5.952861e-06 |\n",
       "| 0.981        | 1            | 5.135162e-04 | 5.135162e-06 |\n",
       "| 0.982        | 1            | 4.393046e-04 | 4.393046e-06 |\n",
       "| 0.983        | 1            | 3.723464e-04 | 3.723464e-06 |\n",
       "| 0.984        | 1            | 3.123272e-04 | 3.123272e-06 |\n",
       "| 0.985        | 1            | 2.589229e-04 | 2.589229e-06 |\n",
       "| 0.986        | 1            | 2.117995e-04 | 2.117995e-06 |\n",
       "| 0.987        | 1            | 1.706131e-04 | 1.706131e-06 |\n",
       "| 0.988        | 1            | 1.350096e-04 | 1.350096e-06 |\n",
       "| 0.989        | 1            | 1.046249e-04 | 1.046249e-06 |\n",
       "| 0.990        | 1            | 7.908433e-05 | 7.908433e-07 |\n",
       "| 0.991        | 1            | 5.800277e-05 | 5.800277e-07 |\n",
       "| 0.992        | 1            | 4.098447e-05 | 4.098447e-07 |\n",
       "| 0.993        | 1            | 2.762288e-05 | 2.762288e-07 |\n",
       "| 0.994        | 1            | 1.750054e-05 | 1.750054e-07 |\n",
       "| 0.995        | 1            | 1.018891e-05 | 1.018891e-07 |\n",
       "| 0.996        | 1            | 5.248259e-06 | 5.248259e-08 |\n",
       "| 0.997        | 1            | 2.227481e-06 | 2.227481e-08 |\n",
       "| 0.998        | 1            | 6.639762e-07 | 6.639762e-09 |\n",
       "| 0.999        | 1            | 8.349726e-08 | 8.349726e-10 |\n",
       "| 1.000        | 1            | 0.000000e+00 | 0.000000e+00 |\n",
       "\n"
      ],
      "text/plain": [
       "     p_grid prior likelihood   posterior   \n",
       "1    0.000  1     0.000000e+00 0.000000e+00\n",
       "2    0.001  1     8.374825e-17 8.374825e-19\n",
       "3    0.002  1     5.343808e-15 5.343808e-17\n",
       "4    0.003  1     6.068653e-14 6.068653e-16\n",
       "5    0.004  1     3.399517e-13 3.399517e-15\n",
       "6    0.005  1     1.292911e-12 1.292911e-14\n",
       "7    0.006  1     3.848983e-12 3.848983e-14\n",
       "8    0.007  1     9.676433e-12 9.676433e-14\n",
       "9    0.008  1     2.149583e-11 2.149583e-13\n",
       "10   0.009  1     4.344655e-11 4.344655e-13\n",
       "11   0.010  1     8.150512e-11 8.150512e-13\n",
       "12   0.011  1     1.439542e-10 1.439542e-12\n",
       "13   0.012  1     2.419010e-10 2.419010e-12\n",
       "14   0.013  1     3.898440e-10 3.898440e-12\n",
       "15   0.014  1     6.062870e-10 6.062870e-12\n",
       "16   0.015  1     9.143986e-10 9.143986e-12\n",
       "17   0.016  1     1.342717e-09 1.342717e-11\n",
       "18   0.017  1     1.925898e-09 1.925898e-11\n",
       "19   0.018  1     2.705508e-09 2.705508e-11\n",
       "20   0.019  1     3.730851e-09 3.730851e-11\n",
       "21   0.020  1     5.059848e-09 5.059848e-11\n",
       "22   0.021  1     6.759944e-09 6.759944e-11\n",
       "23   0.022  1     8.909061e-09 8.909061e-11\n",
       "24   0.023  1     1.159658e-08 1.159658e-10\n",
       "25   0.024  1     1.492438e-08 1.492438e-10\n",
       "26   0.025  1     1.900786e-08 1.900786e-10\n",
       "27   0.026  1     2.397708e-08 2.397708e-10\n",
       "28   0.027  1     2.997784e-08 2.997784e-10\n",
       "29   0.028  1     3.717289e-08 3.717289e-10\n",
       "30   0.029  1     4.574303e-08 4.574303e-10\n",
       "...  ...    ...   ...          ...         \n",
       "972  0.971  1     1.717073e-03 1.717073e-05\n",
       "973  0.972  1     1.555074e-03 1.555074e-05\n",
       "974  0.973  1     1.402968e-03 1.402968e-05\n",
       "975  0.974  1     1.260530e-03 1.260530e-05\n",
       "976  0.975  1     1.127527e-03 1.127527e-05\n",
       "977  0.976  1     1.003718e-03 1.003718e-05\n",
       "978  0.977  1     8.888535e-04 8.888535e-06\n",
       "979  0.978  1     7.826732e-04 7.826732e-06\n",
       "980  0.979  1     6.849097e-04 6.849097e-06\n",
       "981  0.980  1     5.952861e-04 5.952861e-06\n",
       "982  0.981  1     5.135162e-04 5.135162e-06\n",
       "983  0.982  1     4.393046e-04 4.393046e-06\n",
       "984  0.983  1     3.723464e-04 3.723464e-06\n",
       "985  0.984  1     3.123272e-04 3.123272e-06\n",
       "986  0.985  1     2.589229e-04 2.589229e-06\n",
       "987  0.986  1     2.117995e-04 2.117995e-06\n",
       "988  0.987  1     1.706131e-04 1.706131e-06\n",
       "989  0.988  1     1.350096e-04 1.350096e-06\n",
       "990  0.989  1     1.046249e-04 1.046249e-06\n",
       "991  0.990  1     7.908433e-05 7.908433e-07\n",
       "992  0.991  1     5.800277e-05 5.800277e-07\n",
       "993  0.992  1     4.098447e-05 4.098447e-07\n",
       "994  0.993  1     2.762288e-05 2.762288e-07\n",
       "995  0.994  1     1.750054e-05 1.750054e-07\n",
       "996  0.995  1     1.018891e-05 1.018891e-07\n",
       "997  0.996  1     5.248259e-06 5.248259e-08\n",
       "998  0.997  1     2.227481e-06 2.227481e-08\n",
       "999  0.998  1     6.639762e-07 6.639762e-09\n",
       "1000 0.999  1     8.349726e-08 8.349726e-10\n",
       "1001 1.000  1     0.000000e+00 0.000000e+00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observations: 10,000\n",
      "Variables: 4\n",
      "$ p_grid     <dbl> 0.564, 0.651, 0.487, 0.592, 0.596, 0.787, 0.727, 0.490, ...\n",
      "$ prior      <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,...\n",
      "$ likelihood <dbl> 0.22408531, 0.27179502, 0.15128823, 0.24557832, 0.248256...\n",
      "$ posterior  <dbl> 0.0022408531, 0.0027179502, 0.0015128823, 0.0024557832, ...\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAANlBMVEUAAAAzMzNNTU1oaGh8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\nRK5CYII=",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAANlBMVEUAAAAzMzNNTU1oaGh8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\nSIwJBiTGBAMSY4L9DyZ15nbyW6imAAAAAElFTkSuQmCC",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# density plots with boundaryies\n",
    "# how many grid points would you like?\n",
    "n <- 1001\n",
    "n_success <- 6\n",
    "n_trials  <- 9\n",
    "\n",
    "(\n",
    "  d <-\n",
    "  tibble(p_grid     = seq(from = 0, to = 1, length.out = n),\n",
    "         # note we're still using a flat uniform prior\n",
    "         prior      = 1) %>% \n",
    "  mutate(likelihood = dbinom(n_success, size = n_trials, prob = p_grid)) %>% \n",
    "  mutate(posterior  = (likelihood * prior) / sum(likelihood * prior))\n",
    "  )\n",
    "# how many samples would you like?\n",
    "n_samples <- 1e4\n",
    "\n",
    "# make it reproducible\n",
    "set.seed(3)\n",
    "\n",
    "samples <-\n",
    "  d %>% \n",
    "  sample_n(size = n_samples, weight = posterior, replace = T)\n",
    "\n",
    "glimpse(samples)\n",
    "d %>% \n",
    "  ggplot(aes(x = p_grid)) +\n",
    "  geom_line(aes(y = posterior)) +\n",
    "  geom_ribbon(data = d %>% filter(p_grid < .5),\n",
    "              aes(ymin = 0, ymax = posterior)) +\n",
    "  labs(x = \"proportion of water (p)\",\n",
    "       y = \"density\")\n",
    "# upper right panel\n",
    "d %>% \n",
    "  ggplot(aes(x = p_grid)) +\n",
    "  geom_line(aes(y = posterior)) +\n",
    "  # note this next line is the only difference in code from the last plot\n",
    "  geom_ribbon(data = d %>% filter(p_grid < .75 & p_grid > .5),\n",
    "              aes(ymin = 0, ymax = posterior)) +\n",
    "  labs(x = \"proportion of water (p)\",\n",
    "       y = \"density\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in mean_qi(., p_grid): could not find function \"mean_qi\"\n",
     "output_type": "error",
     "traceback": [
      "Error in mean_qi(., p_grid): could not find function \"mean_qi\"\nTraceback:\n",
      "1. bind_rows(samples %>% mean_qi(p_grid), samples %>% median_qi(p_grid), \n .     samples %>% mode_qi(p_grid)) %>% select(p_grid, .point) %>% \n .     mutate(x = p_grid + c(-0.03, 0.03, -0.03), y = c(0.1, 0.25, \n .         0.4))",
      "2. eval(lhs, parent, parent)",
      "3. eval(lhs, parent, parent)",
      "4. bind_rows(samples %>% mean_qi(p_grid), samples %>% median_qi(p_grid), \n .     samples %>% mode_qi(p_grid))",
      "5. flatten_bindable(dots_values(...))",
      "6. dots_values(...)",
      "7. samples %>% mean_qi(p_grid)",
      "8. withVisible(eval(quote(`_fseq`(`_lhs`)), env, env))",
      "9. eval(quote(`_fseq`(`_lhs`)), env, env)",
      "10. eval(quote(`_fseq`(`_lhs`)), env, env)",
      "11. `_fseq`(`_lhs`)",
      "12. freduce(value, `_function_list`)",
      "13. withVisible(function_list[[k]](value))",
      "14. function_list[[k]](value)"
     ]
    }
   ],
   "source": [
    "(\n",
    "  point_estimates <-\n",
    "  bind_rows(\n",
    "    samples %>% mean_qi(p_grid),\n",
    "    samples %>% median_qi(p_grid),\n",
    "    samples %>% mode_qi(p_grid)\n",
    "  ) %>% \n",
    "  select(p_grid, .point) %>% \n",
    "  # these last two columns will help us annotate  \n",
    "  mutate(x = p_grid + c(-.03, .03, -.03),\n",
    "         y = c(.1, .25, .4))\n",
    ")\n",
    "d %>% \n",
    "  ggplot(aes(x = p_grid)) +\n",
    "  geom_ribbon(aes(ymin = 0, ymax = posterior),\n",
    "              fill = \"grey75\") +\n",
    "  geom_vline(xintercept = point_estimates$p_grid) +\n",
    "  geom_text(data = point_estimates,\n",
    "            aes(x = x, y = y, label = .point),\n",
    "            angle = 90) +\n",
    "  labs(x = \"proportion of water (p)\",\n",
    "       y = \"density\") +\n",
    "  theme(panel.grid = element_blank())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# beta distribution with binomial likelihood functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b3.1 <-\n",
    "  brm(data = list(w = 6), \n",
    "      family = binomial(link = \"identity\"),\n",
    "      w | trials(9) ~ 1,\n",
    "      # this is a flat prior\n",
    "      prior(beta(1, 1), class = Intercept),\n",
    "      seed = 3,\n",
    "      control = list(adapt_delta = .999))\n",
    "# posterior distribution of intercept\n",
    "posterior_summary(b3.1)[\"b_Intercept\", ] %>% \n",
    "  round(digits = 2)\n",
    "#By default, brms::fitted() will return summary information. Since we want \n",
    "#actual simulation draws, well specify summary = F\n",
    "f <-\n",
    "  fitted(b3.1, summary = F,\n",
    "         scale = \"linear\") %>% \n",
    "  as_tibble() %>% \n",
    "  set_names(\"p\")\n",
    "\n",
    "glimpse(f)\n",
    "f %>% \n",
    "  ggplot(aes(x = p)) +\n",
    "  geom_density(fill = \"grey50\", color = \"grey50\") +\n",
    "  annotate(geom = \"text\", \n",
    "           x = .08, y = 2.5,\n",
    "           label = \"Posterior probability\") +\n",
    "  scale_x_continuous(\"probability of water\",\n",
    "                     breaks = c(0, .5, 1),\n",
    "                     limits = 0:1) +\n",
    "  scale_y_continuous(NULL, breaks = NULL) +\n",
    "  theme(panel.grid = element_blank())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model 1\n",
    "\\begin{align*}\n",
    "\\text{criterion}_i & \\sim \\text{Normal}(\\mu_i, \\sigma) \\\\\n",
    "\\mu_i  & = \\beta \\times \\text{predictor}_i \\\\\n",
    "\\beta  & \\sim \\text{Normal}(0, 10) \\\\\n",
    "\\sigma & \\sim \\text{HalfCauchy}(0, 1)\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fitting with brms\n",
    "b4.1 <- \n",
    "  brm(data = d2, family = gaussian,\n",
    "      height ~ 1,\n",
    "      prior = c(prior(normal(178, 20), class = Intercept),\n",
    "                prior(uniform(0, 50), class = sigma)),\n",
    "      iter = 31000, warmup = 30000, chains = 4, cores = 4,\n",
    "      seed = 4)\n",
    "# uniform prior for  \n",
    "#  was rough on brms. It took an unusually-large number of warmup \n",
    "# iterations before the chains sampled properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b4.1_half_cauchy <- \n",
    "  brm(data = d2, family = gaussian,\n",
    "      height ~ 1,\n",
    "      prior = c(prior(normal(178, 20), class = Intercept),\n",
    "                prior(cauchy(0, 1), class = sigma)),\n",
    "      iter = 2000, warmup = 1000, chains = 4, cores = 4,\n",
    "      seed = 4)\n",
    "# inspect the chains\n",
    "plot(b4.1_half_cauchy)\n",
    "print(b4.1_half_cauchy)\n",
    "b4.1_half_cauchy$fit\n",
    "summary(b4.1_half_cauchy, prob = .90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b4.2 <- \n",
    "  brm(data = d2, family = gaussian,\n",
    "      height ~ 1,\n",
    "      prior = c(prior(normal(178, .1), class = Intercept),\n",
    "                prior(uniform(0, 50), class = sigma)),\n",
    "      iter = 3000, warmup = 2000, chains = 4, cores = 4,\n",
    "      seed = 4)\n",
    "#Check the chains.\n",
    "\n",
    "plot(b4.2)\n",
    "# calculate the postierior covriance structure\n",
    "post <- posterior_samples(b4.1_half_cauchy)\n",
    "# covariance\n",
    "head(post)\n",
    "select(post, b_Intercept:sigma) %>% \n",
    "  cov()\n",
    "# correlation\n",
    "post %>%\n",
    "select(b_Intercept, sigma) %>%\n",
    "  cor()\n",
    "# results\n",
    "summary(post[, 1:2])\n",
    "\n",
    "# sample the posterior distributions\n",
    "ggplot(data = post, \n",
    "       aes(x = sigma)) +\n",
    "  geom_density(size = 1/10, fill = \"black\") +\n",
    "  scale_y_continuous(NULL, breaks = NULL) +\n",
    "  xlab(expression(sigma)) +\n",
    "  theme(panel.grid = element_blank())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAANlBMVEUAAAAzMzNNTU1oaGh8\nfHyMjIyampqnp6eysrK9vb3Hx8fQ0NDZ2dnh4eHp6enr6+vw8PD////agy6EAAAACXBIWXMA\nABJ0AAASdAHeZh94AAAgAElEQVR4nO2di3YbRw4FJ7S9duI4tv7/Z1dSU+JzZvqBbtzG1D1n\nYybGuhoDlEmRFLW8EEKas3gfgJAIQSRCDIJIhBgEkQgxCCIRYhBEIsQgiESIQRCJEINYivR7\nNxkl1hmPpMkoyH0iIoUi0qQXEZFCEWnSi4hIoYg06UVEpFBEmvQiIlIoIk16EREpFJEmvYiI\nFIpIk15ERApFpEkvIiKFItKkFxGRQhFp0ouISKGINOlFRKRQRJr0IiJSKCJNehERKRSRJr2I\niBSKSJNeREQKRaRJLyIihSLSpBcRkUIRadKLiEihiDTpRUSkUESa9CIiUigiTXoRESkUkSa9\niIgUikiTXkRECkWkSS8iIoUi0qQXEZFCEWnSi4hIoYg06UVEpFBEmvQiloh0es397ftfEcmV\nSJNexAKRTp//uNy+/xWRfIk06UVEpFBEmvQiNor08S+IpEGkSS+iuUh/vWXvjyIkbKpFOr1w\nj6RCpEkvIiKFIl4hl3PGEYdFcZLtIp3ufw+R/IgfyItA3VVikqmiVaR7mxDJk3hG3srTVyUm\nmSoaRXr25AMiuRHfkY/i9DSJSaaKfJEu72K43D6drm5cKi1OZh7Fy98D+ewOqKNJTDJVFIiU\nH4uTmUfx8ndAPn8g1+/hHZNMFYgUifj7ZU2YbiYxyVSBSJGIG4/hepnEJFMFIkUibtmCSD2J\niBSJuCxbyD4mMclUgUiBiMs2sotJTDJVIFIc4rKD7PJlEpNMFYgUhrjsIhGpGxGRwhCXfZF6\nmMQkUwUiRSEuOUh7k5hkqkCkIMQlTyRzk5hkqkCkIMQlD4lIfYiIFIS4ZCIRqQ8RkWIQl1yR\nzE1ikqkCkUIQP/TIQBqbxCRTBSJFIH7KgUhOREQKQSwRydgkJpkqECkA8aIGIjkRESkAcSkT\nydYkJpkqEGl+4pUYeUhLk5hkqkCk+YmI5E9EpPmJ11ogkhMRkeYnlotkaRKTTBWINDvxRgpE\nciIi0vTEGpEMTWKSqQKRJifeKoFITkREmp1YJ5KdSUwyVSDS3MQ7IRDJiYhIkxNrRTIziUmm\nCkSamnivAyI5ERFpbmK9SFYmMclUgUhTExFJhIhIUxMfZChB2pjEJFMFIs1MRCQVIiLNTHxU\nAZGciIg0MxGRZIiINDOxTSQbk5hkqkCkeYlPREAkJyIiTUxsFcnEJCaZKhBpWuIzDRDJiYhI\n8xLbRbIwiUmmCkSalfhUAkRyIiLStEREUiIi0rREC5EMTGKSqQKRJiU+VwCRnIiINCvRRqR2\nk5hkqkCkSYmIJEVEpFmJiCRFRKRJiSsCIJITEZEmJVqJ1GwSk0wViDQlcW39EcmJiEhzEhFJ\njIhIcxLtRGo1iUmmCkSakbi6/IjkRESkKYmIpEZEpCmJliI1msQkUwUiTUhcX31EciIi0oxE\nW5HaTGKSqQKR5iNuLD4iORERaUIiIukREWlCorVITSYxyVSBSPMREUmPiEjzEbfWHpGciIg0\nH9FepBaTmGSqQKTpiIgkSESk6YibS49ITkREmo6ISIqTRKTpiD1EajCJSaYKRJqMuL3yiORE\nRKTZiIgkOUlEmo3YR6R6k5hkqkCkuYg7C49ITkREmoyISJqTRKTJiL1EqjaJSaYKRJqKuLfu\niORERKS5iIjkgkQkV+RUItWaxCRTBSJNRUQkFyQiuSIRqU8UJ4lIUxF3l70FWWcSk0wViDQT\nEZF8kIjkikSkPlGcZB+RSJ/0nREbYBLukfSJ+/cZ3CM5ERFpJmJfkepMYpKpApHmIWYsOiI5\nERFpIiIieSERyRU5m0hVJjHJVIFI0xBz1hyRnIiINA8RkdyQiOSKRKQ+UZwkIs1D7C9SjUlM\nMlUg0izErCVHJCciIk1DRCQ/JCK5IucTqcIkJpkqEGkSYt6KI5ITEZFmISKSIxKRXJETilRu\nEpNMFYg0CRGRHJGI5IpEpD5RnCQiTULMXHBEciIi0iTEUSIVm8QkUwUizUFEJE8kIrkiEalP\nFCeJSHMQc9cbkZyIiDQHEZFckYjkipxSpFKTmGSqQKQZiNnLjUhORESagohIvkhEckXOKVKh\nSUwyVSDSBMT81UYkJyIizUBEJGckIrkiEalPFCeJSDMQx4pUZhKTTBWIpE8sWGxEciIi0gRE\nRPJGIpIrEpH6RHGSiDQBcbRIRSYxyVSBSPpERPJGIpIr0og4fq0RqZiISPpEh7Uefh9YFMVJ\nIpI+EZHckYjkikSkPlGcJCLJEz2ejEakUiIiyRMRyR+JSK5IROoTxUkikjzR5X0Gg98mWxbF\nSSKSOtHnmxoQqZCISOpERBJAIpIrcmKRxn5KRGEUJ4lI4kSvz/RBpDIiIokTEUkBiUiuSETq\nE8VJIpI40e3jGgd+SHJpFCeJSNpEv4+0R6QiIiJpExFJAolIrkhE6hPFSSKSNtHxpxUN+xmB\nxVGcJCJJEz1/xjgilRARSZqISBpIRHJFIlKfKE4SkaSJniJlwplkqkAkZSIiaSARyRWJSH2i\nOElEUiYWe4RIXkREUiYikggSkVyRk4uUh2eSqQKRdInlHiGSFxGRhImIpIJEJFckIvWJ4iQR\nSZjoLVLWAZhkqkAkWWKFR4jkRUQkXSIiySARyRWJSH2iOElE0iX6i5RzBCaZKhBJlVjjESJ5\nERFJlohIOkhEckUiUp8oThKRZIkKImUcgkmmCkQSJVZ5hEheRERSJSKSEBKRXJGI1CeKk0Qk\nVaKGSPvHYJKpApFEiYgkhEQkVyQi9YniJBFJlFjnESJ5EUtEOr3m8fbp898/fxOR2okqIu0e\nhEmminyRThdtrm6f9TndlFqczDyKl389iKSE7C/S6QWRuhARSQk54B7p5j8jkhWx0iNE8iJa\nifT5JdJfb9n7o8heLJ/6aYvOSSZJ+z0STzbYEblHkkIOu0e6u2VxMvMoXv7V6Ii0dxQmmSoQ\nSZFY6xEieRGNROKhnS0RkbSQQ0W6eubO4mTmUbz8a0EkLWSfdzacrm5fv7MBkcyISiLtHIZJ\npooCkfJjcTLzKF7+lVR7hEheRERSJCKSGBKRXJGI1CeKk0QkRaKWSNvHYZKpApH0iPUeIZIX\nEZEEiYi0HcVJIpIgEZG2ozhJRBIkqom0eSAmmSoQSY7Y4BEieRERSY+ISDtRnCQi6RERaSeK\nk0QkPaKeSFtHYpKpApHkiIi0E8VJIpIeEZF2ojhJRJIjtniESF5ERJIjItJeFCeJSHJERNqL\n4iQRSY6oKNLGoZhkqkAkNSIi7UVxkoikRmzyCJG8iIikRkSk3ShOEpHUiIi0G8VJIpIaUVOk\n9WMxyVSBSFrENo8QyYuISGJERNqP4iQRSYyISPtRnCQiiRFVRVo9GJNMFYgkRWz0CJG8iIik\nRUSkjChOEpG0iIiUEcVJIpIWUVektaMxyVSBSErEVo8QyYuISFJERMqJ4iQRSYqISDlRnCQi\nSRGVRVo5HJNMFYikRESknChOEpGkiIiUE8VJIpISsdkjRPIiIpISUVuk58djkqkCkYSIiJQV\nxUkikhIRkbKiOElEEiK2e4RIXkREEiIiUl4UJ4lIQkREyoviJBFJiKgu0tMDMslUgUg6RETK\ni+IkEUmHaOARInkREUmHiEiZUZwkIukQESkzipNEJB2ivkjPjsgkUwUiqRAtPEIkLyIiyRAR\nKTeKk0QkGSIi5UZxkogkQ5xBpCeHZJKpApFEiCYeIZIXEZFUiIiUHcVJIpIKEZGyozhJRFIh\nziHS4zGZZKpAJA2ijUeI5EVEJBEiIuVHcZKIJEJEpPwoThKRRIiziPRwUCaZKhBJg4hI+VGc\nJCKJEBEpP4qTRCQRIiLlR3GSiKRBNPIIkbyIiKRBRKSCKE4SkTSIiFQQxUkikgZxHpHuj8ok\nUwUiKRCtPEIkLyIiSRARqSSKk0QkCSIilURxkogkQZxJpLvDMslUgUgCRDOPEMmLiEgKREQq\niuIkEUmBiEhFUZwkIikQ5xLp9rhMMlUgkgARkYqiOElEEiDaeYRIXkREEiAiUlkUJ4lIAkRE\nKoviJBFJgDibSDcHZpKpootIpCTzXfn5Tjww3CN5EQ3vkLhH8iIikj8RkQqjOElE8ifOJ9L1\nkZlkqkAkdyIiFUZxkojkT0SkwihOEpHciZYeIZIXEZHciTOKdHVoJpkqEMmbiEilUZwkIrkT\nEak0ipNEJHciIpVGcZKI5E009QiRvIiI5E1EpOIoThKRvImIVBzFSSKSN3FOkS7HZpKpApF8\nibYeIZIXEZGciYhUHsVJIpIzEZHKozhJRHImzirS58GZZKpAJFeisUeI5EVEJF8iIlVEcZKI\n5EtEpIooThKRfInzivRxdCaZKhDJk2jtESJ5ERHJlYhINVGcJCK5EhGpJoqTRCRX4swinQ/P\nJFMFInkSEakmipNEJFciItVEcZKI5EpEpJooThKRPInmHiGSFxGRPIlzi5SOzyRTBSI5EhGp\nKoKTRCRXIiJVRXCSiORJtPcIkbyIiORIRKS66E0SkVyJiFQXvUkikitxdpHeG2CSqQKR3Igd\nPEIkLyIi+RERqTJyk/yNSJ5ERKqM3CR/I5IncX6R3lpgkqkCkdyIiFQZuUn+RiRHYg+PEMmL\niEhuRESqjdok3ysQyYuISLVRm+R7BSJ5ESOI9NoEk0wViORE7OIRInkREcmLiEjVEZtkqkAk\nJyIiVUdskqkCkZyIMUT6vTDJVIFIPsQ+HiGSFxGRnIiIVB+tSZ4rEMmHiEj10ZrkuQKRfIhR\nROrVyFa0JnmuQCQfIiLVR2uS5wpE8iEiUn20JnmuQCQfIiLVR2uS5wpEciH2Wj+HJsebJDXJ\njwpEciEiUgtSkIhIPkREakEKEldF+vLjX0TqR0SkFqQgcVWkZVlO//uJSH2I3ZYPkZyIqyL9\n+efbq0vL13/+QyR7IiI1IQWJqyK95ef306tLX8rvlyxOZh6ly49ITUhB4qZIL/99X97vlhDJ\nmBhJpPGvJClN8rNiQ6Rf397vjv79unxDJFNiv9VDJCfiukg/v34+qltKnxq3OJl5hC4/IjUi\n9YirIn1Zlm+/Pn7rhEimRERqROoRV0Vavv96qY7FycwjdPljiTTcJKFJXirWRPpTrxEi7RA7\nLh4iORFXRfr4uuhU+rAOkXaJiNSMlCM+F+m0XAWRrImI1IyUIz4X6e8rj/5GJGtiNJFGm6Qz\nyauKpyK9VDzljUi5xJ5rh0hOxFWRmmJxMvPIXH5EMkCqEZ+L9Hp3xNdI3YiIZIBUIyLSeGI8\nkQabJDPJ64qnIrXG4mTmkbn8iGSBFCMi0ngiIlkgxYjrIv19enn5dzn9QCRrIiJZIMWIqyL9\n/frF0X9vL8zWmGRxMvOoXP6uS4dITsRVkb4s/77+7+9fxe/8RqQdYkSRxpqkMsmbijWRXu+Q\nfi5fKl+YtTiZeVQuPyLZILWIqyKdlv/+t/x6+yrp8p9Ol3ewXm6fHn4PkTaJiGSD1CKuivTj\n7fO43u6Qvn+6c9Hm6vbpdP97iLRJ7LtyiOREXBXp5fty+vkqx6dHz0U6vSBSGRGRjJBaxHWR\nHvL8HgmRComIZITUIpqL9Ndb9v6oI8fyhW+hBG2rIg8P7U5377XjHsmC2PmvbrcmR94laUzy\nrmJNpO8Pb1pFJAsiIpkhpYirIp0evjUWkSyIiGSGlCKuivT4QiwiWRCjijTSJI1J3lWsifRt\nuf9ALkQyIPZeN0RyIq6K9N/p6/0PdPl498Lp6jbvbCgjIpIhUom4KhLfIduFiEiGSCUiIo0l\nxhVpoEkSk7yvWBOpKRYnM4/C5e++bIjkRESkoUREMkUKETdE+vvb68O6r1U/k8LiZOZRuPyI\nZIoUIq6K9OfL+9dHy/IvItkRI4s0ziSFST5UrIn0v+X724uy/5T/AFlEWiX2XzVEciKuivT2\nbN3H/xDJiIhIxkgdIiKNJCKSMVKHuCrS+aHd9+V/iGRGjC3SMJMEJvlYsSbSn/O3I53u3yiE\nSPVERLJGyhBXRXp5+fFlWb58r/pZshYnM4/A5Ucka6QMcUOkhliczDwClx+RrJEyREQaSByw\naIjkRHwu0vXPYuZZOzMiIpkjZYiINJCISOZIGeJzkd7y7e0b+/77+q3CI0R6Towu0iiT/Cf5\npGJNpI9vNV9qTLI4mXncL/+INUMkJ+KqSOeHdH94aGdGRKQOSBXiqkhfl/TQjnskMyIidUCq\nEFdF+o93NlgT44s0yCT3ST6rWBPp5c/3t3c2/OCdDVbEIUuGSE7EdZFaYnEy83hffkTqghQh\nItIwIiJ1QYoQEWkY8QgiHaPJpxWINIh4jL+sEQmROhMRqRNSg4hIo4iI1AmpQUSkUcRjiHSE\nF8ueVyDSGOJRXvRHJETqSkSkbkgJIiINIiJSN6QEEZEGEY8iUvxvulqpQKQxRETqh1QgItIg\nIiL1QyoQEWkM8TgfZ4BIiNSReByRon9431oFIg0hIlJPpAARkcYQEaknUoCISEOIR/qJJ4iE\nSN2IiNQVKUBEpCFEROqKFCAi0hDikUSK/ROnVysQaQBxmEcSO4ZIiNSJiEidkf5ERBpBRKTO\nSH8iIo0gHkuk7u1KNHlfgUj9ieM80tgxREKkLkRE6o50JyLSACIidUe6ExFpAPFoIvVuWKPJ\nuwpE6k4c6JHIjiESInUgItIApDcRkfoTjydS55ZFmrytQKTexJEeqewYIiGSORGRhiCdiYjU\nnYhIQ5DORETqTjyiSH2bVmnypgKRehMRaQzSl4hI3YmINAbpS0Sk3sShHsnsGCIhkjERkQYh\nfYmI1JuISIOQvkRE6k08pkhd25Zp8roCkfoSx3qks2OIhEimREQahnQlIlJnIiINQ7oSEakz\n8agi9Wxcp8mrCkTqShzskdCOIRIiGRIRaSDSk4hIfYmINBDpSUSkvsTjitSxdaEmLxWI1JM4\n2iOlHUMkRDIjItJQpCMRkboSEWko0pGISF2JRxapX/NKTX5WIFJH4nCPpHYMkRDJiIhIg5F+\nRETqSTy2SN1MkmryowKROhIRaTTSjYhIPYmINBrpRkSkjhnvkdaOIRIxyeEv6SEvAPdI5jn6\nPVKvC6DV5LkCkfoFkcYjvYiI1C/LEZpEpHMFInULIiESIhkEkRAJkQyCSJ1MEmsyVSBSryxH\naBKRPioQqVcQCZEQySCI9LuTSWpNvlcgUqcsR2hyl4hIiNQYRHoLIiFSYxDpLYiESI1BpPf0\nMEmuyd+I1C3LcOJ75HYMkRCpKYiUgkiI1BREOqeDSXpNIlKvLMOJKXo7hkiI1BBE+ggiIVJD\nEOkjiIRIDUGkz9ibJNgkInUKIn0GkRCpPoj0GURCpOosw4nnCO4YIiFSdRDpEkRCpOog0lXM\nTVJsEpF6ZBlO/IjijiESIlUGka6DSIhUGUS6DiIhUmUQ6SbWJik2iUgd8rE4oZssICISIlUF\nkW6DSIhUFUS6i7FJik0ikn0+1yZyk0VEREKkiiDSfRAJkSqCSPdBJESqCCI9xNYkxSYRyTyX\npQncZCERkRCpOIj0GERCpOIg0pOYmqTYJCKZB5GeBJEQqTSI9CSIhEiFuVqZuE0WExEJkQqD\nSE9jaZJik4hkHUR6GkRCpKJcL0zYJiuIiIRIRUGk50EkRCoKIj0PIiFSURBpJYYmKTaJSLa5\nWZeoTVYREQmRCoJIa0EkRCoIIq3GziTFJhHJNLfLErTJSiIiIVJ2EGk9iIRI2UGkjZiZpNgk\nIlnmblViNllNRCREygwibQWRECkziLQZK5MUm0QkyyDSZhAJkfKCSJtBJETKyv2ihGyygYhI\niJQVRNqJkUmKTSKSYRBpJ4iESBl5WJOITTYREQmRMoJIe0EkRMoIIu0FkRApI4i0GxuTFJtE\nJLM8LknAJhuJiIRIu0Gk/SASIu0GkTJiYpJik4hklScrEq/JZiIiIdJOECkniIRIO0GkrFiY\npNgkIhnl2YKEa9KAiEiItBlEygsiIdJmECkzBiYpNolINnm6HtGaNCEiEiJtBJFyg0iItBFE\nyk67SYpNIpJNECk7iIRIq3m+HMGaNCIiEiKtBpEK0mySYpOIZBJEKggiIdJKVlYjVpNmxMOL\ndHrN/e3rXz9/E5G6E9eiuGP3ObpIp89/XG5//rfTTanFycyDSCrEVpMUm0Qkg6wtRqgmDYmI\ntCrSrUeI1Ju4GsUdewgirYv0+SXSX2/Z+6OCxfJ5mkMk9AVrv0c66pMNq3/BRmrSlNh4l6TY\npJFIL9e/IlJv4noUd+wxiIRIT4JIxWkzSbFJI5GO/NBufSkCNWlMRKQNka6eubM4mXkQSYd4\naJEu72K4vn33KyINIG5EcceepckkxSZLRMqPxcnMg0hCRERCpPsgUkUQCZHusrEScZq0J7aY\npNgkIrUGkaqCSIh0G0SqCiIh0k22FiJMkx2IiIRIN0Gkyv9fg0mKTSJSWzbXIUqTXYiIhEhX\nQSREShWI1BREqibWm6TYJCI1ZXsZgjTZiYhIiPQZREKkcwUitQSRGojVJik2iUgt2VmFGE12\nIyISIp2DSIj0UYFIDUGkJmKtSYpNIlJD9hYhRJMdiYiESO9BpEZipUmKTSJSQxCpkYhIiPQW\nRGokIhIi/c5YgwhNdiUiEiL9RiQDYp1Jik0iUnX2lyBAk52JiIRIiGRARCREQiQLYpVJik0i\nUm0yVmD+JrsTEQmRhhNzorhjm6kxSbFJRKpMzgJM3+QAIiIh0mBiVhR3bDOIhEiDiVlR3LHt\nVJik2CQi1SVr/LM3OYSISIg0lJgXxR3bDiIh0lBiXhR3bCflJik2iUh1QSQzIiIdWKS84U/e\n5ChisUmKTSJSVRDJkIhIhxUpc/RzNzmMiEiINIyYG8Ud2wsiIdIwYm4Ud2w3pSYpNolIFckd\n/NRNDiQiEiINImZHccf2U2iSYpOIVJ7ssc/c5FAiIiHSEGJ+FHcsI2UmKTaJSMXJH/rETQ4m\nIhIiDSAWRHHHMoJIiDSAWBDFHctJkUmKTSJSaQpGPm+Tw4mIhEjdiSVR3LGslJik2CQilQaR\nuhAR6WAiaQ9ccseyon1dEckcqT1wyR3LivZ1RSRzpPbAJXcsL9IPmRHJGin+7JLkjuUFkRCp\nK7EsijuWGeXX5xDJGKn+CrzkjmUGkRCpI7EwijuWG+E3AyOSLVL+7f6SO5YbREKkbsTSKO5Y\ndnS/YRKRTJH63xItuWPZQSRE6kQsjuKO5Uf2Q2UQyRSJSJ2JiHQIkSb4/DXJHSuI6ifYIpIl\nEpG6ExHpACLN8FMTJHesIIiESB2IFVHcsYIgEiJ1IFZEccdKIvpzpxDJDjnFj2iU3LGSIBIi\nmRNrorhjRdH8afGIZIas8Gi+JgWIiIRIxsSqKO5YWTIutGKTiJSXGo+ma1KCiEiIZEqsi+KO\nFWb/Uis2iUhZqfJotiZFiIiESIbEyijuWGl2L7Zik4iUkzqPJmtShohIiGRGrI3ijhVn73Ir\nNolIGan0aK4mhYiIhEhGxOoo7lh5di64YpOItJ9aj6ZqUoqISIhkQqyP4o5VZPuSKzaJSLup\n9mimJsWIiBQwXBiHTHzRuUd6nvo7pImalCNuXnXFJhFpL4jkQty67IpNItJeEMmFiEjBRGrw\naJ4mFYkbF16xSUTaTotH0zQpSUQkRGoitkVxxyqzfukVm0SkzTR5NEuTokREQqQGYmMUd6w2\nqxdfsUlE2kqbR5M0KUtc1i6/YpOItJFGj+ZoUpiISBYnMw8iTUdcGYBik4i0EURyJiKSwcnM\nU4xs9WiKJrWJz0eg2CQirWb1a91uRIMo7lhDEKn9ZOYpFmk40SCKO9aSp0NQbBKR1tLu0QRN\nyhMRqflk5ilDtj+wm6DJCYjPxqDYJCKtxMAj/SZnID4ZhGKTiPQ8Fh7JNzkFEZEaT2aeEqTF\nAzv5JichPo5CsUlEehoTj9SbnIX4MAzFJhHpaRBJiIhITSczTwHSxiPxJuch3o9DsUlEehIj\nj7SbnIiISC0nMw8iTUu8G4hik4j0GCuPpJucinj3JKpik4j0EDOPlJucjIhI9SczTybS5iWk\nEqJlFHfMIjdDUWwSke5j55Fwk/MRr8ei2CQi3cXwDkm3yQmJ13NRbBKR7mLokW6TMxIRqfJk\n5slCWnok2+SUxKu7JMUmEekmph6pNjkp8WKSYpOIdB1bj0SbnJaISFUnM88+0vKJhjyieRR3\nzCwf41FsEpEusfZIssmpict4ZC4RkS6x9kiyybmJy3hkJhGRPmN+h6TY5ORERCo/mXl2kPYe\nCTY5PXEZj8wjItJH7D0SbHJ+4jIemUVEpHM6eKTXZADi2wMHxSYRKaWHR3JNhiC+mqTYJCK9\np4tHak0GIS6LYpOI9JYOTzTsEHtFcces02laW0GkLGSvyUg1GYfY6fHDVhApB9ntbzilJgMR\nf78MNwmRMpD9HikINRmJ+IocbRIi7SM7PuLWaTIU8Q052CRE2kX2/MpVpslYxHfkWJMQaRfZ\ncyAyTcYiJuRQkxBpD9l1HCpNBiOeRRppEiLtIPsOQ6TJaMQzcqRJiLSJ7D0KiSbjET+QA01C\npC1k90EoNBmQeEEOMwmRtpDdx6DQZEDiFXKUSYi0jhzwwMC/yZDEa+QgkxBpFTniAbZ7kzGJ\nN8gxJiHSGnLIF6reTQYlSk7ymCINer7He8eCEiUfWxxUpOHEUTmgSCPGiUjPkMNefxDYsYjE\nR5EEnn89oEjjXscT2LGIRMmX1g8nktYbSwIgNZrsPFZEukeKvdUxAFKlya6TRaQ75NjPzVDZ\nsWBEye8sO5RIoz9+RmbHYhHXkIvnhwYcSSTBj8wIgFRq0vFjbI4jkuSnoQVAajXp9gmFRxFJ\n9INuAyDFmuxjEiKlLKofvR4AKddkD5UQ6T2L7E/VCYAUbNLjR8bFF+nzuRx2LAhxH2n+/B0i\nXf3txI4FIWYhbVU6ukg3fzOxY0GImUhLlY4t0t0dPDsWhJiNtHuEd2CRHi8iOxaEWIC0Uumo\nIi3PLhNlPRgAAAOpSURBVCA7FoRYhjRx6ZgirVw6diwIsRjZ7tLxRHp6X9QXuZ4JdmxGYgVy\nYy2MiKFE2r5c7FgQYiWyxaUDibTs/qXDjgUh1iOr75gOItK+RObIrMy0YxMR25B5y1JMnF2k\nJf+6sGNBiO3Igq3JJc4r0lJ6NdixIEQjZMkC2Yp0es397ftfB4i0FCvUjKzMtDumTTRF5i2T\nqUinz39cbt//2lGkZak1qBrZmsl3TJXYA7mzXXOLtNwk4//QjrRNjB2TI/Z+Nf/J1umLtGyk\n+mJsI8cl2I6pEMd+M9t7HET66y17f9Qr7eOEhMSK3kM74/CXdRCiZJOIFIpIk15ERApFpEkv\nIiKFItKkFxGRQhFp0otYINLlXQzXt8e/s6E2ipc/AJImU0WBSPmxOJl5FC9/ACRNpgpEikSk\nSS8iIoUi0qQXEZFCEWnSi4hIoYg06UVEpFBEmvQiIlIoIk16EREpFJEmvYiIFIpIk15ERApF\npEkvIiKFItKkFxGRQhFp0ouISKGINOlFRKRQRJr0IiJSKCJNehERKRSRJr2IiBSKSJNeREQK\nRaRJLyIihSLSpBcRkUIRadKLiEihiDTpRUSkUESa9CIiUigiTXoRESkUkSa9iIgUikiTXkRE\nCkWkSS8iIoUi0qQXEZFCEWnSi9hHpP1k/HTM+UOTUVLSJCKZhyajBJFcQ5NRgkiuocko0RWJ\nkKBBJEIMgkiEGASRCDEIIhFiEEQixCBjRDqlf77m+tdguTR5egna5P0EwzeZP8khIp0Pdv7H\n5V9C5Xy1z42FbPJ+gqGbLJzkCJFOLwcQ6fSCSCEiLNLLEUS66ytqk/FFes+peJKIZJbbB9af\n/yVaDiNS2SQRySyHaPLlerdo8hJEMsvp+lbUJo8j0scNRBqdQ4jEJFeCSGY5QpNXz0zS5E0Q\nySw3z5vGbPLuGeHwTWo+2RD79fAjNHm6f7GfJj/De+0IMQgiEWIQRCLEIIhEiEEQiRCDIBIh\nBkEkQgyCSIQYBJEIMQgiEWIQRCLEIIhEiEEQafZ8W369vPxavnqf4+BBpNnzZ/ny8vL1zSbi\nGESaPj+Wn/8s371PcfQg0vyJ+F1B0wWR5s8/y/KP9xkOH0SaP4gkEESaP6cvX3ho5x1Emj4/\nlp8/lx/epzh6EGn2vD/9/WX5432OgweRZs/5Bdlv3uc4eBCJEIMgEiEGQSRCDIJIhBgEkQgx\nCCIRYhBEIsQgiESIQRCJEIMgEiEGQSRCDIJIhBjk/1OX6FkwLnw/AAAAAElFTkSuQmCC",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAAKlBMVEUAAAAzMzNNTU1oaGh8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\nAABJRU5ErkJggg==",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAANlBMVEUAAAAzMzNNTU1oaGh8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\nGJIUwJCkAIYkBTAkKYAhSQH+Hyb4w7DuaCHpAAAAAElFTkSuQmCC",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# density for mu\n",
    "ggplot(data = tibble(x = seq(from = 100, to = 250, by = .1)), \n",
    "       aes(x = x, y = dnorm(x, mean = 178, sd = 20))) +\n",
    "  geom_line() +\n",
    "  ylab(\"density\")\n",
    "tibble(x = seq(from = -10, to = 60, by = .1)) %>%\n",
    "# density for sigma  \n",
    "ggplot(aes(x = x, y = dunif(x, min = 0, max = 50))) +\n",
    "geom_line() +\n",
    "scale_y_continuous(NULL, breaks = NULL) +\n",
    "theme(panel.grid = element_blank())\n",
    "\n",
    "# density for X\n",
    "n <- 1e4\n",
    "\n",
    "set.seed(4)\n",
    "tibble(sample_mu    = rnorm(n, mean = 178,       sd = 20),\n",
    "       sample_sigma = runif(n, min = 0,         max = 50)) %>% \n",
    "  mutate(x          = rnorm(n, mean = sample_mu, sd = sample_sigma)) %>% \n",
    "  \n",
    "ggplot(aes(x = x)) +\n",
    "geom_density(fill = \"black\", size = 0) +\n",
    "scale_y_continuous(NULL, breaks = NULL) +\n",
    "labs(subtitle = expression(paste(\"Prior predictive distribution for \", italic(h[i]))),\n",
    "   x        = NULL) +\n",
    "theme(panel.grid = element_blank())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>mu</th><th scope=col>sigma</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>140     </td><td>4.000000</td></tr>\n",
       "\t<tr><td>140     </td><td>4.025126</td></tr>\n",
       "\t<tr><td>140     </td><td>4.050251</td></tr>\n",
       "\t<tr><td>140     </td><td>4.075377</td></tr>\n",
       "\t<tr><td>140     </td><td>4.100503</td></tr>\n",
       "\t<tr><td>140     </td><td>4.125628</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ll}\n",
       " mu & sigma\\\\\n",
       "\\hline\n",
       "\t 140      & 4.000000\\\\\n",
       "\t 140      & 4.025126\\\\\n",
       "\t 140      & 4.050251\\\\\n",
       "\t 140      & 4.075377\\\\\n",
       "\t 140      & 4.100503\\\\\n",
       "\t 140      & 4.125628\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| mu | sigma |\n",
       "|---|---|\n",
       "| 140      | 4.000000 |\n",
       "| 140      | 4.025126 |\n",
       "| 140      | 4.050251 |\n",
       "| 140      | 4.075377 |\n",
       "| 140      | 4.100503 |\n",
       "| 140      | 4.125628 |\n",
       "\n"
      ],
      "text/plain": [
       "  mu  sigma   \n",
       "1 140 4.000000\n",
       "2 140 4.025126\n",
       "3 140 4.050251\n",
       "4 140 4.075377\n",
       "5 140 4.100503\n",
       "6 140 4.125628"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ERROR",
     "evalue": "Error in dnorm(d2$height, mean = mu, sd = sigma, log = T): object 'd2' not found\n",
     "output_type": "error",
     "traceback": [
      "Error in dnorm(d2$height, mean = mu, sd = sigma, log = T): object 'd2' not found\nTraceback:\n",
      "1. d_grid %>% mutate(log_likelihood = map2(mu, sigma, grid_function)) %>% \n .     unnest() %>% mutate(prior_mu = dnorm(mu, mean = 178, sd = 20, \n .     log = T), prior_sigma = dunif(sigma, min = 0, max = 50, log = T)) %>% \n .     mutate(product = log_likelihood + prior_mu + prior_sigma) %>% \n .     mutate(probability = exp(product - max(product)))",
      "2. withVisible(eval(quote(`_fseq`(`_lhs`)), env, env))",
      "3. eval(quote(`_fseq`(`_lhs`)), env, env)",
      "4. eval(quote(`_fseq`(`_lhs`)), env, env)",
      "5. `_fseq`(`_lhs`)",
      "6. freduce(value, `_function_list`)",
      "7. function_list[[i]](value)",
      "8. mutate(., log_likelihood = map2(mu, sigma, grid_function))",
      "9. mutate.tbl_df(., log_likelihood = map2(mu, sigma, grid_function))",
      "10. mutate_impl(.data, dots, caller_env())",
      "11. map2(mu, sigma, grid_function)",
      "12. .f(.x[[i]], .y[[i]], ...)",
      "13. dnorm(d2$height, mean = mu, sd = sigma, log = T) %>% sum()   # at line 13-14 of file <text>",
      "14. eval(lhs, parent, parent)",
      "15. eval(lhs, parent, parent)",
      "16. dnorm(d2$height, mean = mu, sd = sigma, log = T)"
     ]
    }
   ],
   "source": [
    "# grid approximation\n",
    "n <- 200\n",
    "\n",
    "d_grid <-\n",
    "  tibble(mu    = seq(from = 140, to = 160, length.out = n),\n",
    "         sigma = seq(from = 4,   to = 9,   length.out = n)) %>% \n",
    "  # we'll accomplish with `tidyr::expand()` what McElreath did with base R `expand.grid()`\n",
    "  expand(mu, sigma)\n",
    "\n",
    "head(d_grid)\n",
    "\n",
    "grid_function <- function(mu, sigma){\n",
    "  dnorm(d2$height, mean = mu, sd = sigma, log = T) %>% \n",
    "    sum()\n",
    "}\n",
    "\n",
    "d_grid <-\n",
    "  d_grid %>% \n",
    "  mutate(log_likelihood = map2(mu, sigma, grid_function)) %>% \n",
    "  unnest() %>% \n",
    "  mutate(prior_mu       = dnorm(mu,    mean = 178, sd  = 20, log = T),\n",
    "         prior_sigma    = dunif(sigma, min  = 0,   max = 50, log = T)) %>% \n",
    "  mutate(product        = log_likelihood + prior_mu + prior_sigma) %>% \n",
    "  mutate(probability    = exp(product - max(product)))\n",
    "  \n",
    "head(d_grid)\n",
    "\n",
    "d_grid %>% \n",
    "  ggplot(aes(x = mu, y = sigma, z = probability)) + \n",
    "  geom_contour() +\n",
    "  labs(x = expression(mu),\n",
    "       y = expression(sigma)) +\n",
    "  coord_cartesian(xlim = range(d_grid$mu),\n",
    "                  ylim = range(d_grid$sigma)) +\n",
    "  theme(panel.grid = element_blank())\n",
    "\n",
    "# heat map\n",
    "d_grid %>% \n",
    "  ggplot(aes(x = mu, y = sigma)) + \n",
    "  geom_raster(aes(fill = probability),\n",
    "              interpolate = T) +\n",
    "  scale_fill_viridis_c(option = \"A\") +\n",
    "  labs(x = expression(mu),\n",
    "       y = expression(sigma)) +\n",
    "  theme(panel.grid = element_blank())\n",
    "\n",
    "# samples\n",
    "set.seed(4)\n",
    "d_grid_samples <- \n",
    "  d_grid %>% \n",
    "  sample_n(size = 1e4, replace = T, weight = probability)\n",
    "\n",
    "d_grid_samples %>% \n",
    "  ggplot(aes(x = mu, y = sigma)) + \n",
    "  geom_point(size = .9, alpha = 1/15) +\n",
    "  scale_fill_viridis_c() +\n",
    "  labs(x = expression(mu[samples]),\n",
    "       y = expression(sigma[samples])) +\n",
    "  theme(panel.grid = element_blank())\n",
    "\n",
    "\n",
    "#We can use gather() and then facet_warp() to plot the densities for both mu\n",
    "#and sigma at once.\n",
    "\n",
    "d_grid_samples %>% \n",
    "  select(mu, sigma) %>% \n",
    "  gather() %>% \n",
    "\n",
    "  ggplot(aes(x = value)) + \n",
    "  geom_density(fill = \"grey33\", size = 0) +\n",
    "  scale_y_continuous(NULL, breaks = NULL) +\n",
    "  xlab(NULL) +\n",
    "  theme(panel.grid = element_blank()) +\n",
    "  facet_wrap(~key, scales = \"free\")\n",
    "\n",
    "# calculate the posterior modes and HDIs\n",
    "d_grid_samples %>% \n",
    "  select(mu, sigma) %>% \n",
    "  gather() %>% \n",
    "  group_by(key) %>% \n",
    "  mode_hdi(value)\n",
    "\n",
    "# samples\n",
    "set.seed(4)\n",
    "d_grid_samples <- \n",
    "  d_grid %>% \n",
    "  sample_n(size = 1e4, replace = T, weight = probability)\n",
    "\n",
    "d_grid_samples %>% \n",
    "  ggplot(aes(x = mu, y = sigma)) + \n",
    "  geom_point(size = .9, alpha = 1/15) +\n",
    "  scale_fill_viridis_c() +\n",
    "  labs(x = expression(mu[samples]),\n",
    "       y = expression(sigma[samples])) +\n",
    "  theme(panel.grid = element_blank())\n",
    "\n",
    "d_grid_samples %>% \n",
    "  select(mu, sigma) %>% \n",
    "  gather() %>% \n",
    "\n",
    "  ggplot(aes(x = value)) + \n",
    "  geom_density(fill = \"grey33\", size = 0) +\n",
    "  scale_y_continuous(NULL, breaks = NULL) +\n",
    "  xlab(NULL) +\n",
    "  theme(panel.grid = element_blank()) +\n",
    "  facet_wrap(~key, scales= \"free\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model 2\n",
    "\\begin{align*}\n",
    "h_i & \\sim \\text{Normal}(\\mu_i, \\sigma) \\\\\n",
    "\\mu_i & = \\alpha + \\beta x_i \\\\\n",
    "\\alpha & \\sim \\text{Normal}(178, 100) \\\\\n",
    "\\beta & \\sim \\text{Normal}(0, 10) \\\\\n",
    "\\sigma & \\sim \\text{Uniform}(0, 50)\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b4.3 <- \n",
    "  brm(data = d2, \n",
    "      family = gaussian,\n",
    "      height ~ 1 + weight,\n",
    "      prior = c(prior(normal(156, 100), class = Intercept),\n",
    "                prior(normal(0, 10), class = b),\n",
    "                prior(uniform(0, 50), class = sigma)),\n",
    "      iter = 41000, warmup = 40000, chains = 4, cores = 4,\n",
    "      seed = 4)\n",
    "plot(b4.3)\n",
    "# results\n",
    "posterior_summary(b4.3)[1:3, ]\n",
    "# samples from posterior\n",
    "posterior_samples(b4.3) %>%\n",
    "  select(-lp__) %>%\n",
    "  cor() %>%\n",
    "  round(digits = 2)\n",
    "\n",
    "# refit and visulize the figures\n",
    "d2 %>%\n",
    "  ggplot(aes(x = weight, y = height)) +\n",
    "  geom_abline(intercept = fixef(b4.3)[1], \n",
    "              slope     = fixef(b4.3)[2]) +\n",
    "  geom_point(shape = 1, size = 2, color = \"royalblue\") +\n",
    "  theme_bw() +\n",
    "  theme(panel.grid = element_blank())\n",
    "\n",
    "# adding uncertainty around the mean\n",
    "post <- posterior_samples(b4.3)\n",
    "\n",
    "post %>%\n",
    "  slice(1:5)  # this serves a similar function as `head()`\n",
    "\n",
    "p10 <- \n",
    "  ggplot(data =  d2[1:10 , ], \n",
    "         aes(x = weight, y = height)) +\n",
    "  geom_abline(intercept = post10[1:20, 1], \n",
    "              slope     = post10[1:20, 2],\n",
    "              size = 1/3, alpha = .3) +\n",
    "  geom_point(shape = 1, size = 2, color = \"royalblue\") +\n",
    "  coord_cartesian(xlim = range(d2$weight),\n",
    "                  ylim = range(d2$height)) +\n",
    "  labs(subtitle = \"N = 10\") +\n",
    "  theme_bw() +\n",
    "  theme(panel.grid = element_blank())\n",
    "\n",
    "# prediction\n",
    "mu_at_50 <- \n",
    "  post %>% \n",
    "  transmute(mu_at_50 = b_Intercept + b_weight * 50)\n",
    "mu_at_50 %>%\n",
    "  ggplot(aes(x = mu_at_50)) +\n",
    "  geom_density(size = 0, fill = \"royalblue\") +\n",
    "  stat_pointintervalh(aes(y = 0), \n",
    "                      point_interval = mode_hdi, .width = .95) +\n",
    "  scale_y_continuous(NULL, breaks = NULL) +\n",
    "  labs(x = expression(mu[\"height | weight = 50\"])) +\n",
    "  theme_classic()\n",
    "\n",
    "mu <- fitted(b4.3, summary = F)\n",
    "d2 %>%\n",
    "  ggplot(aes(x = weight, y = height)) +\n",
    "  geom_smooth(data = mu_summary,\n",
    "              aes(y = Estimate, ymin = Q2.5, ymax = Q97.5),\n",
    "              stat = \"identity\",\n",
    "              fill = \"grey70\", color = \"black\", alpha = 1, size = 1/2) +\n",
    "  geom_point(color = \"navyblue\", shape = 1, size = 1.5, alpha = 2/3) +\n",
    "  coord_cartesian(xlim = range(d2$weight)) +\n",
    "  theme(text = element_text(family = \"Times\"),\n",
    "        panel.grid = element_blank())\n",
    "\n",
    "pred_height <-\n",
    "  predict(b4.3,\n",
    "          newdata = weight_seq) %>%\n",
    "  as_tibble() %>%\n",
    "  bind_cols(weight_seq)\n",
    "  \n",
    "pred_height %>%\n",
    "  slice(1:6)\n",
    "\n",
    "\n",
    "d2 %>%\n",
    "  ggplot(aes(x = weight)) +\n",
    "  geom_ribbon(data = pred_height, \n",
    "              aes(ymin = Q2.5, ymax = Q97.5),\n",
    "              fill = \"grey83\") +\n",
    "  geom_smooth(data = mu_summary,\n",
    "              aes(y = Estimate, ymin = Q2.5, ymax = Q97.5),\n",
    "              stat = \"identity\",\n",
    "              fill = \"grey70\", color = \"black\", alpha = 1, size = 1/2) +\n",
    "  geom_point(aes(y = height),\n",
    "             color = \"navyblue\", shape = 1, size = 1.5, alpha = 2/3) +\n",
    "  coord_cartesian(xlim = range(d2$weight),\n",
    "                  ylim = range(d2$height)) +\n",
    "  theme(text = element_text(family = \"Times\"),\n",
    "        panel.grid = element_blank()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# polynomial regression\n",
    "b4.5 <- \n",
    "  brm(data = d, family = gaussian,\n",
    "      height ~ 1 + weight_s + I(weight_s^2),\n",
    "      prior = c(prior(normal(178, 100), class = Intercept),\n",
    "                prior(normal(0, 10), class = b),\n",
    "                prior(cauchy(0, 1), class = sigma)),\n",
    "      iter = 2000, warmup = 1000, chains = 4, cores = 4,\n",
    "      seed = 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mulivariate Linear models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "\\text{Divorce}_i & \\sim \\text{Normal}(\\mu_i, \\sigma) \\\\\n",
    "\\mu_i   & = \\alpha + \\beta_1 \\text{Marriage_s}_i + \\beta_2 \\text{MedianAgeMarriage_s}_i \\\\\n",
    "\\alpha  & \\sim \\text{Normal}(10, 10) \\\\\n",
    "\\beta_1 & \\sim \\text{Normal}(0, 1) \\\\\n",
    "\\beta_2 & \\sim \\text{Normal}(0, 1) \\\\\n",
    "\\sigma  & \\sim \\text{Uniform}(0, 10)\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gg theme\n",
    "install.packages(\"ggrepel\", depencencies = T)\n",
    "library(ggrepel)\n",
    "\n",
    "d %>%\n",
    "  ggplot(aes(x = WaffleHouses/Population, y = Divorce)) +\n",
    "  stat_smooth(method = \"lm\", fullrange = T, size = 1/2,\n",
    "              color = \"firebrick4\", fill = \"firebrick\", alpha = 1/5) +\n",
    "  geom_point(size = 1.5, color = \"firebrick4\", alpha = 1/2) +\n",
    "  geom_text_repel(data = d %>% filter(Loc %in% c(\"ME\", \"OK\", \"AR\", \"AL\", \n",
    "                                                 \"GA\", \"SC\", \"NJ\")),  \n",
    "                  aes(label = Loc), \n",
    "                  size = 3, seed = 1042) +  # this makes it reproducible\n",
    "  scale_x_continuous(\"Waffle Houses per million\", limits = c(0, 55)) +\n",
    "  coord_cartesian(xlim = 0:50, ylim = 5:15) +\n",
    "  ylab(\"Divorce rate\") +\n",
    "  theme_bw() +\n",
    "  theme(panel.grid = element_blank())  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the data with map visualization method\n",
    "library(fiftystater)\n",
    "\n",
    "d %>% \n",
    "  # first we'll standardize the three variables to put them all on the same scale\n",
    "  mutate(Divorce_z           = (Divorce - mean(Divorce))/ sd(Divorce),\n",
    "         MedianAgeMarriage_z = (MedianAgeMarriage - mean(MedianAgeMarriage))/sd(MedianAgeMarriage),\n",
    "         Marriage_z          = (Marriage - mean(Marriage))/ sd(Marriage),\n",
    "         # need to make the state names lowercase to match with the map data\n",
    "         Location            = str_to_lower(Location)) %>% \n",
    "  # here we select the relevant variables and put them in the long format to facet with `facet_wrap()`\n",
    "  select(Divorce_z:Marriage_z, Location) %>% \n",
    "  gather(key, value, -Location) %>% \n",
    "  \n",
    "  ggplot(aes(map_id = Location)) +\n",
    "  geom_map(aes(fill = value), map = fifty_states, \n",
    "           color = \"firebrick\", size = 1/15) +\n",
    "  expand_limits(x = fifty_states$long, y = fifty_states$lat) +\n",
    "  scale_x_continuous(NULL, breaks = NULL) +\n",
    "  scale_y_continuous(NULL, breaks = NULL) +\n",
    "  scale_fill_gradient(low = \"#f8eaea\", high = \"firebrick4\") +\n",
    "  coord_map() +\n",
    "  theme_bw() +\n",
    "  theme(panel.grid       = element_blank(),\n",
    "        legend.position  = \"none\",\n",
    "        strip.background = element_rect(fill = \"transparent\", color = \"transparent\")) +\n",
    "  facet_wrap(~key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b5.1 <- \n",
    "  brm(data = d, family = gaussian,\n",
    "      Divorce ~ 1 + MedianAgeMarriage_s,\n",
    "      prior = c(prior(normal(10, 10), class = Intercept),\n",
    "                prior(normal(0, 1), class = b),\n",
    "                prior(uniform(0, 10), class = sigma)),\n",
    "      iter = 2000, warmup = 500, chains = 4, cores = 4,\n",
    "      seed = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the range of `MedianAgeMarriage_s` values we'd like to feed into `fitted()`\n",
    "nd <- tibble(MedianAgeMarriage_s = seq(from = -3, to = 3.5, length.out = 30))\n",
    "\n",
    "# now use `fitted()` to get the model-implied trajectories\n",
    "f <- \n",
    "  fitted(b5.1, newdata = nd) %>%\n",
    "  as_tibble() %>%\n",
    "  # tack the `nd` data onto the `fitted()` results\n",
    "  bind_cols(nd)\n",
    "\n",
    "# plot\n",
    "ggplot(data = f, \n",
    "       aes(x = MedianAgeMarriage_s, y = Estimate)) +\n",
    "  geom_smooth(aes(ymin = Q2.5, ymax = Q97.5),\n",
    "              stat = \"identity\",\n",
    "              fill = \"firebrick\", color = \"firebrick4\", alpha = 1/5, size = 1/4) +\n",
    "  geom_point(data = d, \n",
    "             aes(y = Divorce), \n",
    "             size = 2, color = \"firebrick4\") +\n",
    "  ylab(\"Divorce\") +\n",
    "  coord_cartesian(xlim = range(d$MedianAgeMarriage_s), \n",
    "                  ylim = range(d$Divorce)) +\n",
    "  theme_bw() +\n",
    "  theme(panel.grid = element_blank())   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Three ways to make coefficients plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b5.3 <- \n",
    "  brm(data = d, family = gaussian,\n",
    "      Divorce ~ 1 + Marriage_s + MedianAgeMarriage_s,\n",
    "      prior = c(prior(normal(10, 10), class = Intercept),\n",
    "                prior(normal(0, 1), class = b),\n",
    "                prior(uniform(0, 10), class = sigma)),\n",
    "      iter = 2000, warmup = 500, chains = 4, cores = 4,\n",
    "      seed = 5)\n",
    "print(b5.3)\n",
    "\n",
    "#1 The stanplot() function is an easy way to get a default coefficient plot\n",
    "stanplot(b5.3)\n",
    "#2 install.packages(\"bayesplot\", dependencies = T)\n",
    "library(bayesplot)\n",
    "\n",
    "post <- posterior_samples(b5.3)\n",
    "\n",
    "color_scheme_set(\"red\")\n",
    "mcmc_intervals(post[, 1:4], \n",
    "               prob = .5,\n",
    "               point_est = \"median\") +\n",
    "  labs(title = \"My fancy bayesplot-based coefficient plot\") +\n",
    "  theme(axis.text.y  = element_text(hjust = 0),\n",
    "        axis.line.x  = element_line(size = 1/4),\n",
    "        axis.line.y  = element_blank(),\n",
    "        axis.ticks.y = element_blank())\n",
    "\n",
    "# 3\n",
    "library(tidybayes)\n",
    "\n",
    "post %>% \n",
    "  select(-lp__) %>% \n",
    "  gather() %>% \n",
    "  \n",
    "  ggplot(aes(x = value, y = reorder(key, value))) +  # note how we used `reorder()` to arrange the coefficients\n",
    "  geom_vline(xintercept = 0, color = \"firebrick4\", alpha = 1/10) +\n",
    "  stat_pointintervalh(point_interval = mode_hdi, .width = .95, \n",
    "                      size = 3/4, color = \"firebrick4\") +\n",
    "  labs(title = \"My tidybayes-based coefficient plot\",\n",
    "       x = NULL, y = NULL) +\n",
    "  theme_bw() +\n",
    "  theme(panel.grid   = element_blank(),\n",
    "        panel.grid.major.y = element_line(color = alpha(\"firebrick4\", 1/4), linetype = 3),\n",
    "        axis.text.y  = element_text(hjust = 0),\n",
    "        axis.ticks.y = element_blank())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Residual Checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b5.4 <- \n",
    "  brm(data = d, family = gaussian,\n",
    "      Marriage_s ~ 1 + MedianAgeMarriage_s,\n",
    "      prior = c(prior(normal(0, 10), class = Intercept),\n",
    "                prior(normal(0, 1), class = b),\n",
    "                prior(uniform(0, 10), class = sigma)),\n",
    "      iter = 2000, warmup = 500, chains = 4, cores = 4,\n",
    "      seed = 5)\n",
    "# With fitted(), we compute the expected values for each x\n",
    "f <- \n",
    "  fitted(b5.4) %>%\n",
    "  as_tibble() %>%\n",
    "  bind_cols(d)\n",
    "f %>% \n",
    "  \n",
    "  ggplot(aes(x = MedianAgeMarriage_s, y = Marriage_s)) +\n",
    "  geom_point(size = 2, shape = 1, color = \"firebrick4\") +\n",
    "  geom_segment(aes(xend = MedianAgeMarriage_s, yend = Estimate), \n",
    "               size = 1/4) +\n",
    "  geom_line(aes(y = Estimate), \n",
    "            color = \"firebrick4\") +\n",
    "  coord_cartesian(ylim = range(d$Marriage_s)) +\n",
    "  theme_bw() +\n",
    "  theme(panel.grid = element_blank())   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We get the residuals with the well-named residuals() function. Much like \n",
    "# with brms::fitted(), brms::residuals() returns a four-vector matrix with \n",
    "# the number of rows equal to the number of observations in the original \n",
    "# data (by default, anyway).\n",
    "r <- \n",
    "  residuals(b5.4) %>%\n",
    "  # to use this in ggplot2, we need to make it a tibble or data frame\n",
    "  as_tibble() %>% \n",
    "  bind_cols(d)\n",
    "\n",
    "# for the annotation at the top\n",
    "text <-\n",
    "  tibble(Estimate = c(- 0.5, 0.5),\n",
    "         Divorce = 14.1,\n",
    "         label = c(\"slower\", \"faster\"))\n",
    "\n",
    "# plot\n",
    "r %>% \n",
    "  ggplot(aes(x = Estimate, y = Divorce)) +\n",
    "  stat_smooth(method = \"lm\", fullrange = T,\n",
    "              color = \"firebrick4\", fill = \"firebrick4\", \n",
    "              alpha = 1/5, size = 1/2) +\n",
    "  geom_vline(xintercept = 0, linetype = 2, color = \"grey50\") +\n",
    "  geom_point(size = 2, color = \"firebrick4\", alpha = 2/3) +\n",
    "  geom_text(data = text,\n",
    "            aes(label = label)) +\n",
    "  scale_x_continuous(\"Marriage rate residuals\", limits = c(-2, 2)) +\n",
    "  coord_cartesian(xlim = range(r$Estimate),\n",
    "                  ylim = c(6, 14.1)) +\n",
    "  theme_bw() +\n",
    "  theme(panel.grid = element_blank())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "\\text{kcal.per.g}_i & \\sim \\text{Normal}(\\mu_i, \\sigma) \\\\\n",
    "\\mu_i   & = \\alpha + \\beta_1 \\text{neocortex.perc}_i + \\beta_2 \\text{log}(\\text{mass}_i) \\\\\n",
    "\\alpha  & \\sim \\text{Normal}(0, 100) \\\\\n",
    "\\beta_1 & \\sim \\text{Normal}(0, 1) \\\\\n",
    "\\beta_2 & \\sim \\text{Normal}(0, 1) \\\\\n",
    "\\sigma  & \\sim \\text{Uniform}(0, 1)\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b5.7 <- \n",
    "  brm(data = dcc, family = gaussian,\n",
    "      kcal.per.g ~ 1 + neocortex.perc + log_mass,\n",
    "      prior = c(prior(normal(0, 100), class = Intercept),\n",
    "                prior(normal(0, 1), class = b),\n",
    "                prior(uniform(0, 1), class = sigma)),\n",
    "      iter = 4000, warmup = 2000, chains = 4, cores = 4,\n",
    "      control = list(adapt_delta = 0.999),\n",
    "      seed = 5)\n",
    "print(b5.7, digits = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multicollinearity means very strong correlation between two or more \n",
    "# predictor variables. The consequence of it is that the posterior \n",
    "# distribution will \n",
    "# say that a very large range of parameter values are plausible, from tiny \n",
    "# associations to massive ones, even if all of the variables are in reality \n",
    "# strongly associated with the outcome. This frustrating phenomenon arises \n",
    "# from the details of how statistical control works. So once you understand \n",
    "# multicollinearity, you will better understand [multivariable] models in \n",
    "# general.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simulate data\n",
    "n <- 100\n",
    "set.seed(5)\n",
    "d <- \n",
    "  tibble(height    = rnorm(n, mean = 10, sd = 2),\n",
    "         leg_prop  = runif(n, min = 0.4, max = 0.5)) %>% \n",
    "  mutate(leg_left  = leg_prop * height + rnorm(n, mean = 0, sd = 0.02),\n",
    "         leg_right = leg_prop * height + rnorm(n, mean = 0, sd = 0.02))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d %>%\n",
    "  select(leg_left:leg_right) %>%\n",
    "  cor() %>%\n",
    "  round(digits = 4)\n",
    "d %>%\n",
    "  ggplot(aes(x = leg_left, y = leg_right)) +\n",
    "  geom_point(alpha = 1/2, color = \"firebrick4\") +\n",
    "  theme_bw() +\n",
    "  theme(panel.grid = element_blank())\n",
    "# check\n",
    "b5.8 <- \n",
    "  brm(data = d, family = gaussian,\n",
    "      height ~ 1 + leg_left + leg_right,\n",
    "      prior = c(prior(normal(10, 100), class = Intercept),\n",
    "                prior(normal(2, 10), class = b),\n",
    "                prior(uniform(0, 10), class = sigma)),\n",
    "      iter = 2000, warmup = 500, chains = 4, cores = 4,\n",
    "      seed = 5)\n",
    "print(b5.8)\n",
    "color_scheme_set(\"red\")\n",
    "\n",
    "stanplot(b5.8, \n",
    "         type = \"intervals\", \n",
    "         prob = .5, \n",
    "         prob_outer = .95,\n",
    "         point_est = \"median\") +\n",
    "  labs(title    = \"The coefficient plot for the two-leg model\",\n",
    "       subtitle = \"Holy smokes; look at the widths of those betas!\") +\n",
    "  theme_bw() +\n",
    "  theme(text         = element_text(size = 14),\n",
    "        panel.grid   = element_blank(),\n",
    "        axis.ticks.y = element_blank(),\n",
    "        axis.text.y  = element_text(hjust = 0))\n",
    "\n",
    "pairs(b5.8, pars = parnames(b5.8)[2:3])\n",
    "post <- posterior_samples(b5.8)\n",
    "  \n",
    "post %>% \n",
    "  ggplot(aes(x = b_leg_left, y = b_leg_right)) +\n",
    "  geom_point(color = \"firebrick\", alpha = 1/10, size = 1/3) +\n",
    "  theme_bw() +\n",
    "  theme(panel.grid = element_blank())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#install.packages(\"GGally\", dependencies = T)\n",
    "library(GGally)\n",
    "\n",
    "ggpairs(data = d, columns = c(3:4, 6)) + \n",
    "  theme(panel.grid = element_blank())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit regression model with Categorical Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# male is the categorical indicator with two levels\n",
    "b5.15 <- \n",
    "  brm(data = d, family = gaussian,\n",
    "      height ~ 1 + male,\n",
    "      prior = c(prior(normal(178, 100), class = Intercept),\n",
    "                prior(normal(0, 10), class = b),\n",
    "                prior(cauchy(0, 2), class = sigma)),\n",
    "      iter = 2000, warmup = 500, chains = 4, cores = 4,\n",
    "      seed = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d <-\n",
    "  d %>%\n",
    "  mutate(female = 1 - male)\n",
    "b5.15b <- \n",
    "  brm(data = d, family = gaussian,\n",
    "      height ~ 0 + male + female,\n",
    "      prior = c(prior(normal(178, 100), class = b),\n",
    "                prior(cauchy(0, 2), class = sigma)),\n",
    "      iter = 2000, warmup = 500, chains = 4, cores = 4,\n",
    "      seed = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# When there are more than two categories, youll need more than one dummy \n",
    "#variable. Heres the general rule: To include k categories in a linear model,\n",
    "# you require k1 dummy variables. Each dummy variable indicates, with the \n",
    "# value 1, a unique category. The category with no dummy variable assigned \n",
    "# to it ends up again as the intercept category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For multi-categorical variables, first transform into dummy\n",
    "\n",
    "d %>%\n",
    "  distinct(clade)\n",
    "d <- \n",
    "  d %>%\n",
    "  mutate(clade_nwm = ifelse(clade == \"New World Monkey\", 1, 0),\n",
    "         clade_owm = ifelse(clade == \"Old World Monkey\", 1, 0),\n",
    "         clade_s   = ifelse(clade == \"Strepsirrhine\", 1, 0),\n",
    "         clade_ape = ifelse(clade == \"Ape\", 1, 0))\n",
    "\n",
    "# Population-Level Effects: \n",
    "b5.16 <- \n",
    "  brm(data = d, family = gaussian,\n",
    "      kcal.per.g ~ 1 + clade_nwm + clade_owm + clade_s,\n",
    "      prior = c(prior(normal(.6, 10), class = Intercept),\n",
    "                prior(normal(0, 1), class = b),\n",
    "                prior(uniform(0, 10), class = sigma)),\n",
    "      iter = 2000, warmup = 500, chains = 4, cores = 4,\n",
    "      seed = 5)\n",
    "post <- \n",
    "  b5.16 %>%\n",
    "  posterior_samples()\n",
    "\n",
    "head(post)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coefficents for each categoricals fitting visualization\n",
    "nd <- tibble(clade_nwm = c(1, 0, 0, 0),\n",
    "             clade_owm = c(0, 1, 0, 0),\n",
    "             clade_s   = c(0, 0, 1, 0),\n",
    "             primate   = c(\"New World Monkey\", \"Old World Monkey\",\n",
    "                           \"Strepsirrhine\", \"Ape\"))\n",
    "\n",
    "fitted(b5.16,\n",
    "       newdata = nd,\n",
    "       summary = F) %>% \n",
    "  as_tibble() %>% \n",
    "  gather() %>% \n",
    "  mutate(primate = rep(c(\"New World Monkey\", \"Old World Monkey\", \n",
    "                         \"Strepsirrhine\", \"Ape\"), \n",
    "                       each = n() / 4)) %>% \n",
    "  \n",
    "  ggplot(aes(x = value, y = reorder(primate, value))) +\n",
    "  geom_halfeyeh(fill = \"firebrick4\", \n",
    "                point_interval = median_qi, .width = .95) +\n",
    "  labs(x = \"kcal.per.g\",\n",
    "       y = NULL) +\n",
    "  theme_bw() +\n",
    "  theme(panel.grid   = element_blank(),\n",
    "        axis.ticks.y = element_blank(),\n",
    "        axis.text.y  = element_text(hjust = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quantile plotting\n",
    "# base R\n",
    "quantile(post$mu_nwm - post$mu_owm, probs = c(.5, .025, .975))\n",
    "##         50%        2.5%       97.5% \n",
    "## -0.07362279 -0.21514058  0.06410530\n",
    "# tidyverse + tidybayes\n",
    "post %>%\n",
    "  transmute(dif = mu_nwm - mu_owm) %>%\n",
    "  median_qi()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "another way to use categorical variables without dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clade is the categorical varialbe\n",
    "b5.16_alt <- \n",
    "  brm(data = d, family = gaussian,\n",
    "      kcal.per.g ~ 0 + clade,\n",
    "      prior = c(prior(normal(.6, 10), class = b),\n",
    "                prior(uniform(0, 10), class = sigma)),\n",
    "      iter = 2000, warmup = 500, chains = 4, cores = 4,\n",
    "      seed = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install.packages(\"rcartocolor\", dependencies = T)\n",
    "library(rcartocolor)\n",
    "carto_pal(7, \"BurgYl\")\n",
    "display_carto_pal(7, \"BurgYl\")\n",
    "\n",
    "library(gridExtra)\n",
    "grid.arrange(p1, p2, p3, p4, p5, p6, ncol = 2)\n",
    "\n",
    "p +\n",
    "  stat_smooth(method = \"lm\", fullrange = TRUE, level = .89,\n",
    "              color = carto_pal(7, \"BurgYl\")[6], fill = carto_pal(7, \"BurgYl\")[6], \n",
    "              size = 1/2, alpha = 1/3,              \n",
    "              formula = y ~ 1) +\n",
    "  ggtitle(NULL, subtitle = expression(paste(italic(R)^2, \" = 0\")))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rethinking regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now well specify the initial values and fit the model.\n",
    "\n",
    "# Here we specify our starting values\n",
    "inits <- list(Intercept = mean(d$brain),\n",
    "              mass_s    = 0,\n",
    "              sigma     = sd(d$brain))\n",
    "\n",
    "inits_list <- list(inits, inits, inits, inits)\n",
    "\n",
    "# The model\n",
    "b6.8 <- \n",
    "  brm(data = d, family = gaussian,\n",
    "      brain ~ 1 + mass_s,\n",
    "      prior = c(prior(normal(0, 1000), class = Intercept),\n",
    "                prior(normal(0, 1000), class = b),\n",
    "                prior(cauchy(0, 10), class = sigma)),\n",
    "      iter = 2000, warmup = 1000, chains = 4, cores = 4,\n",
    "      inits = inits_list,  # here we insert our start values\n",
    "      seed = 6)\n",
    "print(b6.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the brms function log_lik() returns a matrix. Each occasion \n",
    "gets a column and each HMC chain iteration gets a row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ll <-\n",
    "  b6.8 %>%\n",
    "  log_lik() %>%\n",
    "  as_tibble(.name_repair = ~ d$species)\n",
    "\n",
    "ll %>%\n",
    "  glimpse()\n",
    "\n",
    "ll <-\n",
    "  ll %>%\n",
    "  mutate(sums     = rowSums(.),\n",
    "         deviance = -2 * sums)\n",
    "\n",
    "library(tidybayes)\n",
    "\n",
    "ll %>%\n",
    "  ggplot(aes(x = deviance, y = 0)) +\n",
    "  geom_halfeyeh(fill = carto_pal(7, \"BurgYl\")[5], color = carto_pal(7, \"BurgYl\")[7],\n",
    "                point_interval = median_qi, .width = .95) +\n",
    "  scale_x_continuous(breaks = quantile(ll$deviance, c(.025, .5, .975)),\n",
    "                     labels = quantile(ll$deviance, c(.025, .5, .975)) %>% round(1)) +\n",
    "  scale_y_continuous(NULL, breaks = NULL) +\n",
    "  labs(title = \"The deviance distribution\") +\n",
    "  theme_classic() +\n",
    "  theme(text = element_text(family = \"Courier\"),\n",
    "        panel.background = element_rect(fill = alpha(carto_pal(7, \"BurgYl\")[3], 1/4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deviance is a principled way to measure distance from the target insample. But deviance as computed in the previous section has the same flaw as R2 : It always improves as the model gets more complex, at least for the types of models we have considered so far. Just like R2 , deviance in-sample is a measure of retrodictive accuracy, not predictive accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation with WAIC and LOO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Widely Applicable Information Criterion (WAIC)\n",
    "Define  as the average likelihood of observation P(y_i) in the training sample. This means we compute the likelihood of  \n",
    "yi for each set of parameters sampled from the posterior distribution. Then we average the likelihoods for each observation i and finally sum over all observations. This produces the first part of WAIC, the log-pointwise-predictive-density, lppd:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\text{lppd} = \\sum_{i = 1}^N \\text{log Pr} (y_i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You might say this out loud as:\n",
    "\n",
    "The log-pointwise-predictive-density is the total across observations of the logarithm of the average likelihood of each observation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second piece of WAIC is the effect number of parameters  \n",
    "pWAIC . Define V(yi) as the variance in log-likelihood for observation i in the training sample. This means we compute the log-likelihood for observation yi for each sample from the posterior distribution. Then we take the variance of those values. This is V(yi). Now PAIC s defined as:\n",
    "Pwaic = sum(V(yi))\n",
    "Now WAIC is -2*(lppd - pwaic)\n",
    "This is another estimate of out-of-sample deviance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data(cars)\n",
    "\n",
    "b <- \n",
    "  brm(data = cars, family = gaussian,\n",
    "      dist ~ 1 + speed,\n",
    "      prior = c(prior(normal(0, 100), class = Intercept),\n",
    "                prior(normal(0, 10), class = b),\n",
    "                prior(uniform(0, 30), class = sigma)),\n",
    "      iter = 2000, warmup = 1000, chains = 4, cores = 4,\n",
    "      seed = 6)\n",
    "\n",
    "#In brms, you return the loglikelihood with log_lik().\n",
    "\n",
    "ll <-\n",
    "  b %>%\n",
    "  log_lik() %>%\n",
    "  as_tibble()\n",
    "\n",
    "#Computing the lppd, the Bayesian deviance, takes a bit of leg work.\n",
    "\n",
    "dfmean <-\n",
    "  ll %>%\n",
    "  exp() %>%\n",
    "  summarise_all(mean) %>%\n",
    "  gather(key, means) %>%\n",
    "  select(means) %>%\n",
    "  log()\n",
    "\n",
    "(\n",
    "  lppd <-\n",
    "  dfmean %>%\n",
    "  sum()\n",
    ")\n",
    "\n",
    "# Comupting the effective number of parameters,pWAIC , isnt much better.\n",
    "dfvar <-\n",
    "  ll %>%\n",
    "  summarise_all(var) %>%\n",
    "  gather(key, vars) %>%\n",
    "  select(vars) \n",
    "\n",
    "pwaic <-\n",
    "  dfvar %>%\n",
    "  sum()\n",
    "\n",
    "pwaic\n",
    "\n",
    "# compare two methods for waic\n",
    "-2 * (lppd - pwaic)\n",
    "waic(b)\n",
    "waic(b6.11)\n",
    "b6.11 <- add_criterion(b6.11, \"waic\")\n",
    "b6.11$waic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute and save the WAIC information for the next three \n",
    "# models\n",
    "b6.12 <- add_criterion(b6.12, \"waic\")\n",
    "b6.13 <- add_criterion(b6.13, \"waic\")\n",
    "b6.14 <- add_criterion(b6.14, \"waic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare the WAIC estimates\n",
    "w <- loo_compare(b6.11, b6.12, b6.13, b6.14,\n",
    "                 criterion = \"waic\")\n",
    "\n",
    "print(w)\n",
    "With respect to the output, notice the elpd_diff column and the adjacent se_diff column. Those are our WAIC differences. The models have been rank ordered from the lowest (i.e., b6.14) to the highest (i.e., b6.12). The scores listed are the differences of b6.14 minus the comparison model. Since b6.14 is the comparison model in the top row, the values are naturally 0 (i.e.,  \n",
    "But now heres another critical thing to understand: Since the brms version 2.8.0 update, WAIC and LOO differences are no longer reported in the  \n",
    " metric. Remember how we keep rehearsing that multiplying (lppd - pwaic) by -2 is a historic artifact associated with the frequentist chi-square test? Well, the makers of the loo package arent fans and they no longer support the conversion.\n",
    " So heres the deal. The substantive interpretations of the differences presented in an elpd_diff metric will be the same as if presented in a WAIC metric. But if we want to compare our elpd_diff results to those in the text, we will have to multiply them by -2. And also, if we want the associated standard error in the proper metric, well need to multiply the se_diff column by 2. You wouldnt multiply by -2 because that would return a negative standard error, which would be silly. Heres a quick way to do so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cbind(waic_diff = w[, 1] * -2,\n",
    "      se        = w[, 2] * 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(w, simplify = F)\n",
    "model_weights(b6.11, b6.12, b6.13, b6.14, \n",
    "              weights = \"waic\") %>% \n",
    "  round(digits = 2)\n",
    "model_weights(b6.11, b6.12, b6.13, b6.14, \n",
    "              weights = \"waic\") %>%\n",
    "  as_tibble() %>% \n",
    "  rename(weight = value) %>% \n",
    "  mutate(model  = c(\"b6.11\", \"b6.12\", \"b6.13\", \"b6.14\"),\n",
    "         weight = weight %>% round(digits = 2)) %>% \n",
    "  select(model, weight) %>% \n",
    "  arrange(desc(weight)) %>% \n",
    "  knitr::kable()\n",
    "w[, 7:8] %>% \n",
    "  data.frame() %>% \n",
    "  rownames_to_column(var = \"model_name\") %>% \n",
    "  \n",
    "  ggplot(aes(x    = model_name, \n",
    "             y    = waic, \n",
    "             ymin = waic - se_waic, \n",
    "             ymax = waic + se_waic)) +\n",
    "  geom_pointrange(shape = 21, color = carto_pal(7, \"BurgYl\")[7], fill = carto_pal(7, \"BurgYl\")[5]) +\n",
    "  coord_flip() +\n",
    "  labs(x = NULL, y = NULL,\n",
    "       title = \"My custom WAIC plot\") +\n",
    "  theme_classic() +\n",
    "  theme(text             = element_text(family = \"Courier\"),\n",
    "        axis.ticks.y     = element_blank(),\n",
    "        panel.background = element_rect(fill = alpha(carto_pal(7, \"BurgYl\")[3], 1/4)))\n",
    "\n",
    "\n",
    "loo(b6.11)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need new data for both the `fitted()` and `pp_average()` functions\n",
    "nd <- \n",
    "  tibble(neocortex = seq(from = .5, to = .8, length.out = 30),\n",
    "         mass      = 4.5)\n",
    "\n",
    "# we'll get the `b6.14`-implied trajectory with `fitted()`\n",
    "f <-\n",
    "  fitted(b6.14, newdata = nd) %>%\n",
    "  as_tibble() %>%\n",
    "  bind_cols(nd)\n",
    "\n",
    "# the model-average trajectory comes from `pp_average()`\n",
    "pp_average(b6.11, b6.12, b6.13, b6.14,\n",
    "           weights = \"waic\",\n",
    "           method  = \"fitted\",  # for new data predictions, use `method = \"predict\"`\n",
    "           newdata = nd) %>%\n",
    "  as_tibble() %>%\n",
    "  bind_cols(nd) %>%\n",
    "  \n",
    "  # plot Figure 6.13\n",
    "  ggplot(aes(x = neocortex, y = Estimate)) +\n",
    "  geom_ribbon(aes(ymin = Q2.5, ymax = Q97.5), \n",
    "              fill  = carto_pal(7, \"BurgYl\")[6], alpha = 1/4) +\n",
    "  geom_line(color   = carto_pal(7, \"BurgYl\")[6]) +\n",
    "  geom_ribbon(data  = f, aes(ymin = Q2.5, ymax = Q97.5),\n",
    "              color = carto_pal(7, \"BurgYl\")[5], fill = \"transparent\", linetype = 2) +\n",
    "  geom_line(data = f,\n",
    "              color = carto_pal(7, \"BurgYl\")[5], linetype = 2) +\n",
    "  geom_point(data = d, aes(y = kcal.per.g), \n",
    "             size = 2, color = carto_pal(7, \"BurgYl\")[7]) +\n",
    "  labs(y = \"kcal.per.g\") +\n",
    "  coord_cartesian(xlim = range(d$neocortex), \n",
    "                  ylim = range(d$kcal.per.g)) +\n",
    "  theme_classic() +\n",
    "  theme(text             = element_text(family = \"Courier\"),\n",
    "        panel.background = element_rect(fill = alpha(carto_pal(7, \"BurgYl\")[3], 1/4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bayes R square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bayes_R2(b6.14) %>% round(digits = 3)\n",
    "rbind(bayes_R2(b6.11), \n",
    "      bayes_R2(b6.12), \n",
    "      bayes_R2(b6.13), \n",
    "      bayes_R2(b6.14)) %>%\n",
    "  as_tibble() %>%\n",
    "  mutate(model = c(\"b6.11\", \"b6.12\", \"b6.13\", \"b6.14\"),\n",
    "         r_square_posterior_mean = round(Estimate, digits = 2)) %>%\n",
    "  select(model, r_square_posterior_mean)\n",
    "r2_b6.13 <- bayes_R2(b6.13, summary = F)\n",
    "\n",
    "r2_b6.13 %>%\n",
    "  glimpse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model `b6.13`\n",
    "r2_b6.13 <- \n",
    "  bayes_R2(b6.13, summary = F) %>%\n",
    "  as_tibble() %>%\n",
    "  rename(r2_13 = R2)\n",
    "\n",
    "# model `b6.14`\n",
    "r2_b6.14 <- \n",
    "  bayes_R2(b6.14, summary = F) %>%\n",
    "  as_tibble() %>%\n",
    "  rename(r2_14 = R2)\n",
    "\n",
    "# let's put them in the same data object\n",
    "r2_combined <-\n",
    "  bind_cols(r2_b6.13, r2_b6.14) %>%\n",
    "  mutate(dif = r2_14 - r2_13)\n",
    "\n",
    "# plot their densities\n",
    "r2_combined %>%\n",
    "  ggplot() +\n",
    "  geom_density(aes(x = r2_13),\n",
    "               fill = carto_pal(7, \"BurgYl\")[4], alpha = 3/4, size = 0, ) +\n",
    "  geom_density(aes(x = r2_14),\n",
    "               fill = carto_pal(7, \"BurgYl\")[6], alpha = 3/4, size = 0, ) +\n",
    "  scale_y_continuous(NULL, breaks = NULL) +\n",
    "  coord_cartesian(xlim = 0:1) +\n",
    "  labs(x        = NULL,\n",
    "       title    = expression(paste(italic(\"R\")^{2}, \" distributions\")),\n",
    "       subtitle = \"Going from left to right, these are\\nfor models b6.13 and b6.14.\") +\n",
    "  theme_classic() +\n",
    "  theme(text = element_text(family = \"Courier\"),\n",
    "        panel.background = element_rect(fill = alpha(carto_pal(7, \"BurgYl\")[3], 1/4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_combined %>%\n",
    "  ggplot(aes(x = dif, y = 0)) +\n",
    "  geom_halfeyeh(fill  = carto_pal(7, \"BurgYl\")[5], \n",
    "                color = carto_pal(7, \"BurgYl\")[7],\n",
    "                point_interval = median_qi, .width = .95) +\n",
    "  scale_y_continuous(NULL, breaks = NULL) +\n",
    "  labs(x        = expression(paste(Delta, italic(\"R\")^{2})),\n",
    "       subtitle = \"This is how much more variance, in\\nterms of %, model b6.14 explained\\ncompared to model b6.13.\") +\n",
    "  theme_classic() +\n",
    "  theme(text = element_text(family = \"Courier\"),\n",
    "        panel.background = element_rect(fill = alpha(carto_pal(7, \"BurgYl\")[3], 1/4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interation between variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install.packages(\"ggthemes\", dependencies = T)\n",
    "library(ggthemes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into countries in Africa and not in Africa\n",
    "d.A1 <-\n",
    "  dd %>%\n",
    "  filter(cont_africa == 1)\n",
    "\n",
    "d.A0 <-\n",
    "  dd %>%\n",
    "  filter(cont_africa == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b7.1 <-\n",
    "  brm(data = d.A1, family = gaussian,\n",
    "      log_gdp ~ 1 + rugged,\n",
    "      prior = c(prior(normal(8, 100), class = Intercept),\n",
    "                prior(normal(0, 1), class = b),\n",
    "                prior(uniform(0, 10), class = sigma)),\n",
    "      iter = 2000, warmup = 1000, chains = 4, cores = 4,\n",
    "      seed = 7)\n",
    "\n",
    "b7.2 <-\n",
    "  update(b7.1, \n",
    "         newdata = d.A0)\n",
    "nd <- \n",
    "  tibble(rugged = seq(from = 0, to = 6.3, length.out = 30))\n",
    "\n",
    "f_b7.1 <-\n",
    "  fitted(b7.1, newdata = nd) %>%\n",
    "  as_tibble() %>%\n",
    "  bind_cols(nd)\n",
    "\n",
    "f_b7.2 <-\n",
    "  fitted(b7.2, newdata = nd) %>%\n",
    "  as_tibble() %>%\n",
    "  bind_cols(nd)\n",
    "\n",
    "# here we'll put both in a single data object, with `f_b7.1` stacked atop `f_b7.2`\n",
    "f <-\n",
    "  full_join(f_b7.1, f_b7.2) %>%\n",
    "  mutate(cont_africa = rep(c(\"Africa\", \"not Africa\"), each = 30))\n",
    "\n",
    "dd %>%\n",
    "  mutate(cont_africa = ifelse(cont_africa == 1, \"Africa\", \"not Africa\")) %>%\n",
    "  \n",
    "  ggplot(aes(x = rugged)) +\n",
    "  geom_smooth(data = f,\n",
    "              aes(y = Estimate, ymin = Q2.5, ymax = Q97.5,\n",
    "                  fill = cont_africa, color = cont_africa),\n",
    "              stat = \"identity\", \n",
    "              alpha = 1/4, size = 1/2) +\n",
    "  geom_point(aes(y = log_gdp, color = cont_africa),\n",
    "             size = 2/3) +\n",
    "  scale_colour_pander() +\n",
    "  scale_fill_pander() +\n",
    "  scale_x_continuous(\"Terrain Ruggedness Index\", expand = c(0, 0)) +\n",
    "  ylab(\"log GDP from year 2000\") +\n",
    "  theme_pander() + \n",
    "  theme(text = element_text(family = \"Times\"),\n",
    "        legend.position = \"none\") +\n",
    "  facet_wrap(~cont_africa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding dummy varialbe in level\n",
    "b7.3 <-\n",
    "  update(b7.1,\n",
    "         newdata = dd)\n",
    "#Now well add the dummy.\n",
    "\n",
    "b7.4 <-\n",
    "  update(b7.3,\n",
    "         newdata = dd,\n",
    "         formula = log_gdp ~ 1 + rugged + cont_africa) \n",
    "b7.3 <- add_criterion(b7.3, c(\"loo\", \"waic\"))\n",
    "b7.4 <- add_criterion(b7.4, c(\"loo\", \"waic\"))\n",
    "b7.3 <- add_criterion(b7.3, c(\"loo\", \"waic\"))\n",
    "b7.4 <- add_criterion(b7.4, c(\"loo\", \"waic\"))\n",
    "loo_compare(b7.3, b7.4,\n",
    "            criterion = \"loo\")\n",
    "\n",
    "\n",
    "model_weights(b7.3, b7.4,\n",
    "              weights = \"waic\") %>% \n",
    "  round(digits = 3)\n",
    "nd <- \n",
    "  tibble(rugged      = seq(from = 0, to = 6.3, length.out = 30) %>% \n",
    "           rep(., times = 2),\n",
    "         cont_africa = rep(0:1, each = 30))\n",
    "\n",
    "f <-\n",
    "  fitted(b7.4, newdata = nd) %>%\n",
    "  as_tibble() %>%\n",
    "  bind_cols(nd) %>%\n",
    "  mutate(cont_africa = ifelse(cont_africa == 1, \"Africa\", \"not Africa\"))\n",
    "\n",
    "dd %>%\n",
    "  mutate(cont_africa = ifelse(cont_africa == 1, \"Africa\", \"not Africa\")) %>%\n",
    "  \n",
    "ggplot(aes(x = rugged)) +\n",
    "  geom_smooth(data = f,\n",
    "              aes(y = Estimate, ymin = Q2.5, ymax = Q97.5,\n",
    "                  fill = cont_africa, color = cont_africa),\n",
    "              stat = \"identity\", \n",
    "              alpha = 1/4, size = 1/2) +\n",
    "  geom_point(aes(y = log_gdp, color = cont_africa),\n",
    "             size = 2/3) +\n",
    "  scale_colour_pander() +\n",
    "  scale_fill_pander() +\n",
    "  scale_x_continuous(\"Terrain Ruggedness Index\", expand = c(0, 0)) +\n",
    "  ylab(\"log GDP from year 2000\") +\n",
    "  theme_pander() + \n",
    "  theme(text = element_text(family = \"Times\"),\n",
    "        legend.position  = c(.69, .94),\n",
    "        legend.title     = element_blank(),\n",
    "        legend.direction = \"horizontal\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "\\text{log_gdp}_i & \\sim \\text{Normal} (\\mu_i, \\sigma) \\\\\n",
    "\\mu_i    & = \\alpha + \\gamma_i \\text{rugged}_i + \\beta_2 \\text{cont_africa}_i \\\\\n",
    "\\gamma_i & = \\beta_1 + \\beta_3 \\text{cont_africa}_i\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "\\text{log_gdp}_i & \\sim \\text{Normal} (\\mu_i, \\sigma) \\\\\n",
    "\\mu_i & = \\alpha + \\beta_1 \\text{rugged}_i + \\beta_2 \\text{cont_africa}_i + \\beta_3 \\text{rugged}_i \\times \\text{cont_africa}_i\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b7.5 <-\n",
    "  update(b7.4,\n",
    "         formula = log_gdp ~ 1 + rugged*cont_africa) \n",
    "b7.5 <- add_criterion(b7.5, c(\"loo\", \"waic\"))\n",
    "\n",
    "l <- loo_compare(b7.3, b7.4, b7.5,\n",
    "                 criterion = \"loo\")\n",
    "\n",
    "print(l, simplify = F)\n",
    "b7.5b <-\n",
    "  update(b7.5,\n",
    "         formula = log_gdp ~ 1 + rugged + cont_africa + rugged:cont_africa) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting the interaction\n",
    "nd <- \n",
    "  tibble(rugged      = seq(from = 0, to = 6.3, length.out = 30) %>% \n",
    "           rep(., times = 2),\n",
    "         cont_africa = rep(0:1, each = 30))\n",
    "f <-\n",
    "  fitted(b7.5, newdata = nd) %>%  # we can use the same `nd` data from last time\n",
    "  as_tibble() %>%\n",
    "  bind_cols(nd) %>%\n",
    "  mutate(cont_africa = ifelse(cont_africa == 1, \"Africa\", \"not Africa\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "\\text{blooms}_i & \\sim \\text{Normal} (\\mu_i, \\sigma) \\\\\n",
    "\\mu_i   & = \\alpha + \\beta_1 \\text{water}_i + \\beta_2 \\text{shade}_i \\\\\n",
    "\\alpha  & \\sim \\text{Normal} (0, 100) \\\\\n",
    "\\beta_1 & \\sim \\text{Normal} (0, 100) \\\\\n",
    "\\beta_2 & \\sim \\text{Normal} (0, 100) \\\\\n",
    "\\sigma  & \\sim \\text{Uniform} (0, 100)\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "\\text{blooms}_i & \\sim \\text{Normal} (\\mu_i, \\sigma) \\\\\n",
    "\\mu_i   & = \\alpha + \\beta_1 \\text{water} + \\beta_2 \\text{shade}_i + \\beta_3 \\text{water}_i \\times \\text{shade}_i \\\\\n",
    "\\alpha  & \\sim \\text{Normal} (0, 100) \\\\\n",
    "\\beta_1 & \\sim \\text{Normal} (0, 100) \\\\\n",
    "\\beta_2 & \\sim \\text{Normal} (0, 100) \\\\\n",
    "\\beta_3 & \\sim \\text{Normal} (0, 100) \\\\\n",
    "\\sigma  & \\sim \\text{Uniform} (0, 100)\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b7.6 <-\n",
    "  brm(data = d, family = gaussian,\n",
    "      blooms ~ 1 + water + shade,\n",
    "      prior = c(prior(normal(0, 100), class = Intercept),\n",
    "                prior(normal(0, 100), class = b),\n",
    "                prior(uniform(0, 100), class = sigma)),\n",
    "      iter = 2000, warmup = 1000, cores = 4, chains = 4,\n",
    "      seed = 7)\n",
    "b7.7 <- \n",
    "  update(b7.6, \n",
    "         formula = blooms ~ 1 + water + shade + water:shade)\n",
    "b7.6 <-\n",
    "  update(b7.6,\n",
    "         prior = c(prior(normal(0, 100), class = Intercept),\n",
    "                   prior(normal(0, 100), class = b),\n",
    "                   prior(cauchy(0, 10), class = sigma)),\n",
    "         control = list(adapt_delta = 0.9),\n",
    "         seed = 7)\n",
    "b7.7 <- \n",
    "  update(b7.6, \n",
    "         formula = blooms ~ 1 + water + shade + water:shade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior_summary(b7.6) %>% round(digits = 2)\n",
    "b7.6 <- add_criterion(b7.6, \"waic\")\n",
    "b7.7 <- add_criterion(b7.7, \"waic\")\n",
    "\n",
    "w <- loo_compare(b7.6, b7.7, criterion = \"waic\")\n",
    "\n",
    "print(w, simplify = F)\n",
    "d <-\n",
    "  d %>%\n",
    "  mutate(shade_c = shade - mean(shade),\n",
    "         water_c = water - mean(water))\n",
    "b7.8 <-\n",
    "  brm(data = d, family = gaussian,\n",
    "      blooms ~ 1 + water_c + shade_c,\n",
    "      prior = c(prior(normal(130, 100), class = Intercept),\n",
    "                prior(normal(0, 100), class = b),\n",
    "                prior(cauchy(0, 10), class = sigma)),\n",
    "      iter = 2000, warmup = 1000, chains = 4, cores = 4,\n",
    "      control = list(adapt_delta = 0.9),\n",
    "      seed = 7)\n",
    "\n",
    "b7.9 <- \n",
    "  update(b7.8, \n",
    "         formula = blooms ~ 1 + water_c + shade_c + water_c:shade_c)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "brms has marginal_effects() as a convenient way to look at simple effects and two-way interations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b7.3$formula\n",
    "marginal_effects(b7.3)\n",
    "plot(marginal_effects(b7.3), points = T)\n",
    "plot(marginal_effects(b7.3,\n",
    "                      spaghetti = T, nsamples = 200),\n",
    "     points = T,\n",
    "     point_args = c(alpha = 1/2, size = 1))\n",
    "b7.4$formula\n",
    "marginal_effects(b7.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MCMC (HMC Dynamic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "post <- posterior_samples(b8.1)\n",
    "str(post)\n",
    "pairs(b8.1,\n",
    "      off_diag_args = list(size = 1/5, alpha = 1/5))\n",
    "library(GGally)\n",
    "post %>%\n",
    "  select(b_Intercept:sigma) %>%\n",
    "  ggpairs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_diag <- function(data, mapping, ...){\n",
    "  ggplot(data = data, mapping = mapping) + \n",
    "    geom_density(fill = \"grey50\")\n",
    "}\n",
    "\n",
    "my_lower <- function(data, mapping, ...){\n",
    "  ggplot(data = data, mapping = mapping) + \n",
    "    geom_point(shape = 1, size = 1/2, alpha = 1/6)\n",
    "  }\n",
    "\n",
    "post %>%\n",
    "  select(b_Intercept:sigma) %>%\n",
    "\n",
    "  ggpairs(diag  = list(continuous = my_diag),\n",
    "          lower = list(continuous = my_lower)) +\n",
    "  labs(subtitle = \"My custom pairs plot\") +\n",
    "  theme_ipsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(b8.1)\n",
    "library(bayesplot)\n",
    "\n",
    "post <- posterior_samples(b8.1, add_chain = T)\n",
    "\n",
    "mcmc_trace(post[, c(1:5, 7)],  # we need to include column 7 because it contains the chain info \n",
    "           facet_args = list(ncol = 3), \n",
    "           size = .15) +\n",
    "  labs(title = \"My custom trace plots\") +\n",
    "  scale_color_ipsum() +\n",
    "  theme_ipsum() +\n",
    "  theme(legend.position = c(.95, .2))\n",
    "\n",
    "mcmc_acf(post, \n",
    "         pars = c(\"b_Intercept\", \"b_rugged\", \"b_cont_africa\", \"b_rugged:cont_africa\", \"sigma\"),\n",
    "         lags = 5) +\n",
    "  scale_color_ipsum() +\n",
    "  theme_ipsum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brms::stancode(b8.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If all you want are posterior means, it doesnt take many samples at all to get very good estimates. Even a couple hundred samples will do. But if you care about the exact shape in the extreme tails of the posterior, the 99th percentile or so, then youll need many many more. So there is no universally useful number of samples to aim for. In most typical regression applications, you can get a very good estimate of the posterior mean with as few as 200 effective samples. And if the posterior is approximately Gaussian, then all you need in addition is a good estimate of the variance, which can be had with one order of magnitude more, in most cases. For highly skewed posteriors, youll have to think more about which region of the distribution interests you."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The default diagnostic output from Stan includes two metrics, n_eff and Rhat. The first is a measure of the effective number of samples. The second is the Gelman-Rubin convergence diagnostic,  \n",
    "^\n",
    "R\n",
    " . When n_eff is much lower than the actual number of iterations (minus warmup) of your chains, it means the chains are inefficient, but possibly still okay. When Rhat is above 1.00, it usually indicates that the chain has not yet converged, and probably you shouldnt trust the samples. If you draw more iterations, it could be fine, or it could never converge. See the Stan user manual for more details. Its important however not to rely too much on these diagnostics. Like all heuristics, there are cases in which they provide poor advice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "p(x|x_0, \\gamma) = \\Bigg ( \\pi \\gamma \\Bigg [ 1 + \\Big ( \\frac{x - x_0}{\\gamma} \\Big ) ^2 \\Bigg ] \\Bigg ) ^{-1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generalized Linear model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "y_i         & \\sim \\text{Some distribution} (\\theta_i, \\phi) \\\\\n",
    "f(\\theta_i) & = \\alpha + \\beta x_i\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "y_i & \\sim \\text{Binomial}(n, p_i)\\\\\n",
    "\\text{logit}(p_i) & = \\alpha+\\beta x_i \n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(9)\n",
    "(\n",
    "  d <-\n",
    "  tibble(x = rep(0:1, each = 100)) %>% \n",
    "  mutate(y = rnorm(n = n(), mean = 100, sd = 10 + x * 10))\n",
    "  )\n",
    "library(tidybayes)\n",
    "\n",
    "d %>% \n",
    "  mutate(x = x %>% as.character()) %>% \n",
    "  \n",
    "  ggplot(aes(x = y, y = x, fill = x)) +\n",
    "  geom_halfeyeh(color = ghibli_palette(\"KikiMedium\")[2],\n",
    "                point_interval = mean_qi, .width = .68) +\n",
    "  scale_fill_manual(values = c(ghibli_palette(\"KikiMedium\")[4],\n",
    "                                   ghibli_palette(\"KikiMedium\")[6])) +\n",
    "  theme(panel.grid       = element_blank(),\n",
    "        axis.ticks.y     = element_blank(),\n",
    "        legend.position  = \"none\",\n",
    "        panel.background = element_rect(fill = ghibli_palette(\"KikiMedium\")[7]))\n",
    "\n",
    "b9.1 <- \n",
    "  brm(data = d,\n",
    "      family = gaussian,\n",
    "      bf(y ~ 1, sigma ~ 1 + x),\n",
    "      prior = c(prior(normal(100, 10), class = Intercept),\n",
    "                prior(normal(0, 10),   class = Intercept, dpar = sigma),\n",
    "                prior(normal(0, 10),   class = b,         dpar = sigma)),\n",
    "      seed = 9)\n",
    "\n",
    "print(b9.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we get an intercept for both  \n",
    "\n",
    "  and  \n",
    "\n",
    " , with the intercept for sigma identified as sigma_Intercept. And note the coefficient for  \n",
    "\n",
    "  was named sigma_x. Also notice the scale the sigma_ coefficients are on. These are not in the original metric, but rather based on log(). You can confirm that by the second line of the print() output: Links: mu = identity; sigma = log. So if you want to get a sense of the effects of x on the  \n",
    "\n",
    "  for y, you have to exponentiate the formula. Here well do so with the posterior_samples()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "post <- posterior_samples(b9.1)\n",
    "\n",
    "head(post)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "\\text{pulled_left}_i & \\sim \\text{Binomial} (1, p_i) \\\\\n",
    "\\text{logit} (p_i)    & = \\alpha \\\\\n",
    "\\alpha                & \\sim \\text{Normal} (0, 10)\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b10.1 <-\n",
    "  brm(data = d, family = binomial,\n",
    "      pulled_left | trials(1) ~ 1,\n",
    "      prior(normal(0, 10), class = Intercept),\n",
    "      seed = 10)\n",
    "fixef(b10.1) %>%\n",
    "  round(digits = 2)\n",
    "#The brms::inv_logit_scaled() function will be our alternative to the logistic() function in rethinking.\n",
    "c(.18, .46) %>%\n",
    "  inv_logit_scaled()\n",
    "fixef(b10.1) %>%\n",
    "  inv_logit_scaled()\n",
    "b10.2 <-\n",
    "  brm(data = d, family = binomial,\n",
    "      pulled_left | trials(1) ~ 1 + prosoc_left,\n",
    "      prior = c(prior(normal(0, 10), class = Intercept),\n",
    "                prior(normal(0, 10), class = b)),\n",
    "      seed = 10)\n",
    "\n",
    "b10.3 <-\n",
    "  update(b10.2,\n",
    "         newdata = d,\n",
    "         formula = pulled_left | trials(1) ~ 1 + prosoc_left + condition:prosoc_left)\n",
    "\n",
    "b10.1 <- add_criterion(b10.1, \"waic\")\n",
    "b10.2 <- add_criterion(b10.2, \"waic\")\n",
    "b10.3 <- add_criterion(b10.3, \"waic\")\n",
    "#Compare them with the loo_compare() and make sure to add the criterion = \"waic\" argument.\n",
    "w <- loo_compare(b10.1, b10.2, b10.3, criterion = \"waic\")\n",
    "print(w, simplify = F)\n",
    "cbind(waic_diff = w[, 1] * -2,\n",
    "      se        = w[, 2] *  2) %>% \n",
    "  round(digits = 2)\n",
    "\n",
    "# visuzlization\n",
    "# install.packages(\"wesanderson\", dependencies = T)\n",
    "library(wesanderson)\n",
    "\n",
    "wes_palette(\"Moonrise2\")\n",
    "wes_palette(\"Moonrise2\")[1:4]\n",
    "library(ggthemes)\n",
    "library(bayesplot)\n",
    "\n",
    "theme_set(theme_default() + \n",
    "            theme_tufte() +\n",
    "            theme(plot.background = element_rect(fill  = wes_palette(\"Moonrise2\")[3],\n",
    "                                                 color = wes_palette(\"Moonrise2\")[3])))\n",
    "\n",
    "w %>%\n",
    "  data.frame() %>% \n",
    "  rownames_to_column(var = \"model\") %>% \n",
    "  \n",
    "  ggplot() +\n",
    "  geom_pointrange(aes(x = reorder(model, -waic), y = waic,\n",
    "                      ymin = waic - se_waic,\n",
    "                      ymax = waic + se_waic,\n",
    "                      color = model),\n",
    "                  shape = 16) +\n",
    "  scale_color_manual(values = wes_palette(\"Moonrise2\")[c(1:2, 4)]) +\n",
    "  coord_flip() +\n",
    "  labs(x = NULL, y = NULL,\n",
    "       title = \"WAIC\") +\n",
    "  theme(axis.ticks.y    = element_blank(),\n",
    "        legend.position = \"none\")\n",
    "\n",
    "model_weights(b10.1, b10.2, b10.3, \n",
    "              weights = \"waic\")\n",
    "\n",
    "# the combined `fitted()` results of the three models weighted by their WAICs\n",
    "ppa <- \n",
    "  pp_average(b10.1, b10.2, b10.3,\n",
    "             weights = \"waic\",\n",
    "             method = \"fitted\") %>%\n",
    "  as_tibble() %>% \n",
    "  bind_cols(b10.3$data) %>% \n",
    "  distinct(Estimate, Q2.5, Q97.5, condition, prosoc_left) %>% \n",
    "  mutate(x_axis = str_c(prosoc_left, condition, sep = \"/\")) %>%\n",
    "  mutate(x_axis = factor(x_axis, levels = c(\"0/0\", \"1/0\", \"0/1\", \"1/1\"))) %>% \n",
    "  rename(pulled_left = Estimate)\n",
    "\n",
    "# the empirically-based summaries\n",
    "d_plot <-\n",
    "  d %>%\n",
    "  group_by(actor, condition, prosoc_left) %>%\n",
    "  summarise(pulled_left = mean(pulled_left)) %>%\n",
    "  mutate(x_axis = str_c(prosoc_left, condition, sep = \"/\")) %>%\n",
    "  mutate(x_axis = factor(x_axis, levels = c(\"0/0\", \"1/0\", \"0/1\", \"1/1\")))\n",
    "\n",
    "# the plot\n",
    "ppa %>% \n",
    "  ggplot(aes(x = x_axis)) +\n",
    "  geom_smooth(aes(y = pulled_left, ymin = Q2.5, ymax = Q97.5, group = 0),\n",
    "              stat = \"identity\",\n",
    "              fill = wes_palette(\"Moonrise2\")[2], color = \"black\", \n",
    "              alpha = 1, size = 1/2) +\n",
    "  geom_line(data = d_plot,\n",
    "            aes(y = pulled_left, group = actor),\n",
    "            color = wes_palette(\"Moonrise2\")[1], size = 1/3) +\n",
    "  scale_x_discrete(expand = c(.03, .03)) +\n",
    "  coord_cartesian(ylim = 0:1) +\n",
    "  labs(x = \"prosoc_left/condition\",\n",
    "       y = \"proportion pulled left\") +\n",
    "  theme(axis.ticks.x = element_blank())\n",
    "\n",
    "# this helps us set our custom color scheme\n",
    "color_scheme_set(c(wes_palette(\"Moonrise2\")[3], \n",
    "                   wes_palette(\"Moonrise2\")[1], \n",
    "                   wes_palette(\"Moonrise2\")[2], \n",
    "                   wes_palette(\"Moonrise2\")[2], \n",
    "                   wes_palette(\"Moonrise2\")[1], \n",
    "                   wes_palette(\"Moonrise2\")[1]))\n",
    "\n",
    "# the actual plot\n",
    "mcmc_pairs(x = posterior_samples(b10.3),\n",
    "           pars = c(\"b_Intercept\", \"b_prosoc_left\", \"b_prosoc_left:condition\"),\n",
    "           off_diag_args = list(size = 1/10, alpha = 1/6),\n",
    "           diag_fun = \"dens\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "\\text{pulled_left}_i & \\sim \\text{Binomial} (1, p_i) \\\\\n",
    "\\text{logit} (p_i)    & = \\alpha_{\\text{actor}} + (\\beta_1 + \\beta_2 \\text{condition}_i) \\text{prosoc_left}_i \\\\\n",
    "\\alpha_{\\text{actor}} & \\sim \\text{Normal} (0, 10) \\\\\n",
    "\\beta_1               & \\sim \\text{Normal} (0, 10) \\\\\n",
    "\\beta_2               & \\sim \\text{Normal} (0, 10)\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b10.4 <-\n",
    "  brm(data = d, family = binomial,\n",
    "      pulled_left | trials(1) ~ 0 + factor(actor) + prosoc_left + condition:prosoc_left ,\n",
    "      prior(normal(0, 10), class = b),\n",
    "      iter = 2500, warmup = 500, chains = 2, cores = 2,\n",
    "      control = list(adapt_delta = 0.9),\n",
    "      seed = 10)\n",
    "\n",
    "d %>%\n",
    "  distinct(actor)\n",
    "print(b10.4)\n",
    "post <- posterior_samples(b10.4)\n",
    " \n",
    "post %>%\n",
    "  glimpse()\n",
    "\n",
    "b10.5 <-\n",
    "  brm(data = d_aggregated, family = binomial,\n",
    "      x | trials(18) ~ 1 + prosoc_left + condition:prosoc_left,\n",
    "      prior = c(prior(normal(0, 10), class = Intercept),\n",
    "                prior(normal(0, 10), class = b)),\n",
    "      iter = 2500, warmup = 500, cores = 2, chains = 2, \n",
    "      seed = 10)\n",
    "library(broom)\n",
    "\n",
    "# wrangle\n",
    "tibble(model  = str_c(\"b10.\", c(3, 5))) %>% \n",
    "  mutate(fit  = map(model, get)) %>% \n",
    "  mutate(tidy = map(fit, tidy)) %>% \n",
    "  unnest(tidy) %>% \n",
    "  filter(term != \"lp__\") %>% \n",
    "  \n",
    "  # plot\n",
    "  ggplot() +\n",
    "  geom_pointrange(aes(x = model, y = estimate,\n",
    "                      ymin = lower,\n",
    "                      ymax = upper,\n",
    "                      color = term),\n",
    "                  shape = 16) +\n",
    "  scale_color_manual(values = wes_palette(\"Moonrise2\")[c(1:2, 4)]) +\n",
    "  coord_flip() +\n",
    "  labs(x = NULL, y = NULL) +\n",
    "  theme(axis.ticks.y    = element_blank(),\n",
    "        legend.position = \"none\") +\n",
    "  facet_wrap(~term, ncol = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "n_{\\text{admit}_i}   & \\sim \\text{Binomial} (n_i, p_i) \\\\\n",
    "\\text{logit} (p_i)   & = \\alpha_{\\text{dept}_i} + \\beta \\text{male}_i \\\\\n",
    "\\alpha_{\\text{dept}} & \\sim \\text{Normal} (0, 10) \\\\\n",
    "\\beta                & \\sim \\text{Normal} (0, 10)\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in brm(data = d, family = binomial, admit | trials(applications) ~ : could not find function \"brm\"\n",
     "output_type": "error",
     "traceback": [
      "Error in brm(data = d, family = binomial, admit | trials(applications) ~ : could not find function \"brm\"\nTraceback:\n"
     ]
    }
   ],
   "source": [
    "b10.8 <-\n",
    "  brm(data = d, family = binomial,\n",
    "      admit | trials(applications) ~ 0 + dept,\n",
    "      prior(normal(0, 10), class = b),\n",
    "      iter = 2500, warmup = 500, cores = 2, chains = 2,\n",
    "      seed = 10) \n",
    "\n",
    "b10.9 <-\n",
    "  update(b10.8,\n",
    "         newdata = d,\n",
    "         formula = admit | trials(applications) ~ 0 + dept + male)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.good <-\n",
    "  brm(data = list(y = y, x = x), family = binomial,\n",
    "      y ~ 1 + x,\n",
    "      prior = c(prior(normal(0, 10), class = Intercept),\n",
    "                prior(normal(0, 10), class = b)),\n",
    "      seed = 10) \n",
    "\n",
    "pairs(b.good,\n",
    "      off_diag_args = list(size = 1/10, alpha = 1/6))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "y_i                    & \\sim \\text{Poisson} (\\lambda_i) \\\\\n",
    "\\text{log} (\\lambda_i) & = \\alpha + \\beta x_i\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "\\text{total_tools}_i   & \\sim \\text{Poisson} (\\lambda_i) \\\\\n",
    "\\text{log} (\\lambda_i) & = \\alpha + \\beta_1 \\text{log_pop}_i + \\beta_2 \\text{contact_high}_i + \\beta_3 \\text{contact_high}_i \\times \\text{log_pop}_i \\\\\n",
    "\\alpha  & \\sim \\text{Normal} (0, 100) \\\\\n",
    "\\beta_1 & \\sim \\text{Normal} (0, 1) \\\\\n",
    "\\beta_2 & \\sim \\text{Normal} (0, 1) \\\\\n",
    "\\beta_3 & \\sim \\text{Normal} (0, 1)\n",
    "\\end{align*}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b10.10 <-\n",
    "  brm(data = d, family = poisson,\n",
    "      total_tools ~ 1 + log_pop + contact_high + contact_high:log_pop,\n",
    "      prior = c(prior(normal(0, 100), class = Intercept),\n",
    "                prior(normal(0, 1), class = b)),\n",
    "      iter = 3000, warmup = 1000, chains = 4, cores = 4,\n",
    "      seed = 10) \n",
    "post <-\n",
    "  posterior_samples(b10.10)\n",
    "\n",
    "post %>%\n",
    "  select(-lp__) %>% \n",
    "  rename(b_interaction = `b_log_pop:contact_high`) %>%\n",
    "  psych::lowerCor()\n",
    "\n",
    "# we'll set a renewed color theme\n",
    "color_scheme_set(c(wes_palette(\"Moonrise2\")[2],\n",
    "                   wes_palette(\"Moonrise2\")[1], \n",
    "                   wes_palette(\"Moonrise2\")[4], \n",
    "                   wes_palette(\"Moonrise2\")[2], \n",
    "                   wes_palette(\"Moonrise2\")[1], \n",
    "                   wes_palette(\"Moonrise2\")[1]))\n",
    "\n",
    "post %>%\n",
    "  select(-lp__) %>% \n",
    "  rename(b_interaction = `b_log_pop:contact_high`) %>%\n",
    "\n",
    "  mcmc_intervals(prob = .5, prob_outer = .95) +\n",
    "  theme(axis.ticks.y = element_blank(),\n",
    "        axis.text.y  = element_text(hjust = 0))\n",
    "# no interaction\n",
    "b10.11 <- \n",
    "  update(b10.10, formula = total_tools ~ 1 + log_pop + contact_high)\n",
    "\n",
    "# no contact rate\n",
    "b10.12 <-\n",
    "  update(b10.10, formula = total_tools ~ 1 + log_pop)\n",
    "\n",
    "# no log-population\n",
    "b10.13 <-\n",
    "  update(b10.10, formula = total_tools ~ 1 + contact_high)\n",
    "\n",
    "# intercept only\n",
    "b10.14 <-\n",
    "  update(b10.10, formula = total_tools ~ 1,\n",
    "         seed = 10)\n",
    "b10.10 <- add_criterion(b10.10, criterion = \"waic\")\n",
    "b10.11 <- add_criterion(b10.11, criterion = \"waic\")\n",
    "b10.12 <- add_criterion(b10.12, criterion = \"waic\")\n",
    "b10.13 <- add_criterion(b10.13, criterion = \"waic\")\n",
    "b10.14 <- add_criterion(b10.14, criterion = \"waic\")\n",
    "# Now compare them.\n",
    "\n",
    "w <- loo_compare(b10.10, b10.11, b10.12, b10.13, b10.14, criterion = \"waic\")\n",
    "\n",
    "cbind(waic_diff = w[, 1] * -2,\n",
    "      se        = w[, 2] *  2) %>% \n",
    "  round(digits = 2)\n",
    "\n",
    "model_weights(b10.10, b10.11, b10.12, b10.13, b10.14, weights = \"waic\") %>% \n",
    "  round(digits = 2)\n",
    "\n",
    "w %>% \n",
    "  data.frame() %>% \n",
    "  rownames_to_column(var = \"model\") %>%\n",
    "  \n",
    "  ggplot(aes(x = reorder(model, -waic), \n",
    "             y    = waic,\n",
    "             ymin = waic - se_waic,\n",
    "             ymax = waic + se_waic,\n",
    "             color = model)) +\n",
    "  geom_pointrange(shape = 16, show.legend = F) +\n",
    "  scale_color_manual(values = wes_palette(\"Moonrise2\")[c(1, 2, 1, 1, 1)]) +\n",
    "  coord_flip() +\n",
    "  labs(x = NULL, y = NULL,\n",
    "       title = \"WAIC\") +\n",
    "  theme(axis.ticks.y    = element_blank())\n",
    "\n",
    "# this helps us set our custom color scheme\n",
    "color_scheme_set(c(wes_palette(\"Moonrise2\")[3], \n",
    "                   wes_palette(\"Moonrise2\")[1], \n",
    "                   wes_palette(\"Moonrise2\")[2], \n",
    "                   wes_palette(\"Moonrise2\")[2], \n",
    "                   wes_palette(\"Moonrise2\")[1], \n",
    "                   wes_palette(\"Moonrise2\")[1]))\n",
    "\n",
    "# the actual plot\n",
    "mcmc_pairs(x = posterior_samples(b10.10),\n",
    "           pars = c(\"b_Intercept\", \"b_log_pop\", \"b_contact_high\", \"b_log_pop:contact_high\"),\n",
    "           off_diag_args = list(size = 1/10, alpha = 1/10),\n",
    "           diag_fun = \"dens\")\n",
    "\n",
    "mcmc_pairs(x = posterior_samples(b10.10_c),\n",
    "           pars = c(\"b_Intercept\", \"b_log_pop_c\", \"b_contact_high\", \"b_log_pop_c:contact_high\"),\n",
    "           off_diag_args = list(size = 1/10, alpha = 1/10),\n",
    "           diag_fun = \"dens\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Categorical distirbution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b10.16 <-\n",
    "  brm(data = list(career = career), \n",
    "      family = categorical(link = logit),\n",
    "      career ~ 1,\n",
    "      prior(normal(0, 5), class = Intercept),\n",
    "      iter = 2500, warmup = 500, cores = 2, chains = 2,\n",
    "      seed = 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# binomial model of overall admission probability\n",
    "b_binom <-\n",
    "  brm(data = d, family = binomial,\n",
    "      admit | trials(applications) ~ 1,\n",
    "      prior(normal(0, 100), class = Intercept),\n",
    "      iter = 2000, warmup = 1000, cores = 3, chains = 3,\n",
    "      seed = 10)\n",
    "\n",
    "# Poisson model of overall admission rate and rejection rate\n",
    "b_pois <-\n",
    "  brm(data = d %>%\n",
    "        mutate(rej = reject),  # 'reject' is a reserved word\n",
    "      family = poisson,\n",
    "      mvbind(admit, rej) ~ 1,\n",
    "      prior(normal(0, 100), class = Intercept),\n",
    "      iter = 2000, warmup = 1000, cores = 3, chains = 3,\n",
    "      seed = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ordered categorical model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "\"package 'ggplot2' is in use and will not be installed\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "package 'ggthemes' successfully unpacked and MD5 sums checked\n",
      "\n",
      "The downloaded binary packages are in\n",
      "\tC:\\Users\\hn93h\\AppData\\Local\\Temp\\Rtmps98ZbC\\downloaded_packages\n"
     ]
    }
   ],
   "source": [
    "install.packages('ggplot2')\n",
    "install.packages('ggthemes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "\"package 'ggthemes' was built under R version 3.6.2\""
     ]
    },
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>'#919636'</li>\n",
       "\t<li>'#524a3a'</li>\n",
       "\t<li>'#fffae1'</li>\n",
       "\t<li>'#5a5f37'</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item '\\#919636'\n",
       "\\item '\\#524a3a'\n",
       "\\item '\\#fffae1'\n",
       "\\item '\\#5a5f37'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. '#919636'\n",
       "2. '#524a3a'\n",
       "3. '#fffae1'\n",
       "4. '#5a5f37'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] \"#919636\" \"#524a3a\" \"#fffae1\" \"#5a5f37\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "'#fffae1'"
      ],
      "text/latex": [
       "'\\#fffae1'"
      ],
      "text/markdown": [
       "'#fffae1'"
      ],
      "text/plain": [
       "[1] \"#fffae1\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAAulBMVEUAAAAYFhEbHBAhHhck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",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "library(ggthemes)\n",
    "scales::show_col(canva_pal(\"Green fields\")(4))\n",
    "canva_pal(\"Green fields\")(4)\n",
    "canva_pal(\"Green fields\")(4)[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ggplot(data = d, aes(x = response, fill = ..x..)) +\n",
    "  geom_histogram(binwidth = 1/4, size = 0) +\n",
    "  scale_x_continuous(breaks = 1:7) +\n",
    "  scale_fill_gradient(low  = canva_pal(\"Green fields\")(4)[4],\n",
    "                      high = canva_pal(\"Green fields\")(4)[1]) +\n",
    "  theme_hc() +\n",
    "  theme(axis.ticks.x    = element_blank(),\n",
    "        plot.background = element_rect(fill = \"grey92\"),\n",
    "        legend.position = \"none\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d %>%\n",
    "  group_by(response) %>% \n",
    "  count() %>%\n",
    "  mutate(pr_k     = n / nrow(d)) %>% \n",
    "  ungroup() %>% \n",
    "  mutate(cum_pr_k = cumsum(pr_k)) %>% \n",
    "  \n",
    "  ggplot(aes(x = response, y = cum_pr_k, \n",
    "             fill = response)) +\n",
    "  geom_line(color = canva_pal(\"Green fields\")(4)[2]) +\n",
    "  geom_point(shape = 21, colour = \"grey92\", \n",
    "             size = 2.5, stroke = 1) +\n",
    "  scale_x_continuous(breaks = 1:7) +\n",
    "  scale_y_continuous(\"cumulative proportion\", breaks = c(0, .5, 1)) +\n",
    "  scale_fill_gradient(low  = canva_pal(\"Green fields\")(4)[4],\n",
    "                      high = canva_pal(\"Green fields\")(4)[1]) +\n",
    "  coord_cartesian(ylim = c(0, 1)) +\n",
    "  theme_hc() +\n",
    "  theme(axis.ticks.x    = element_blank(),\n",
    "        plot.background = element_rect(fill = \"grey92\"),\n",
    "        legend.position = \"none\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# McElreath's convenience function from page 335\n",
    "logit <- function(x) log(x / (1 - x))\n",
    "\n",
    "d %>%\n",
    "  group_by(response) %>% \n",
    "  count() %>%\n",
    "  mutate(pr_k     = n / nrow(d)) %>% \n",
    "  ungroup() %>% \n",
    "  mutate(cum_pr_k = cumsum(pr_k)) %>% \n",
    "  filter(response < 7) %>% \n",
    "  \n",
    "  # we can do the `logit()` conversion right in ggplot2\n",
    "  ggplot(aes(x = response, y = logit(cum_pr_k), \n",
    "             fill = response)) +\n",
    "  geom_line(color = canva_pal(\"Green fields\")(4)[2]) +\n",
    "  geom_point(shape = 21, colour = \"grey92\", \n",
    "             size = 2.5, stroke = 1) +\n",
    "  scale_x_continuous(breaks = 1:7) +\n",
    "  scale_fill_gradient(low  = canva_pal(\"Green fields\")(4)[4],\n",
    "                      high = canva_pal(\"Green fields\")(4)[1]) +\n",
    "  coord_cartesian(xlim = c(1, 7)) +\n",
    "  ylab(\"log-cumulative-odds\") +\n",
    "  theme_hc() +\n",
    "  theme(axis.ticks.x    = element_blank(),\n",
    "        plot.background = element_rect(fill = \"grey92\"),\n",
    "        legend.position = \"none\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_plot <-\n",
    "  d %>%\n",
    "  group_by(response) %>% \n",
    "  count() %>%\n",
    "  mutate(pr_k     = n / nrow(d)) %>% \n",
    "  ungroup() %>% \n",
    "  mutate(cum_pr_k = cumsum(pr_k)) \n",
    "\n",
    "ggplot(data = d_plot,\n",
    "       aes(x = response, y = cum_pr_k,\n",
    "           color = cum_pr_k, fill = cum_pr_k)) +\n",
    "  geom_line(color = canva_pal(\"Green fields\")(4)[1]) +\n",
    "  geom_point(shape = 21, colour = \"grey92\", \n",
    "             size = 2.5, stroke = 1) +\n",
    "  geom_linerange(aes(ymin = 0, ymax = cum_pr_k),\n",
    "                 alpha = 1/2, color = canva_pal(\"Green fields\")(4)[1]) +\n",
    "  # there must be more elegant ways to do this part\n",
    "  geom_linerange(data = . %>% \n",
    "                   mutate(discrete_probability =\n",
    "                            ifelse(response == 1, cum_pr_k,\n",
    "                                   cum_pr_k - pr_k)),\n",
    "                 aes(x    = response + .025,\n",
    "                     ymin = ifelse(response == 1, 0, discrete_probability), \n",
    "                     ymax = cum_pr_k),\n",
    "                 color = \"black\") +\n",
    "  geom_text(data = tibble(text     = 1:7,\n",
    "                          response = seq(from = 1.25, to = 7.25, by = 1),\n",
    "                          cum_pr_k = d_plot$cum_pr_k - .065),\n",
    "            aes(label = text),\n",
    "            size = 4) +\n",
    "  scale_x_continuous(breaks = 1:7) +\n",
    "  scale_y_continuous(\"cumulative proportion\", breaks = c(0, .5, 1)) +\n",
    "  scale_fill_gradient(low  = canva_pal(\"Green fields\")(4)[4],\n",
    "                      high = canva_pal(\"Green fields\")(4)[1]) +\n",
    "  scale_color_gradient(low  = canva_pal(\"Green fields\")(4)[4],\n",
    "                       high = canva_pal(\"Green fields\")(4)[1]) +\n",
    "  coord_cartesian(ylim = c(0, 1)) +\n",
    "  theme_hc() +\n",
    "  theme(axis.ticks.x    = element_blank(),\n",
    "        plot.background = element_rect(fill = \"grey92\"),\n",
    "        legend.position = \"none\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align*} \n",
    "R_i & \\sim \\text{Ordered} (\\mathbf p) \\\\\n",
    "\\text{logit} (p_k) & = \\alpha_k \\\\\n",
    "\\alpha_k           & \\sim \\text{Normal} (0, 10)\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the start values\n",
    "inits <- list(`Intercept[1]` = -2,\n",
    "              `Intercept[2]` = -1,\n",
    "              `Intercept[3]` = 0,\n",
    "              `Intercept[4]` = 1,\n",
    "              `Intercept[5]` = 2,\n",
    "              `Intercept[6]` = 2.5)\n",
    "\n",
    "inits_list <- list(inits, inits)\n",
    "\n",
    "b11.1 <- \n",
    "  brm(data = d, family = cumulative,\n",
    "      response ~ 1,\n",
    "      prior(normal(0, 10), class = Intercept),\n",
    "      iter = 2000, warmup = 1000, cores = 2, chains = 2,\n",
    "      inits = inits_list,  # here we add our start values\n",
    "      seed = 11)\n",
    "b11.1 %>% \n",
    "  fixef() %>% \n",
    "  inv_logit_scaled()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "\\text{log} \\frac{\\text{Pr} (y_i \\leq k)}{1 - \\text{Pr} (y_i \\leq k)} & = \\alpha_k - \\phi_i \\\\\n",
    "\\phi_i & = \\beta x_i\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MultiLevel Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "\\text{surv}_i        & \\sim \\text{Binomial} (n_i, p_i) \\\\\n",
    "\\text{logit} (p_i)   & = \\alpha_{\\text{tank}_i} \\\\\n",
    "\\alpha_{\\text{tank}} & \\sim \\text{Normal} (0, 5)\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b12.1 <- \n",
    "  brm(data = d, family = binomial,\n",
    "      surv | trials(density) ~ 0 + factor(tank),\n",
    "      prior(normal(0, 5), class = b),\n",
    "      iter = 2000, warmup = 500, chains = 4, cores = 4,\n",
    "      seed = 12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "\\text{surv}_i        & \\sim \\text{Binomial} (n_i, p_i) \\\\\n",
    "\\text{logit} (p_i)   & = \\alpha_{\\text{tank}_i} \\\\\n",
    "\\alpha_{\\text{tank}} & \\sim \\text{Normal} (\\alpha, \\sigma) \\\\\n",
    "\\alpha               & \\sim \\text{Normal} (0, 1) \\\\\n",
    "\\sigma               & \\sim \\text{HalfCauchy} (0, 1)\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\\begin{align*}\n",
    "\\text{surv}_i        & \\sim \\text{Binomial} (n_i, p_i) \\\\\n",
    "\\text{logit} (p_i)   & = \\alpha_{\\text{tank}_i} \\\\\n",
    "\\alpha_{\\text{tank}} & \\sim \\text{Normal} (\\alpha, \\sigma) \\\\\n",
    "\\alpha               & \\sim \\text{Normal} (0, 1) \\\\\n",
    "\\sigma               & \\sim \\text{HalfCauchy} (0, 1)\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The syntax for the varying effects follows the lme4 style, ( <varying parameter(s)> | <grouping variable(s)> )\n",
    " In this case (1 | tank) indicates only the intercept, 1, varies by tank. The extent to which parameters vary is controlled by the prior, prior(cauchy(0, 1), class = sd), which is parameterized in the standard deviation metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b12.2 <- \n",
    "  brm(data = d, family = binomial,\n",
    "      surv | trials(density) ~ 1 + (1 | tank),\n",
    "      prior = c(prior(normal(0, 1), class = Intercept),\n",
    "                prior(cauchy(0, 1), class = sd)),\n",
    "      iter = 4000, warmup = 1000, chains = 4, cores = 4,\n",
    "      seed = 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b12.1 <- add_criterion(b12.1, \"waic\")\n",
    "b12.2 <- add_criterion(b12.2, \"waic\")\n",
    "\n",
    "w <- loo_compare(b12.1, b12.2, criterion = \"waic\")\n",
    "\n",
    "print(w, simplify = F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cbind(waic_diff = w[, 1] * -2,\n",
    "      se        = w[, 2] *  2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b12.2.e <- \n",
    "  update(b12.2,\n",
    "         prior = c(prior(normal(0, 1), class = Intercept),\n",
    "                   prior(exponential(1), class = sd)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Varying intercepts are just regularized estimates, but adaptively regularized by estimating how diverse the clusters are while estimating the features of each cluster. This fact is not easy to grasp\n",
    "\n",
    "A major benefit of using varying effects estimates, instead of the empirical raw estimates, is that they provide more accurate estimates of the individual cluster (tank) intercepts. On average, the varying effects actually provide a better estimate of the individual tank (cluster) means. The reason that the varying intercepts provides better estimates is that they do a better job trading off underfitting and overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Complete pooling (i.e., a single- \n",
    "\n",
    "  model)\n",
    "No pooling (i.e., the single-level  \n",
    "\n",
    "tank\n",
    "i\n",
    "  model)\n",
    "Partial pooling (i.e., the multilevel model for which  \n",
    "\n",
    "tank\n",
    "\n",
    "Normal\n",
    "(\n",
    "\n",
    ",\n",
    "\n",
    ")\n",
    " )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "\\text{surv}_i        & \\sim \\text{Binomial} (n_i, p_i) \\\\\n",
    "\\text{logit} (p_i)   & = \\alpha_{\\text{pond}_i} \\\\\n",
    "\\alpha_{\\text{pond}} & \\sim \\text{Normal} (\\alpha, \\sigma) \\\\\n",
    "\\alpha               & \\sim \\text{Normal} (0, 1) \\\\\n",
    "\\sigma               & \\sim \\text{HalfCauchy} (0, 1)\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>pond</th><th scope=col>ni</th><th scope=col>true_a</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td> 1         </td><td> 5         </td><td>-0.82085139</td></tr>\n",
       "\t<tr><td> 2         </td><td> 5         </td><td> 3.76575421</td></tr>\n",
       "\t<tr><td> 3         </td><td> 5         </td><td>-0.03511672</td></tr>\n",
       "\t<tr><td> 4         </td><td> 5         </td><td> 0.01999213</td></tr>\n",
       "\t<tr><td> 5         </td><td> 5         </td><td>-1.59646315</td></tr>\n",
       "\t<tr><td> 6         </td><td> 5         </td><td> 0.99155593</td></tr>\n",
       "\t<tr><td> 7         </td><td> 5         </td><td> 0.92697693</td></tr>\n",
       "\t<tr><td> 8         </td><td> 5         </td><td> 0.45761715</td></tr>\n",
       "\t<tr><td> 9         </td><td> 5         </td><td> 1.24030417</td></tr>\n",
       "\t<tr><td>10         </td><td> 5         </td><td> 2.04202220</td></tr>\n",
       "\t<tr><td>11         </td><td> 5         </td><td> 0.23342063</td></tr>\n",
       "\t<tr><td>12         </td><td> 5         </td><td>-0.54082345</td></tr>\n",
       "\t<tr><td>13         </td><td> 5         </td><td> 0.23065024</td></tr>\n",
       "\t<tr><td>14         </td><td> 5         </td><td> 1.41792764</td></tr>\n",
       "\t<tr><td>15         </td><td> 5         </td><td> 1.17137564</td></tr>\n",
       "\t<tr><td>16         </td><td>10         </td><td> 0.34480362</td></tr>\n",
       "\t<tr><td>17         </td><td>10         </td><td> 3.18331873</td></tr>\n",
       "\t<tr><td>18         </td><td>10         </td><td> 1.91076841</td></tr>\n",
       "\t<tr><td>19         </td><td>10         </td><td> 2.16045226</td></tr>\n",
       "\t<tr><td>20         </td><td>10         </td><td> 0.96004228</td></tr>\n",
       "\t<tr><td>21         </td><td>10         </td><td> 1.73546212</td></tr>\n",
       "\t<tr><td>22         </td><td>10         </td><td> 4.41080219</td></tr>\n",
       "\t<tr><td>23         </td><td>10         </td><td> 2.91796868</td></tr>\n",
       "\t<tr><td>24         </td><td>10         </td><td> 0.94631113</td></tr>\n",
       "\t<tr><td>25         </td><td>10         </td><td>-0.13786726</td></tr>\n",
       "\t<tr><td>26         </td><td>10         </td><td> 0.99892276</td></tr>\n",
       "\t<tr><td>27         </td><td>10         </td><td> 1.10134151</td></tr>\n",
       "\t<tr><td>28         </td><td>10         </td><td> 1.59668389</td></tr>\n",
       "\t<tr><td>29         </td><td>10         </td><td> 1.61869984</td></tr>\n",
       "\t<tr><td>30         </td><td>10         </td><td> 1.94309708</td></tr>\n",
       "\t<tr><td>31         </td><td>25         </td><td> 2.41097175</td></tr>\n",
       "\t<tr><td>32         </td><td>25         </td><td> 4.50805365</td></tr>\n",
       "\t<tr><td>33         </td><td>25         </td><td> 0.58845703</td></tr>\n",
       "\t<tr><td>34         </td><td>25         </td><td>-0.20573824</td></tr>\n",
       "\t<tr><td>35         </td><td>25         </td><td> 0.84131490</td></tr>\n",
       "\t<tr><td>36         </td><td>25         </td><td> 0.67228797</td></tr>\n",
       "\t<tr><td>37         </td><td>25         </td><td> 1.81217627</td></tr>\n",
       "\t<tr><td>38         </td><td>25         </td><td> 0.68073116</td></tr>\n",
       "\t<tr><td>39         </td><td>25         </td><td> 2.59715799</td></tr>\n",
       "\t<tr><td>40         </td><td>25         </td><td>-0.10667680</td></tr>\n",
       "\t<tr><td>41         </td><td>25         </td><td> 1.55747635</td></tr>\n",
       "\t<tr><td>42         </td><td>25         </td><td>-0.33398934</td></tr>\n",
       "\t<tr><td>43         </td><td>25         </td><td> 2.26720194</td></tr>\n",
       "\t<tr><td>44         </td><td>25         </td><td>-0.99343848</td></tr>\n",
       "\t<tr><td>45         </td><td>25         </td><td> 0.93724452</td></tr>\n",
       "\t<tr><td>46         </td><td>35         </td><td> 2.07419888</td></tr>\n",
       "\t<tr><td>47         </td><td>35         </td><td>-0.06557992</td></tr>\n",
       "\t<tr><td>48         </td><td>35         </td><td> 1.68499679</td></tr>\n",
       "\t<tr><td>49         </td><td>35         </td><td> 2.49718004</td></tr>\n",
       "\t<tr><td>50         </td><td>35         </td><td> 0.66110133</td></tr>\n",
       "\t<tr><td>51         </td><td>35         </td><td> 1.33597263</td></tr>\n",
       "\t<tr><td>52         </td><td>35         </td><td> 1.23099414</td></tr>\n",
       "\t<tr><td>53         </td><td>35         </td><td> 2.08524087</td></tr>\n",
       "\t<tr><td>54         </td><td>35         </td><td> 4.43050226</td></tr>\n",
       "\t<tr><td>55         </td><td>35         </td><td>-0.17633509</td></tr>\n",
       "\t<tr><td>56         </td><td>35         </td><td> 2.50197816</td></tr>\n",
       "\t<tr><td>57         </td><td>35         </td><td> 2.20887462</td></tr>\n",
       "\t<tr><td>58         </td><td>35         </td><td>-0.57140920</td></tr>\n",
       "\t<tr><td>59         </td><td>35         </td><td> 1.02494192</td></tr>\n",
       "\t<tr><td>60         </td><td>35         </td><td> 1.87130689</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lll}\n",
       " pond & ni & true\\_a\\\\\n",
       "\\hline\n",
       "\t  1          &  5          & -0.82085139\\\\\n",
       "\t  2          &  5          &  3.76575421\\\\\n",
       "\t  3          &  5          & -0.03511672\\\\\n",
       "\t  4          &  5          &  0.01999213\\\\\n",
       "\t  5          &  5          & -1.59646315\\\\\n",
       "\t  6          &  5          &  0.99155593\\\\\n",
       "\t  7          &  5          &  0.92697693\\\\\n",
       "\t  8          &  5          &  0.45761715\\\\\n",
       "\t  9          &  5          &  1.24030417\\\\\n",
       "\t 10          &  5          &  2.04202220\\\\\n",
       "\t 11          &  5          &  0.23342063\\\\\n",
       "\t 12          &  5          & -0.54082345\\\\\n",
       "\t 13          &  5          &  0.23065024\\\\\n",
       "\t 14          &  5          &  1.41792764\\\\\n",
       "\t 15          &  5          &  1.17137564\\\\\n",
       "\t 16          & 10          &  0.34480362\\\\\n",
       "\t 17          & 10          &  3.18331873\\\\\n",
       "\t 18          & 10          &  1.91076841\\\\\n",
       "\t 19          & 10          &  2.16045226\\\\\n",
       "\t 20          & 10          &  0.96004228\\\\\n",
       "\t 21          & 10          &  1.73546212\\\\\n",
       "\t 22          & 10          &  4.41080219\\\\\n",
       "\t 23          & 10          &  2.91796868\\\\\n",
       "\t 24          & 10          &  0.94631113\\\\\n",
       "\t 25          & 10          & -0.13786726\\\\\n",
       "\t 26          & 10          &  0.99892276\\\\\n",
       "\t 27          & 10          &  1.10134151\\\\\n",
       "\t 28          & 10          &  1.59668389\\\\\n",
       "\t 29          & 10          &  1.61869984\\\\\n",
       "\t 30          & 10          &  1.94309708\\\\\n",
       "\t 31          & 25          &  2.41097175\\\\\n",
       "\t 32          & 25          &  4.50805365\\\\\n",
       "\t 33          & 25          &  0.58845703\\\\\n",
       "\t 34          & 25          & -0.20573824\\\\\n",
       "\t 35          & 25          &  0.84131490\\\\\n",
       "\t 36          & 25          &  0.67228797\\\\\n",
       "\t 37          & 25          &  1.81217627\\\\\n",
       "\t 38          & 25          &  0.68073116\\\\\n",
       "\t 39          & 25          &  2.59715799\\\\\n",
       "\t 40          & 25          & -0.10667680\\\\\n",
       "\t 41          & 25          &  1.55747635\\\\\n",
       "\t 42          & 25          & -0.33398934\\\\\n",
       "\t 43          & 25          &  2.26720194\\\\\n",
       "\t 44          & 25          & -0.99343848\\\\\n",
       "\t 45          & 25          &  0.93724452\\\\\n",
       "\t 46          & 35          &  2.07419888\\\\\n",
       "\t 47          & 35          & -0.06557992\\\\\n",
       "\t 48          & 35          &  1.68499679\\\\\n",
       "\t 49          & 35          &  2.49718004\\\\\n",
       "\t 50          & 35          &  0.66110133\\\\\n",
       "\t 51          & 35          &  1.33597263\\\\\n",
       "\t 52          & 35          &  1.23099414\\\\\n",
       "\t 53          & 35          &  2.08524087\\\\\n",
       "\t 54          & 35          &  4.43050226\\\\\n",
       "\t 55          & 35          & -0.17633509\\\\\n",
       "\t 56          & 35          &  2.50197816\\\\\n",
       "\t 57          & 35          &  2.20887462\\\\\n",
       "\t 58          & 35          & -0.57140920\\\\\n",
       "\t 59          & 35          &  1.02494192\\\\\n",
       "\t 60          & 35          &  1.87130689\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| pond | ni | true_a |\n",
       "|---|---|---|\n",
       "|  1          |  5          | -0.82085139 |\n",
       "|  2          |  5          |  3.76575421 |\n",
       "|  3          |  5          | -0.03511672 |\n",
       "|  4          |  5          |  0.01999213 |\n",
       "|  5          |  5          | -1.59646315 |\n",
       "|  6          |  5          |  0.99155593 |\n",
       "|  7          |  5          |  0.92697693 |\n",
       "|  8          |  5          |  0.45761715 |\n",
       "|  9          |  5          |  1.24030417 |\n",
       "| 10          |  5          |  2.04202220 |\n",
       "| 11          |  5          |  0.23342063 |\n",
       "| 12          |  5          | -0.54082345 |\n",
       "| 13          |  5          |  0.23065024 |\n",
       "| 14          |  5          |  1.41792764 |\n",
       "| 15          |  5          |  1.17137564 |\n",
       "| 16          | 10          |  0.34480362 |\n",
       "| 17          | 10          |  3.18331873 |\n",
       "| 18          | 10          |  1.91076841 |\n",
       "| 19          | 10          |  2.16045226 |\n",
       "| 20          | 10          |  0.96004228 |\n",
       "| 21          | 10          |  1.73546212 |\n",
       "| 22          | 10          |  4.41080219 |\n",
       "| 23          | 10          |  2.91796868 |\n",
       "| 24          | 10          |  0.94631113 |\n",
       "| 25          | 10          | -0.13786726 |\n",
       "| 26          | 10          |  0.99892276 |\n",
       "| 27          | 10          |  1.10134151 |\n",
       "| 28          | 10          |  1.59668389 |\n",
       "| 29          | 10          |  1.61869984 |\n",
       "| 30          | 10          |  1.94309708 |\n",
       "| 31          | 25          |  2.41097175 |\n",
       "| 32          | 25          |  4.50805365 |\n",
       "| 33          | 25          |  0.58845703 |\n",
       "| 34          | 25          | -0.20573824 |\n",
       "| 35          | 25          |  0.84131490 |\n",
       "| 36          | 25          |  0.67228797 |\n",
       "| 37          | 25          |  1.81217627 |\n",
       "| 38          | 25          |  0.68073116 |\n",
       "| 39          | 25          |  2.59715799 |\n",
       "| 40          | 25          | -0.10667680 |\n",
       "| 41          | 25          |  1.55747635 |\n",
       "| 42          | 25          | -0.33398934 |\n",
       "| 43          | 25          |  2.26720194 |\n",
       "| 44          | 25          | -0.99343848 |\n",
       "| 45          | 25          |  0.93724452 |\n",
       "| 46          | 35          |  2.07419888 |\n",
       "| 47          | 35          | -0.06557992 |\n",
       "| 48          | 35          |  1.68499679 |\n",
       "| 49          | 35          |  2.49718004 |\n",
       "| 50          | 35          |  0.66110133 |\n",
       "| 51          | 35          |  1.33597263 |\n",
       "| 52          | 35          |  1.23099414 |\n",
       "| 53          | 35          |  2.08524087 |\n",
       "| 54          | 35          |  4.43050226 |\n",
       "| 55          | 35          | -0.17633509 |\n",
       "| 56          | 35          |  2.50197816 |\n",
       "| 57          | 35          |  2.20887462 |\n",
       "| 58          | 35          | -0.57140920 |\n",
       "| 59          | 35          |  1.02494192 |\n",
       "| 60          | 35          |  1.87130689 |\n",
       "\n"
      ],
      "text/plain": [
       "   pond ni true_a     \n",
       "1   1    5 -0.82085139\n",
       "2   2    5  3.76575421\n",
       "3   3    5 -0.03511672\n",
       "4   4    5  0.01999213\n",
       "5   5    5 -1.59646315\n",
       "6   6    5  0.99155593\n",
       "7   7    5  0.92697693\n",
       "8   8    5  0.45761715\n",
       "9   9    5  1.24030417\n",
       "10 10    5  2.04202220\n",
       "11 11    5  0.23342063\n",
       "12 12    5 -0.54082345\n",
       "13 13    5  0.23065024\n",
       "14 14    5  1.41792764\n",
       "15 15    5  1.17137564\n",
       "16 16   10  0.34480362\n",
       "17 17   10  3.18331873\n",
       "18 18   10  1.91076841\n",
       "19 19   10  2.16045226\n",
       "20 20   10  0.96004228\n",
       "21 21   10  1.73546212\n",
       "22 22   10  4.41080219\n",
       "23 23   10  2.91796868\n",
       "24 24   10  0.94631113\n",
       "25 25   10 -0.13786726\n",
       "26 26   10  0.99892276\n",
       "27 27   10  1.10134151\n",
       "28 28   10  1.59668389\n",
       "29 29   10  1.61869984\n",
       "30 30   10  1.94309708\n",
       "31 31   25  2.41097175\n",
       "32 32   25  4.50805365\n",
       "33 33   25  0.58845703\n",
       "34 34   25 -0.20573824\n",
       "35 35   25  0.84131490\n",
       "36 36   25  0.67228797\n",
       "37 37   25  1.81217627\n",
       "38 38   25  0.68073116\n",
       "39 39   25  2.59715799\n",
       "40 40   25 -0.10667680\n",
       "41 41   25  1.55747635\n",
       "42 42   25 -0.33398934\n",
       "43 43   25  2.26720194\n",
       "44 44   25 -0.99343848\n",
       "45 45   25  0.93724452\n",
       "46 46   35  2.07419888\n",
       "47 47   35 -0.06557992\n",
       "48 48   35  1.68499679\n",
       "49 49   35  2.49718004\n",
       "50 50   35  0.66110133\n",
       "51 51   35  1.33597263\n",
       "52 52   35  1.23099414\n",
       "53 53   35  2.08524087\n",
       "54 54   35  4.43050226\n",
       "55 55   35 -0.17633509\n",
       "56 56   35  2.50197816\n",
       "57 57   35  2.20887462\n",
       "58 58   35 -0.57140920\n",
       "59 59   35  1.02494192\n",
       "60 60   35  1.87130689"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ERROR",
     "evalue": "Error in inv_logit_scaled(true_a): could not find function \"inv_logit_scaled\"\n",
     "output_type": "error",
     "traceback": [
      "Error in inv_logit_scaled(true_a): could not find function \"inv_logit_scaled\"\nTraceback:\n",
      "1. dsim %>% mutate(si = rbinom(n = n(), prob = inv_logit_scaled(true_a), \n .     size = ni))",
      "2. withVisible(eval(quote(`_fseq`(`_lhs`)), env, env))",
      "3. eval(quote(`_fseq`(`_lhs`)), env, env)",
      "4. eval(quote(`_fseq`(`_lhs`)), env, env)",
      "5. `_fseq`(`_lhs`)",
      "6. freduce(value, `_function_list`)",
      "7. withVisible(function_list[[k]](value))",
      "8. function_list[[k]](value)",
      "9. mutate(., si = rbinom(n = n(), prob = inv_logit_scaled(true_a), \n .     size = ni))",
      "10. mutate.tbl_df(., si = rbinom(n = n(), prob = inv_logit_scaled(true_a), \n  .     size = ni))",
      "11. mutate_impl(.data, dots, caller_env())",
      "12. rbinom(n = n(), prob = inv_logit_scaled(true_a), size = ni)"
     ]
    }
   ],
   "source": [
    "a       <-  1.4\n",
    "sigma   <-  1.5\n",
    "n_ponds <- 60\n",
    "\n",
    "set.seed(12)\n",
    "(\n",
    "  dsim <- \n",
    "  tibble(pond   = 1:n_ponds,\n",
    "         ni     = rep(c(5, 10, 25, 35), each = n_ponds / 4) %>% as.integer(),\n",
    "         true_a = rnorm(n = n_ponds, mean = a, sd = sigma))\n",
    "  )\n",
    "(\n",
    "  dsim <-\n",
    "  dsim %>%\n",
    "  mutate(si = rbinom(n = n(), prob = inv_logit_scaled(true_a), size = ni))\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the no-pooling estimates.\n",
    "(\n",
    "  dsim <-\n",
    "  dsim %>%\n",
    "  mutate(p_nopool = si / ni)\n",
    "  )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# partial pooling\n",
    "b12.3 <- \n",
    "  brm(data = dsim, family = binomial,\n",
    "      si | trials(ni) ~ 1 + (1 | pond),\n",
    "      prior = c(prior(normal(0, 1), class = Intercept),\n",
    "                prior(cauchy(0, 1), class = sd)),\n",
    "      iter = 10000, warmup = 1000, chains = 1, cores = 1,\n",
    "      seed = 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bind_rows(posterior_samples(b12.3),\n",
    "          posterior_samples(b12.3_new)) %>%\n",
    "  mutate(model = rep(c(\"b12.3\", \"b12.3_new\"), each = n() / 2)) %>% \n",
    "\n",
    "  ggplot(aes(x = b_Intercept, y = sd_pond__Intercept)) +\n",
    "  stat_density_2d(geom = \"raster\", \n",
    "                  aes(fill = stat(density)), \n",
    "                  contour = F, n = 200) +\n",
    "  geom_vline(xintercept = a,     color = \"orange3\", linetype = 3) +\n",
    "  geom_hline(yintercept = sigma, color = \"orange3\", linetype = 3) +\n",
    "  scale_fill_gradient(low = \"grey25\", high = \"orange3\") +\n",
    "  ggtitle(\"Our simulation posteriors contrast a bit\",\n",
    "          subtitle = expression(paste(alpha, \" is on the x and \", sigma, \" is on the y, both in log-odds. The dotted lines intersect at the true values.\"))) +\n",
    "  coord_cartesian(xlim = c(.7, 2),\n",
    "                  ylim = c(.8, 1.9)) +\n",
    "  theme_fivethirtyeight() +\n",
    "  theme(legend.position = \"none\",\n",
    "        panel.grid      = element_blank()) +\n",
    "  facet_wrap(~model, ncol = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "\\text{left_pull}_i   & \\sim \\text{Binomial} (n_i = 1, p_i) \\\\\n",
    "\\text{logit} (p_i)    & = \\alpha + \\alpha_{\\text{actor}_i} + (\\beta_1 + \\beta_2 \\text{condition}_i) \\text{prosoc_left}_i \\\\\n",
    "\\alpha_{\\text{actor}} & \\sim \\text{Normal} (0, \\sigma_{\\text{actor}}) \\\\\n",
    "\\alpha                & \\sim \\text{Normal} (0, 10) \\\\\n",
    "\\beta_1               & \\sim \\text{Normal} (0, 10) \\\\\n",
    "\\beta_2               & \\sim \\text{Normal} (0, 10) \\\\\n",
    "\\sigma_{\\text{actor}} & \\sim \\text{HalfCauchy} (0, 1)\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b12.4 <- \n",
    "  brm(data = d, family = binomial,\n",
    "      pulled_left | trials(1) ~ 1 + prosoc_left + prosoc_left:condition + (1 | actor),\n",
    "      prior = c(prior(normal(0, 10), class = Intercept),\n",
    "                prior(normal(0, 10), class = b),\n",
    "                prior(cauchy(0, 1), class = sd)),\n",
    "      # I'm using 4 cores, instead of the `cores=3` in McElreath's code\n",
    "      iter = 5000, warmup = 1000, chains = 4, cores = 4,  \n",
    "      control = list(adapt_delta = 0.95),\n",
    "      seed = 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef(b12.4)$actor[, c(1, 3:4), 1] %>%\n",
    "  as_tibble() %>% \n",
    "  round(digits = 2) %>%\n",
    "  # here we put the credible intervals in an APA-6-style format\n",
    "  mutate(`95% CIs` = str_c(\"[\", Q2.5, \", \", Q97.5, \"]\"),\n",
    "         actor     = str_c(\"chimp #\", 1:7)) %>%\n",
    "  rename(mean = Estimate) %>%\n",
    "  select(actor, mean, `95% CIs`) %>% \n",
    "  knitr::kable()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "\\text{left_pull}_i    & \\sim \\text{Binomial} (n_i = 1, p_i) \\\\\n",
    "\\text{logit} (p_i)    & = \\alpha + \\alpha_{\\text{actor}_i} + \\alpha_{\\text{block}_i} + (\\beta_1 + \\beta_2 \\text{condition}_i) \\text{prosoc_left}_i \\\\\n",
    "\\alpha_{\\text{actor}} & \\sim \\text{Normal} (0, \\sigma_{\\text{actor}}) \\\\\n",
    "\\alpha_{\\text{block}} & \\sim \\text{Normal} (0, \\sigma_{\\text{actor}}) \\\\\n",
    "\\alpha                & \\sim \\text{Normal} (0, 10) \\\\\n",
    "\\beta_1               & \\sim \\text{Normal} (0, 10) \\\\\n",
    "\\beta_2               & \\sim \\text{Normal} (0, 10) \\\\\n",
    "\\sigma_{\\text{actor}} & \\sim \\text{HalfCauchy} (0, 1) \\\\\n",
    "\\sigma_{\\text{block}} & \\sim \\text{HalfCauchy} (0, 1)\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b12.5 <- \n",
    "  update(b12.4,\n",
    "         newdata = d,\n",
    "         formula = pulled_left | trials(1) ~ 1 + prosoc_left + prosoc_left:condition + \n",
    "           (1 | actor) + (1 | block),\n",
    "         iter = 6000, warmup = 1000, cores = 4, chains = 4, \n",
    "         control = list(adapt_delta = 0.99),\n",
    "         seed = 12)\n",
    "\n",
    "library(bayesplot)\n",
    "color_scheme_set(\"orange\")\n",
    "\n",
    "post <- posterior_samples(b12.5, add_chain = T)\n",
    "\n",
    "post %>% \n",
    "  select(-lp__, -iter) %>% \n",
    "  mcmc_trace(facet_args = list(ncol = 4)) +\n",
    "  scale_x_continuous(breaks = c(0, 2500, 5000)) +\n",
    "  theme_fivethirtyeight() +\n",
    "  theme(legend.position = c(.75, .06))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "About half of them are lower than we might like, but none are in the embarrassing  \n",
    "n\n",
    "eff\n",
    "/\n",
    "N\n",
    "\n",
    ".1\n",
    "  range. Lets look at the summary of the main parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neff_ratio(b12.5) %>% \n",
    "  mcmc_neff() +\n",
    "  theme_fivethirtyeight()\n",
    "ranef(b12.5)$block[, , \"Intercept\"] %>% \n",
    "  round(digits = 2)\n",
    "stanplot(b12.5, pars = c(\"^r_\", \"^b_\", \"^sd_\")) +\n",
    "  theme_fivethirtyeight() +\n",
    "  theme(axis.text.y = element_text(hjust = 0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "\\text{criterion}_i                & \\sim \\text{Binomial} (n_i \\geq 1, p_i) \\\\\n",
    "\\text{logit} (p_i)                & = \\alpha + \\alpha_{\\text{grouping variable}_i}\\\\\n",
    "\\alpha                            & \\sim \\text{Normal} (0, 1) \\\\\n",
    "\\alpha_{\\text{grouping variable}} & \\sim \\text{Normal} (0, \\sigma_{\\text{grouping variable}}) \\\\\n",
    "\\sigma_{\\text{grouping variable}} & \\sim \\text{HalfCauchy} (0, 1)\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b12.7 <- \n",
    "  brm(data = b12.4$data, family = binomial,\n",
    "      pulled_left | trials(1) ~ 1 + (1 | actor),\n",
    "      prior = c(prior(normal(0, 10), class = Intercept),\n",
    "                prior(cauchy(0, 1), class = sd)),\n",
    "      iter = 5000, warmup = 1000, chains = 4, cores = 4,\n",
    "      control = list(adapt_delta = 0.95),\n",
    "      seed = 12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "\\text{pulled_left}_i  & \\sim \\text{Binomial} (n_i = 1, p_i) \\\\\n",
    "\\text{logit} (p_i)    & = \\alpha + \\alpha_{\\text{actor}_i} + \\alpha_{\\text{block}_i}\\\\\n",
    "\\alpha                & \\sim \\text{Normal} (0, 10) \\\\\n",
    "\\alpha_{\\text{actor}} & \\sim \\text{Normal} (0, \\sigma_{\\text{actor}}) \\\\\n",
    "\\alpha_{\\text{block}} & \\sim \\text{Normal} (0, \\sigma_{\\text{block}}) \\\\\n",
    "\\sigma_{\\text{actor}} & \\sim \\text{HalfCauchy} (0, 1) \\\\\n",
    "\\sigma_{\\text{block}} & \\sim \\text{HalfCauchy} (0, 1)\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b12.8 <- \n",
    "  brm(data = b12.5$data, family = binomial,\n",
    "      pulled_left | trials(1) ~ 1 + (1 | actor) + (1 | block),\n",
    "      prior = c(prior(normal(0, 10), class = Intercept),\n",
    "                prior(cauchy(0, 1), class = sd)),\n",
    "      iter = 5000, warmup = 1000, chains = 4, cores = 4,\n",
    "      control = list(adapt_delta = 0.95),\n",
    "      seed = 12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. brms::posterior_samples()\n",
    "2. brms::coef()\n",
    "3. brms::fitted()\n",
    "4. tidybayes::spread_draws()\n",
    "\n",
    "Get posetrior draws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior_samples(b12.7) %>% str()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef(b12.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(nd <- b12.7$data %>% distinct(actor))\n",
    "f1 <-\n",
    "  fitted(b12.7,\n",
    "         newdata = nd,\n",
    "         summary = F,\n",
    "         # within `fitted()`, this line does the same work that\n",
    "         # `inv_logit_scaled()` did with the other two methods\n",
    "         scale = \"response\") %>% \n",
    "  as_tibble() %>% \n",
    "  set_names(str_c(\"chimp \", 1:7, \"'s average probability of pulling left\"))\n",
    "\n",
    "str(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(tidybayes)\n",
    "\n",
    "b12.7 %>%\n",
    "  spread_draws(b_Intercept, r_actor[actor,])\n",
    "\n",
    "s1 <-\n",
    "  b12.7 %>%\n",
    "  spread_draws(b_Intercept, r_actor[actor,]) %>% \n",
    "  mutate(p = (b_Intercept + r_actor) %>% inv_logit_scaled()) %>% \n",
    "  select(.draw, actor, p) %>% \n",
    "  ungroup() %>% \n",
    "  mutate(actor = str_c(\"chimp \", actor, \"'s average probability of pulling left\")) %>% \n",
    "  spread(value = p, key = actor)\n",
    "\n",
    "str(s1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Covariance Prior modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>a_cafe</th><th scope=col>b_cafe</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>2.917639  </td><td>-0.8649154</td></tr>\n",
       "\t<tr><td>3.552770  </td><td>-1.6814372</td></tr>\n",
       "\t<tr><td>1.694390  </td><td>-0.4168858</td></tr>\n",
       "\t<tr><td>3.442417  </td><td>-0.6011724</td></tr>\n",
       "\t<tr><td>2.289988  </td><td>-0.7461953</td></tr>\n",
       "\t<tr><td>3.069283  </td><td>-0.8839639</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ll}\n",
       " a\\_cafe & b\\_cafe\\\\\n",
       "\\hline\n",
       "\t 2.917639   & -0.8649154\\\\\n",
       "\t 3.552770   & -1.6814372\\\\\n",
       "\t 1.694390   & -0.4168858\\\\\n",
       "\t 3.442417   & -0.6011724\\\\\n",
       "\t 2.289988   & -0.7461953\\\\\n",
       "\t 3.069283   & -0.8839639\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| a_cafe | b_cafe |\n",
       "|---|---|\n",
       "| 2.917639   | -0.8649154 |\n",
       "| 3.552770   | -1.6814372 |\n",
       "| 1.694390   | -0.4168858 |\n",
       "| 3.442417   | -0.6011724 |\n",
       "| 2.289988   | -0.7461953 |\n",
       "| 3.069283   | -0.8839639 |\n",
       "\n"
      ],
      "text/plain": [
       "  a_cafe   b_cafe    \n",
       "1 2.917639 -0.8649154\n",
       "2 3.552770 -1.6814372\n",
       "3 1.694390 -0.4168858\n",
       "4 3.442417 -0.6011724\n",
       "5 2.289988 -0.7461953\n",
       "6 3.069283 -0.8839639"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :\n",
      "\"font family not found in Windows font database\"Warning message in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :\n",
      "\"font family not found in Windows font database\"Warning message in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :\n",
      "\"font family not found in Windows font database\"Warning message in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :\n",
      "\"font family not found in Windows font database\"Warning message in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :\n",
      "\"font family not found in Windows font database\"Warning message in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :\n",
      "\"font family not found in Windows font database\"Warning message in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, :\n",
      "\"font family not found in Windows font database\"Warning message in grid.Call.graphics(C_text, as.graphicsAnnot(x$label), x$x, x$y, :\n",
      "\"font family not found in Windows font database\""
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAAOVBMVEUQDxRoYmB5cm+AoMeH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\nwMH+Dx+Wkk6fSQ7UAAAAAElFTkSuQmCC",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# devtools::install_github(\"EdwinTh/dutchmasters\")\n",
    "#library(dutchmasters)\n",
    "\n",
    "#dutchmasters$pearl_earring\n",
    "a       <-  3.5  # average morning wait time\n",
    "b       <- -1    # average difference afternoon wait time\n",
    "sigma_a <-  1    # std dev in intercepts\n",
    "sigma_b <-  0.5  # std dev in slopes\n",
    "rho     <- -.7   # correlation between intercepts and slopes\n",
    "\n",
    "# the next three lines of code simply combine the terms, above\n",
    "mu     <- c(a, b)\n",
    "cov_ab <- sigma_a * sigma_b * rho\n",
    "sigma  <- matrix(c(sigma_a^2, cov_ab, \n",
    "                   cov_ab, sigma_b^2), ncol = 2)\n",
    "library(tidyverse)\n",
    "\n",
    "sigmas <- c(sigma_a, sigma_b)          # standard deviations\n",
    "rho    <- matrix(c(1, rho,             # correlation matrix\n",
    "                   rho, 1), nrow = 2)\n",
    "\n",
    "# now matrix multiply to get covariance matrix\n",
    "sigma <- diag(sigmas) %*% rho %*% diag(sigmas)\n",
    "\n",
    "# how many cafes would you like?\n",
    "n_cafes <- 20\n",
    "\n",
    "set.seed(13)  # used to replicate example\n",
    "vary_effects <- \n",
    "  MASS::mvrnorm(n_cafes, mu, sigma) %>% \n",
    "  data.frame() %>% \n",
    "  set_names(\"a_cafe\", \"b_cafe\")\n",
    "\n",
    "theme_pearl_earring <-\n",
    "  theme(text       = element_text(color = \"#E8DCCF\", family = \"Courier\"),\n",
    "        strip.text = element_text(color = \"#E8DCCF\", family = \"Courier\"),\n",
    "        axis.text  = element_text(color = \"#E8DCCF\"),\n",
    "        axis.ticks = element_line(color = \"#E8DCCF\"),\n",
    "        line       = element_line(color = \"#E8DCCF\"),\n",
    "        plot.background   = element_rect(fill = \"#100F14\", color = \"transparent\"),\n",
    "        panel.background  = element_rect(fill = \"#100F14\", color = \"#E8DCCF\"),\n",
    "        strip.background  = element_rect(fill = \"#100F14\", color = \"transparent\"),\n",
    "        panel.grid = element_blank(),\n",
    "        legend.background = element_rect(fill = \"#100F14\", color = \"transparent\"),\n",
    "        legend.key        = element_rect(fill = \"#100F14\", color = \"transparent\"),\n",
    "        axis.line = element_blank())\n",
    "\n",
    "head(vary_effects)\n",
    "vary_effects %>% \n",
    "  ggplot(aes(x = a_cafe, y = b_cafe)) +\n",
    "  geom_point(color = \"#80A0C7\") +\n",
    "  geom_rug(color = \"#8B9DAF\", size = 1/7) +\n",
    "  theme_pearl_earring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_visits <- 10\n",
    "sigma    <-  0.5  # std dev within cafes\n",
    "\n",
    "set.seed(13)  # used to replicate example\n",
    "d <-\n",
    "  vary_effects %>% \n",
    "  mutate(cafe      = 1:n_cafes) %>% \n",
    "  expand(nesting(cafe, a_cafe, b_cafe), visit = 1:n_visits) %>% \n",
    "  mutate(afternoon = rep(0:1, times = n() / 2)) %>% \n",
    "  mutate(mu        = a_cafe + b_cafe * afternoon) %>% \n",
    "  mutate(wait      = rnorm(n = n(), mean = mu, sd = sigma))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "\\text{wait}_i & \\sim \\text{Normal} (\\mu_i, \\sigma) \\\\\n",
    "\\mu_i         & = \\alpha_{\\text{cafe}_i} + \\beta_{\\text{cafe}_i} \\text{afternoon}_i \\\\\n",
    "\\begin{bmatrix} \\alpha_\\text{cafe} \\\\ \\beta_\\text{cafe} \\end{bmatrix} & \\sim \\text{MVNormal} \\bigg (\\begin{bmatrix} \\alpha \\\\ \\beta \\end{bmatrix}, \\mathbf{S}  \\bigg ) \\\\\n",
    "\\mathbf S     & = \\begin{pmatrix} \\sigma_\\alpha & 0 \\\\ 0 & \\sigma_\\beta \\end{pmatrix} \\mathbf R \\begin{pmatrix} \\sigma_\\alpha & 0 \\\\ 0 & \\sigma_\\beta \\end{pmatrix} \\\\\n",
    "\\alpha        & \\sim \\text{Normal} (0, 10) \\\\\n",
    "\\beta         & \\sim \\text{Normal} (0, 10) \\\\\n",
    "\\sigma        & \\sim \\text{HalfCauchy} (0, 1) \\\\\n",
    "\\sigma_\\alpha & \\sim \\text{HalfCauchy} (0, 1) \\\\\n",
    "\\sigma_\\beta  & \\sim \\text{HalfCauchy} (0, 1) \\\\\n",
    "\\mathbf R     & \\sim \\text{LKJcorr} (2)\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As defined above, our first model has both varying intercepts and afternoon slopes. I should point out that the (1 + afternoon | cafe) syntax specifies that wed like brm() to fit the random effects for 1 (i.e., the intercept) and the afternoon slope as correlated. Had we wanted to fit a model in which they were orthogonal, wed have coded (1 + afternoon || cafe)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " b13.1 <- \n",
    "  brm(data = d, family = gaussian,\n",
    "      wait ~ 1 + afternoon + (1 + afternoon | cafe),\n",
    "      prior = c(prior(normal(0, 10), class = Intercept),\n",
    "                prior(normal(0, 10), class = b),\n",
    "                prior(cauchy(0, 2), class = sd),\n",
    "                prior(cauchy(0, 2), class = sigma),\n",
    "                prior(lkj(2), class = cor)),\n",
    "      iter = 5000, warmup = 2000, chains = 2, cores = 2,\n",
    "      seed = 13)\n",
    "\n",
    "post <- posterior_samples(b13.1)\n",
    "\n",
    "post %>%\n",
    "  ggplot(aes(x = cor_cafe__Intercept__afternoon)) +\n",
    "  geom_density(data = r_2, aes(x = V2),\n",
    "               color = \"transparent\", fill = \"#EEDA9D\", alpha = 3/4) +\n",
    "  geom_density(color = \"transparent\", fill = \"#A65141\", alpha = 9/10) +\n",
    "  annotate(\"text\", label = \"posterior\", \n",
    "           x = -0.35, y = 2.2, \n",
    "           color = \"#A65141\", family = \"Courier\") +\n",
    "  annotate(\"text\", label = \"prior\", \n",
    "           x = 0, y = 0.9, \n",
    "           color = \"#EEDA9D\", alpha = 2/3, family = \"Courier\") +\n",
    "  scale_y_continuous(NULL, breaks = NULL) +\n",
    "  xlab(\"correlation\") +\n",
    "  theme_pearl_earring\n",
    "\n",
    "# coef(b13.1) %>% glimpse()\n",
    "\n",
    "coef(b13.1)\n",
    "\n",
    "partially_pooled_params <-\n",
    "  # with this line we select each of the 20 cafe's posterior mean (i.e., Estimate)\n",
    "  # for both `Intercept` and `afternoon`\n",
    "  coef(b13.1)$cafe[ , 1, 1:2] %>%\n",
    "  as_tibble() %>%               # convert the two vectors to a tibble\n",
    "  rename(Slope = afternoon) %>%\n",
    "  mutate(cafe = 1:nrow(.)) %>%  # add the `cafe` index\n",
    "  select(cafe, everything())    # simply moving `cafe` to the leftmost position\n",
    "\n",
    "# compute unpooled estimates directly from data\n",
    "un_pooled_params <-\n",
    "  d %>%\n",
    "  # with these two lines, we compute the mean value for each cafe's wait time \n",
    "  # in the morning and then the afternoon\n",
    "  group_by(afternoon, cafe) %>%\n",
    "  summarise(mean = mean(wait)) %>%\n",
    "  ungroup() %>%  # ungrouping allows us to alter afternoon, one of the grouping variables\n",
    "  mutate(afternoon = ifelse(afternoon == 0, \"Intercept\", \"Slope\")) %>%\n",
    "  spread(key = afternoon, value = mean) %>%  # use `spread()` just as in the previous block\n",
    "  mutate(Slope = Slope - Intercept)          # finally, here's our slope!\n",
    "\n",
    "# here we combine the partially-pooled and unpooled means into a single data object, \n",
    "# which will make plotting easier.\n",
    "params <-\n",
    "  # `bind_rows()` will stack the second tibble below the first\n",
    "  bind_rows(partially_pooled_params, un_pooled_params) %>%\n",
    "  # index whether the estimates are pooled\n",
    "  mutate(pooled = rep(c(\"partially\", \"not\"), each = nrow(.)/2)) \n",
    "\n",
    "# here's a glimpse at what we've been working for\n",
    "params %>%\n",
    "  slice(c(1:5, 36:40))\n",
    "\n",
    "ggplot(data = params, aes(x = Intercept, y = Slope)) +\n",
    "  stat_ellipse(geom = \"polygon\", type = \"norm\", level = 1/10, size = 0, alpha = 1/20, fill = \"#E7CDC2\") +\n",
    "  stat_ellipse(geom = \"polygon\", type = \"norm\", level = 2/10, size = 0, alpha = 1/20, fill = \"#E7CDC2\") +\n",
    "  stat_ellipse(geom = \"polygon\", type = \"norm\", level = 3/10, size = 0, alpha = 1/20, fill = \"#E7CDC2\") +\n",
    "  stat_ellipse(geom = \"polygon\", type = \"norm\", level = 4/10, size = 0, alpha = 1/20, fill = \"#E7CDC2\") +\n",
    "  stat_ellipse(geom = \"polygon\", type = \"norm\", level = 5/10, size = 0, alpha = 1/20, fill = \"#E7CDC2\") +\n",
    "  stat_ellipse(geom = \"polygon\", type = \"norm\", level = 6/10, size = 0, alpha = 1/20, fill = \"#E7CDC2\") +\n",
    "  stat_ellipse(geom = \"polygon\", type = \"norm\", level = 7/10, size = 0, alpha = 1/20, fill = \"#E7CDC2\") +\n",
    "  stat_ellipse(geom = \"polygon\", type = \"norm\", level = 8/10, size = 0, alpha = 1/20, fill = \"#E7CDC2\") +\n",
    "  stat_ellipse(geom = \"polygon\", type = \"norm\", level = 9/10, size = 0, alpha = 1/20, fill = \"#E7CDC2\") +\n",
    "  stat_ellipse(geom = \"polygon\", type = \"norm\", level = .99,  size = 0, alpha = 1/20, fill = \"#E7CDC2\") +\n",
    "  geom_point(aes(group = cafe, color = pooled)) +\n",
    "  geom_line(aes(group = cafe), size = 1/4) +\n",
    "  scale_color_manual(\"Pooled?\",\n",
    "                     values = c(\"#80A0C7\", \"#A65141\")) +\n",
    "  coord_cartesian(xlim = range(params$Intercept),\n",
    "                  ylim = range(params$Slope)) +\n",
    "  theme_pearl_earring\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "\\text{admit}_i         & \\sim \\text{Binomial} (n_i, p_i) \\\\\n",
    "\\text{logit} (p_i)     & = \\alpha_{\\text{dept_id}_i} + \\beta \\text{male}_i \\\\\n",
    "\\alpha_\\text{dept_id} & \\sim \\text{Normal} (\\alpha, \\sigma) \\\\\n",
    "\\alpha                 & \\sim \\text{Normal} (0, 10) \\\\\n",
    "\\beta                  & \\sim \\text{Normal} (0, 1) \\\\\n",
    "\\sigma                 & \\sim \\text{HalfCauchy} (0, 2) \\\\\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b13.2 <- \n",
    "  brm(data = d, family = binomial,\n",
    "      admit | trials(applications) ~ 1 + male + (1 | dept_id),\n",
    "      prior = c(prior(normal(0, 10), class = Intercept),\n",
    "                prior(normal(0, 1), class = b),\n",
    "                prior(cauchy(0, 2), class = sd)),\n",
    "      iter = 4500, warmup = 500, chains = 3, cores = 3,\n",
    "      seed = 13,\n",
    "      control = list(adapt_delta = 0.99))\n",
    "\n",
    "library(broom)\n",
    "\n",
    "tidy(b13.2) %>%\n",
    "  mutate_if(is.numeric, round, digits = 2)  # this line just rounds the output\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "\\text{admit}_i     & \\sim \\text{Binomial} (n_i, p_i) \\\\\n",
    "\\text{logit} (p_i) & = \\alpha_{\\text{dept_id}_i} + \\beta_{\\text{dept_id}_i} \\text{male}_i \\\\\n",
    "\\begin{bmatrix} \\alpha_\\text{dept_id} \\\\ \\beta_\\text{dept_id} \\end{bmatrix} & \\sim \\text{MVNormal} \\bigg (\\begin{bmatrix} \\alpha \\\\ \\beta \\end{bmatrix}, \\mathbf{S}  \\bigg ) \\\\\n",
    "\\mathbf S & = \\begin{pmatrix} \\sigma_\\alpha & 0 \\\\ 0 & \\sigma_\\beta \\end{pmatrix} \\mathbf R \\begin{pmatrix} \\sigma_\\alpha & 0 \\\\ 0 & \\sigma_\\beta \\end{pmatrix} \\\\\n",
    "\\alpha                        & \\sim \\text{Normal} (0, 10) \\\\\n",
    "\\beta                         & \\sim \\text{Normal} (0, 1) \\\\\n",
    "(\\sigma_\\alpha, \\sigma_\\beta) & \\sim \\text{HalfCauchy} (0, 2) \\\\\n",
    "\\mathbf R                     & \\sim \\text{LKJcorr} (2)\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b13.3 <- \n",
    "  brm(data = d, family = binomial,\n",
    "      admit | trials(applications) ~ 1 + male + (1 + male | dept_id),\n",
    "      prior = c(prior(normal(0, 10), class = Intercept),\n",
    "                prior(normal(0, 1), class = b),\n",
    "                prior(cauchy(0, 2), class = sd),\n",
    "                prior(lkj(2), class = cor)),\n",
    "      iter = 5000, warmup = 1000, chains = 4, cores = 4,\n",
    "      seed = 13,\n",
    "      control = list(adapt_delta = .99,\n",
    "                     max_treedepth = 12))\n",
    "\n",
    "post <- posterior_samples(b13.3, add_chain = T)\n",
    "\n",
    "post %>% \n",
    "  select(-lp__) %>% \n",
    "  gather(key, value, -chain, -iter) %>% \n",
    "  mutate(chain = as.character(chain)) %>% \n",
    "\n",
    "  ggplot(aes(x = iter, y = value, group = chain, color = chain)) +\n",
    "  geom_line(size = 1/15) +\n",
    "  scale_color_manual(values = c(\"#80A0C7\", \"#B1934A\", \"#A65141\", \"#EEDA9D\")) +\n",
    "  scale_x_continuous(NULL, breaks = c(1001, 5000)) +\n",
    "  ylab(NULL) +\n",
    "  theme_pearl_earring +\n",
    "  theme(legend.position  = c(.825, .06),\n",
    "        legend.direction = \"horizontal\") +\n",
    "  facet_wrap(~key, ncol = 3, scales = \"free_y\")\n",
    "\n",
    "#examine the R vales in a handmade plot\n",
    "rhat(b13.3) %>% \n",
    "  data.frame() %>% \n",
    "  rownames_to_column() %>% \n",
    "  set_names(\"parameter\", \"rhat\") %>% \n",
    "  filter(parameter != \"lp__\") %>% \n",
    "  \n",
    "  ggplot(aes(x = rhat, y = reorder(parameter, rhat))) + \n",
    "  geom_segment(aes(xend = 1, yend = parameter),\n",
    "               color = \"#EEDA9D\") +\n",
    "  geom_point(aes(color = rhat > 1), \n",
    "             size = 2) +\n",
    "  scale_color_manual(values = c(\"#80A0C7\", \"#A65141\")) +\n",
    "  labs(x = NULL, y = NULL) +\n",
    "  theme_pearl_earring +\n",
    "  theme(legend.position = \"none\",\n",
    "        axis.ticks.y    = element_blank(),\n",
    "        axis.text.y     = element_text(hjust = 0))\n",
    "\n",
    "coef(b13.3)\n",
    "\n",
    "#bayesplog::mcmc_intervals() or tidybayes::pointintervalh() to make our coefficient plot\n",
    "# random effects one at a time and then bind them together to get them ready for a tibble\n",
    "rbind(coef(b13.3)$dept_id[, , 1],\n",
    "      coef(b13.3)$dept_id[, , 2]) %>% \n",
    "  as_tibble() %>% \n",
    "  mutate(param   = c(paste(\"Intercept\", 1:6), paste(\"male\", 1:6)),\n",
    "         reorder = c(6:1, 12:7)) %>% \n",
    "\n",
    "  # plot\n",
    "  ggplot(aes(x = reorder(param, reorder))) +\n",
    "  geom_hline(yintercept = 0, linetype = 3, color = \"#8B9DAF\") +\n",
    "  geom_pointrange(aes(ymin = Q2.5, ymax = Q97.5, y = Estimate, color = reorder < 7),\n",
    "                  shape = 20, size = 3/4) +\n",
    "  scale_color_manual(values = c(\"#394165\", \"#A65141\")) +\n",
    "  xlab(NULL) +\n",
    "  coord_flip() +\n",
    "  theme_pearl_earring +\n",
    "  theme(legend.position = \"none\",\n",
    "        axis.ticks.y    = element_blank(),\n",
    "        axis.text.y     = element_text(hjust = 0))\n",
    "\n",
    "library(tidybayes)\n",
    "\n",
    "post <- posterior_samples(b13.3)\n",
    "\n",
    "post %>% \n",
    "  ggplot(aes(x = cor_dept_id__Intercept__male, y = 0)) +\n",
    "  geom_halfeyeh(fill = \"#394165\", color = \"#8B9DAF\", \n",
    "                point_interval = median_qi, .width = .95) +\n",
    "  scale_x_continuous(breaks = c(-1, median(post$cor_dept_id__Intercept__male), 1),\n",
    "                     labels = c(-1, \"-.35\", 1)) +\n",
    "  scale_y_continuous(NULL, breaks = NULL) +\n",
    "  coord_cartesian(xlim = -1:1) +\n",
    "  labs(subtitle = \"The dot is at the median; the\\nhorizontal bar is the 95% CI.\",\n",
    "       x = \"correlation\") +\n",
    "  theme_pearl_earring\n",
    "\n",
    "b13.2 <- add_criterion(b13.2, \"waic\")\n",
    "b13.3 <- add_criterion(b13.3, \"waic\")\n",
    "b13.4 <- add_criterion(b13.4, \"waic\")\n",
    "\n",
    "loo_compare(b13.2, b13.3, b13.4, criterion = \"waic\") %>% \n",
    "  print(simplify = F)\n",
    "\n",
    "model_weights(b13.2, b13.3, b13.4, weights = \"waic\") %>% \n",
    "  round(digits = 3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "\\text{pulled_left}_i       & \\sim \\text{Binomial} (n = 1, p_i) \\\\\n",
    "\\text{logit} (p_i)         & = \\alpha_i + (\\beta_{1i} + \\beta_{2i} \\text{condition}_i) \\text{prosoc_left}_i  \\\\\n",
    "\\alpha_i                   & = \\alpha + \\alpha_{\\text{actor}_i} + \\alpha_{\\text{block_id}_i} \\\\\n",
    "\\beta_{1i}                 & = \\beta_1 + \\beta_{1, \\text{actor}_i} + \\beta_{1, \\text{block_id}_i} \\\\\n",
    "\\beta_{2i}                 & = \\beta_2 + \\beta_{2, \\text{actor}_i} + \\beta_{2, \\text{block_id}_i} \\\\\n",
    "\\begin{bmatrix} \\alpha_\\text{actor} \\\\ \\beta_{1, \\text{actor}} \\\\ \\beta_{2, \\text{actor}} \\end{bmatrix} & \\sim \\text{MVNormal} \\begin{pmatrix} \\begin{bmatrix}0 \\\\ 0 \\\\ 0 \\end{bmatrix} , \\mathbf{S}_\\text{actor} \\end{pmatrix} \\\\\n",
    "\\begin{bmatrix} \\alpha_\\text{block_id} \\\\ \\beta_{1, \\text{block_id}} \\\\ \\beta_{2, \\text{block_id}} \\end{bmatrix} & \\sim \\text{MVNormal} \\begin{pmatrix} \\begin{bmatrix}0 \\\\ 0 \\\\ 0 \\end{bmatrix} , \\mathbf{S}_\\text{block_id} \\end{pmatrix} \\\\\n",
    "\\mathbf S_\\text{actor}     & = \\begin{pmatrix} \\sigma_{\\alpha_\\text{actor}} & 0 & 0 \\\\ 0 & \\sigma_{\\beta_{1_\\text{actor}}} & 0 \\\\ 0 & 0 & \\sigma_{\\beta_{2_\\text{actor}}} \\end{pmatrix} \n",
    "\\mathbf R_\\text{actor} \\begin{pmatrix} \\sigma_{\\alpha_\\text{actor}} & 0 & 0 \\\\ 0 & \\sigma_{\\beta_{1_\\text{actor}}} & 0 \\\\ 0 & 0 & \\sigma_{\\beta_{2_\\text{actor}}} \\end{pmatrix} \\\\\n",
    "\\mathbf S_\\text{block_id}  & = \\begin{pmatrix} \\sigma_{\\alpha_\\text{block_id}} & 0 & 0 \\\\ 0 & \\sigma_{\\beta_{1_\\text{block_id}}} & 0 \\\\ 0 & 0 & \\sigma_{\\beta_{2_\\text{block_id}}} \\end{pmatrix} \n",
    "\\mathbf R_\\text{block_id} \\begin{pmatrix} \\sigma_{\\alpha_\\text{block_id}} & 0 & 0 \\\\ 0 & \\sigma_{\\beta_{1_\\text{block_id}}} & 0 \\\\ 0 & 0 & \\sigma_{\\beta_{2_\\text{block_id}}} \\end{pmatrix} \\\\\n",
    "\\alpha                     & \\sim \\text{Normal} (0, 1) \\\\\n",
    "\\beta_1                    & \\sim \\text{Normal} (0, 1) \\\\\n",
    "\\beta_2                    & \\sim \\text{Normal} (0, 1) \\\\\n",
    "(\\sigma_{\\alpha_\\text{actor}}, \\sigma_{\\beta_{1_\\text{actor}}}, \\sigma_{\\beta_{2_\\text{actor}}}) & \\sim \\text{HalfCauchy} (0, 2) \\\\\n",
    "(\\sigma_{\\alpha_\\text{block_id}}, \\sigma_{\\beta_{1_\\text{block_id}}}, \\sigma_{\\beta_{2_\\text{block_id}}}) & \\sim \\text{HalfCauchy} (0, 2) \\\\\n",
    "\\mathbf R_\\text{actor}     & \\sim \\text{LKJcorr} (4) \\\\\n",
    "\\mathbf R_\\text{block_id}  & \\sim \\text{LKJcorr} (4)\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b13.6 <- \n",
    "  brm(data = d, family = binomial,\n",
    "      pulled_left | trials(1) ~ 1 + prosoc_left + condition:prosoc_left +\n",
    "        (1 + prosoc_left + condition:prosoc_left | actor) +\n",
    "        (1 + prosoc_left + condition:prosoc_left | block_id),\n",
    "      prior = c(prior(normal(0, 1), class = Intercept),\n",
    "                prior(normal(0, 1), class = b),\n",
    "                prior(cauchy(0, 2), class = sd),\n",
    "                prior(lkj(4), class = cor)),\n",
    "      iter = 5000, warmup = 1000, chains = 3, cores = 3,\n",
    "      seed = 13)\n",
    "ratios_cp <- neff_ratio(b13.6)\n",
    "\n",
    "neff <-\n",
    "  ratios_cp %>% \n",
    "  as_tibble %>% \n",
    "  rename(neff_ratio = value) %>% \n",
    "  mutate(neff       = neff_ratio * 12000)\n",
    "\n",
    "head(neff)\n",
    "library(bayesplot)\n",
    "\n",
    "color_scheme_set(c(\"#DCA258\", \"#EEDA9D\", \"#394165\", \"#8B9DAF\", \"#A65141\", \"#A65141\"))\n",
    "\n",
    "mcmc_neff(ratios_cp, size = 2) +\n",
    "  theme_pearl_earring\n",
    "\n",
    "tidy(b13.6) %>%\n",
    "  filter(str_detect(term , \"sd_\")) %>%\n",
    "  mutate_if(is.numeric, round, digits = 2)\n",
    "\n",
    "fitted(b13.6,\n",
    "       summary = F,\n",
    "       nsamples = 1000) %>% \n",
    "  str()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " If we want individual values, set summary = FALSE. Its also the fitted() default to use all posterior iterations, which is 12,000 in this case. To match the text, we need to set nsamples = 1000. But those are just details. The main point is that fitted() only returns one matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b12.5 <- \n",
    "  brm(data = d, family = binomial,\n",
    "      pulled_left | trials(1) ~ 1 + prosoc_left + condition:prosoc_left + \n",
    "        (1 | actor) + (1 | block_id),\n",
    "      prior = c(prior(normal(0, 10), class = Intercept),\n",
    "                prior(normal(0, 10), class = b),\n",
    "                prior(cauchy(0, 1), class = sd)),\n",
    "      iter = 5000, warmup = 1000, chains = 3, cores = 3,\n",
    "      seed = 13)\n",
    "b13.6 <- add_criterion(b13.6, \"waic\")\n",
    "b12.5 <- add_criterion(b12.5, \"waic\")\n",
    "\n",
    "loo_compare(b13.6, b12.5, criterion = \"waic\") %>% \n",
    "  print(simplify = F)\n",
    "\n",
    "model_weights(b13.6, b12.5, weights = \"waic\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaussian Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b13.7 <- \n",
    "  brm(data = d, family = poisson,\n",
    "      total_tools ~ 1 + gp(lat, lon2) + logpop,\n",
    "      prior = c(prior(normal(0, 10), class = Intercept),\n",
    "                prior(normal(0, 1), class = b),\n",
    "                prior(inv_gamma(2.874624, 0.393695), class = lscale),\n",
    "                prior(cauchy(0, 1), class = sdgp)),\n",
    "      iter = 1e4, warmup = 2000, chains = 4, cores = 4,\n",
    "      seed = 13,\n",
    "      control = list(adapt_delta = 0.999,\n",
    "                     max_treedepth = 12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior_summary(b13.7) %>%\n",
    "  round(digits = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook and others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit1 <- \n",
    "  brm(data = BTdata,\n",
    "      family = gaussian,\n",
    "      mvbind(tarsus, back) ~ sex + hatchdate + (1|p|fosternest) + (1|q|dam), \n",
    "      chains = 2, cores = 2,\n",
    "      seed = 15)\n",
    "\n",
    "# load the model1\n",
    "save(fit1, file = \"fit1.rda\")\n",
    "load(\"fit1.rda\")\n",
    "\n",
    "# load the model2\n",
    "fit2 <- \n",
    "  brm(data = BTdata,\n",
    "      family = gaussian,\n",
    "      mvbind(tarsus, back) ~ sex*hatchdate + (1|p|fosternest) + (1|q|dam), \n",
    "      chains = 2, cores = 2,\n",
    "      seed = 15,\n",
    "      file = \"fit2\")\n",
    "fit2 <- readRDS(\"fit2.rds\")\n",
    "fixef(fit2) %>% \n",
    "  round(digits = 3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimating Distributional Models with brms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unequal variance models are possibly the most simple, but nevertheless very important application of distributional models. Suppose we have two groups of patients: One group recieves a treatment (e.g., an antidepressive drug) and another group recieves placebo. Since the treatment may not work equally well for all patients, the symptom variance of the treatment group may be larger than the symptom variance of the placebo group after some weeks of treatment. For simplicity, assume that we only investigate the post-treatment values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group <- rep(c(\"treat\", \"placebo\"), each = 30)\n",
    "symptom_post <- c(rnorm(30, mean = 1, sd = 2), \n",
    "                  rnorm(30, mean = 0, sd = 1))\n",
    "dat1 <- data.frame(group, symptom_post)\n",
    "head(dat1)\n",
    "\n",
    "fit1 <- brm(bf(symptom_post ~ group, sigma ~ group), \n",
    "            data = dat1, family = gaussian())\n",
    "#Useful summary statistics and plots can be obtained via\n",
    "\n",
    "summary(fit1)\n",
    "plot(fit1, N = 2, ask = FALSE)\n",
    "plot(conditional_effects(fit1), points = TRUE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "additive distribution models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_smooth <- mgcv::gamSim(eg = 6, n = 200, scale = 2, verbose = FALSE)\n",
    "fit_smooth1 <- brm(\n",
    "  bf(y ~ s(x1) + s(x2) + (1|fac), sigma ~ s(x0) + (1|fac)),\n",
    "  data = dat_smooth, family = gaussian(),\n",
    "  chains = 2, control = list(adapt_delta = 0.95)\n",
    ")\n",
    "summary(fit_smooth1)\n",
    "plot(conditional_effects(fit_smooth1), points = TRUE, ask = FALSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Stacking and Pseudo-BMA weights using the loo package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(rstanarm)\n",
    "library(loo)\n",
    "data(milk)\n",
    "library(\"rstanarm\")\n",
    "library(\"bayesplot\")\n",
    "library(\"loo\")\n",
    "\n",
    "d <- milk[complete.cases(milk),]\n",
    "d$neocortex <- d$neocortex.perc /100\n",
    "str(d)\n",
    "\n",
    "fit1 <- stan_glm(kcal.per.g ~ 1, data = d, seed = 2030)\n",
    "fit2 <- update(fit1, formula = kcal.per.g ~ neocortex)\n",
    "fit3 <- update(fit1, formula = kcal.per.g ~ log(mass))\n",
    "fit4 <- update(fit1, formula = kcal.per.g ~ neocortex + log(mass))\n",
    "\n",
    "waic1 <- waic(fit1)\n",
    "waic2 <- waic(fit2)\n",
    "waic3 <- waic(fit3)\n",
    "waic4 <- waic(fit4)\n",
    "\n",
    "waics <- c(\n",
    "  waic1$estimates[\"elpd_waic\", 1],\n",
    "  waic2$estimates[\"elpd_waic\", 1],\n",
    "  waic3$estimates[\"elpd_waic\", 1],\n",
    "  waic4$estimates[\"elpd_waic\", 1]\n",
    ")\n",
    "\n",
    "loo1 <- loo(fit1)\n",
    "loo2 <- loo(fit2)\n",
    "loo3 <- loo(fit3)\n",
    "loo4 <- loo(fit4)\n",
    "lpd_point <- cbind(\n",
    "  loo1$pointwise[,\"elpd_loo\"], \n",
    "  loo2$pointwise[,\"elpd_loo\"],\n",
    "  loo3$pointwise[,\"elpd_loo\"], \n",
    "  loo4$pointwise[,\"elpd_loo\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "waic_wts <- exp(waics) / sum(exp(waics))\n",
    "pbma_wts <- pseudobma_weights(lpd_point, BB=FALSE)\n",
    "pbma_BB_wts <- pseudobma_weights(lpd_point) # default is BB=TRUE\n",
    "stacking_wts <- stacking_weights(lpd_point)\n",
    "round(cbind(waic_wts, pbma_wts, pbma_BB_wts, stacking_wts), 2)\n",
    "\n",
    "waic_wts_demo <- \n",
    "  exp(waics[c(1,1,1,1,1,1,1,1,1,1,2,3,4)]) /\n",
    "  sum(exp(waics[c(1,1,1,1,1,1,1,1,1,1,2,3,4)]))\n",
    "round(waic_wts_demo, 3)\n",
    "\n",
    "stacking_weights(lpd_point[,c(1,1,1,1,1,1,1,1,1,1,2,3,4)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using list of loo objects\n",
    "loo_list <- list(loo10, loo11, loo12)\n",
    "loo_model_weights(loo_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loo_model_weights(loo_list, method = \"pseudobma\", BB = FALSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit1 <-\n",
    "  stan_glm(\n",
    "    formula = y ~ roach1 + treatment + senior,\n",
    "    offset = log(exposure2),\n",
    "    data = roaches,\n",
    "    family = poisson(link = \"log\"),\n",
    "    prior = normal(0, 2.5, autoscale = TRUE),\n",
    "    prior_intercept = normal(0, 5, autoscale = TRUE),\n",
    "    seed = 12345\n",
    "  )\n",
    "loo1 <- loo(fit1, save_psis = TRUE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "loo gives us warnings about the Pareto diagnostics, which indicate that for some observations the leave-one-out posteriors are different enough from the full posterior that importance-sampling is not able to correct the difference. We can see more details by printing the loo object.\n",
    "The table shows us a summary of Pareto k diagnostic, which is used to assess the reliability of the estimates. In addition to the proportion of leave-one-out folds with k values in different intervals, the minimum of the effective sample sizes in that category is shown to give idea why higher k values are bad. Since we have some k>1, we are not able to compute an estimate for the Monte Carlo standard error (SE) of the expected log predictive density (elpd_loo) and NA is displayed. (Full details on the interpretation of the Pareto k diagnostics are available in the two Vehtari, Gelman, and Gabry papers referenced at the top of this vignette.)\n",
    "\n",
    "In this case the elpd_loo estimate should not be considered reliable. If we had a well-specified model we would expect the estimated effective number of parameters (p_loo) to be smaller than or similar to the total number of parameters in the model. Here p_loo is almost 300, which is about 70 times the total number of parameters in the model, indicating severe model misspecification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in plot(loo1): object 'loo1' not found\n",
     "output_type": "error",
     "traceback": [
      "Error in plot(loo1): object 'loo1' not found\nTraceback:\n",
      "1. plot(loo1)"
     ]
    }
   ],
   "source": [
    "plot(loo1)\n",
    "plot(loo2, label_points = TRUE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the label_points argument will label any k values larger than 0.7 with the index of the corresponding data point. These high values are often the result of model misspecification and frequently correspond to data points that would be considered ``outliers in the data and surprising according to the model Gabry et al (2019). Unfortunately, while large k values are a useful indicator of model misspecification, small k values are not a guarantee that a model is well-specified.\n",
    "\n",
    "If there are a small number of problematic k values then we can use a feature in rstanarm that lets us refit the model once for each of these problematic observations. Each time the model is refit, one of the observations with a high k value is omitted and the LOO calculations are performed exactly for that observation. The results are then recombined with the approximate LOO calculations already carried out for the observations without problematic k values:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visual MCMC diagnostics using the bayesplot package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(\"bayesplot\")\n",
    "library(\"ggplot2\")\n",
    "library(\"rstan\")      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schools_dat <- list(\n",
    "  J = 8, \n",
    "  y = c(28,  8, -3,  7, -1,  1, 18, 12),\n",
    "  sigma = c(15, 10, 16, 11,  9, 11, 10, 18)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "y_j &\\sim {\\rm Normal}(\\theta_j, \\sigma_j), \\quad j = 1,\\dots,J \\\\\n",
    "\\theta_j &\\sim {\\rm Normal}(\\mu, \\tau), \\quad j = 1, \\dots, J \\\\\n",
    "\\mu &\\sim {\\rm Normal}(0, 10) \\\\\n",
    "\\tau &\\sim {\\rm half-Cauchy}(0, 10),\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcmc_pairs(posterior_cp, np = np_cp, pars = c(\"mu\",\"tau\",\"theta[1]\"), \n",
    "           off_diag_args = list(size = 0.75))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign to an object so we can reuse later\n",
    "scatter_theta_cp <- mcmc_scatter(\n",
    "  posterior_cp, \n",
    "  pars = c(\"theta[1]\", \"tau\"), \n",
    "  transform = list(tau = \"log\"), # can abbrev. 'transformations'\n",
    "  np = np_cp, \n",
    "  size = 1\n",
    ")\n",
    "scatter_theta_cp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter_eta_ncp <- mcmc_scatter(\n",
    "  posterior_ncp, \n",
    "  pars = c(\"eta[1]\", \"tau\"), \n",
    "  transform = list(tau = \"log\"), \n",
    "  np = np_ncp, \n",
    "  size = 1\n",
    ")\n",
    "scatter_eta_ncp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_scheme_set(\"mix-brightblue-gray\")\n",
    "mcmc_trace(posterior_cp, pars = \"tau\", np = np_cp) + \n",
    "  xlab(\"Post-warmup iteration\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcmc_trace(posterior_cp, pars = \"tau\", np = np_cp, \n",
    "           window = c(50,200)) + \n",
    "  xlab(\"Post-warmup iteration\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_scheme_set(\"red\")\n",
    "mcmc_nuts_divergence(np_cp, lp_cp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_cp_bad_rhat <- sampling(schools_mod_cp, data = schools_dat, \n",
    "                            iter = 50, init_r = 10, seed = 671254821)\n",
    "rhats <- rhat(fit_cp_bad_rhat)\n",
    "print(rhats)\n",
    "color_scheme_set(\"brightblue\") # see help(\"color_scheme_set\")\n",
    "mcmc_rhat(rhats)\n",
    "mcmc_rhat(rhats) + yaxis_text(hjust = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratios_cp <- neff_ratio(fit_cp)\n",
    "print(ratios_cp)\n",
    "mcmc_neff(ratios_cp, size = 2)\n",
    "\n",
    "neff_cp <- neff_ratio(fit_cp, pars = c(\"theta\", \"mu\", \"tau\"))\n",
    "neff_ncp <- neff_ratio(fit_ncp, pars = c(\"theta\", \"mu\", \"tau\"))\n",
    "compare_cp_ncp(mcmc_neff(neff_cp), mcmc_neff(neff_ncp), ncol = 1)\n",
    "\n",
    "compare_cp_ncp(\n",
    "  mcmc_acf(posterior_cp, pars = \"theta[1]\", lags = 10),\n",
    "  mcmc_acf(posterior_ncp, pars = \"eta[1]\", lags = 10)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Custom Response Distributions with brms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data(\"cbpp\", package = \"lme4\")\n",
    "head(cbpp)\n",
    "fit1 <- brm(incidence | trials(size) ~ period + (1|herd), \n",
    "            data = cbpp, family = binomial())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A drawback of the binomial model is that  after taking into account the linear predictor  its variance is fixed to Var(yi)=Tipi(1pi). All variance exceeding this value cannot be not taken into account by the model. There are multiple ways of dealing with this so called overdispersion and the solution described below will serve as an illustrative example of how to define custom families in brms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Beta-Binomial Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The beta-binomial model is a generalization of the binomial model with an additional parameter to account for overdispersion. In the beta-binomial model, we do not predict the binomial probability pi directly, but assume it to be beta distributed with hyperparameters >0 and >0:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fit1 <- brm(incidence | trials(size) ~ period + (1|herd), \n",
    "            data = cbpp, family = binomial())\n",
    "summary(fit1)\n",
    "\n",
    "beta_binomial2 <- custom_family(\n",
    "  \"beta_binomial2\", dpars = c(\"mu\", \"phi\"),\n",
    "  links = c(\"logit\", \"log\"), lb = c(NA, 0),\n",
    "  type = \"int\", vars = \"vint1[n]\"\n",
    ")\n",
    "\n",
    "stan_funs <- \"\n",
    "  real beta_binomial2_lpmf(int y, real mu, real phi, int T) {\n",
    "    return beta_binomial_lpmf(y | T, mu * phi, (1 - mu) * phi);\n",
    "  }\n",
    "  int beta_binomial2_rng(real mu, real phi, int T) {\n",
    "    return beta_binomial_rng(T, mu * phi, (1 - mu) * phi);\n",
    "  }\n",
    "\"\n",
    "\n",
    "stanvars <- stanvar(scode = stan_funs, block = \"functions\")\n",
    "\n",
    "fit2 <- brm(\n",
    "  incidence | vint(size) ~ period + (1|herd), data = cbpp, \n",
    "  family = beta_binomial2, stanvars = stanvars\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Simple Monotonic Model\n",
    "A main application of monotonic effects are ordinal predictors that can be modeled this way without falsely treating them either as continuous or as unordered categorical predictors. In Psychology, for instance, this kind of data is omnipresent in the form of Likert scale items, which are often treated as being continuous for convenience without ever testing this assumption. As an example, suppose we are interested in the relationship of yearly income (in $) and life satisfaction measured on an arbitrary scale from 0 to 100. Usually, people are not asked for the exact income. Instead, they are asked to rank themselves in one of certain classes, say: below 20k, between 20k and 40k, between 40k and 100k and above 100k. We use some simulated data for illustration purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "income_options <- c(\"below_20\", \"20_to_40\", \"40_to_100\", \"greater_100\")\n",
    "income <- factor(sample(income_options, 100, TRUE), \n",
    "                 levels = income_options, ordered = TRUE)\n",
    "mean_ls <- c(30, 60, 70, 75)\n",
    "ls <- mean_ls[income] + rnorm(100, sd = 7)\n",
    "dat <- data.frame(income, ls)\n",
    "\n",
    "# We now proceed with analyzing the data modeling income as a monotonic\n",
    "# effect.\n",
    "fit1 <- brm(ls ~ mo(income), data = dat)\n",
    "summary(fit1)\n",
    "plot(fit1, pars = \"simo\")\n",
    "plot(conditional_effects(fit1))\n",
    "\n",
    "dat$income_num <- as.numeric(dat$income)\n",
    "fit2 <- brm(ls ~ income_num, data = dat)\n",
    "summary(fit2)\n",
    "\n",
    "contrasts(dat$income) <- contr.treatment(4)\n",
    "fit3 <- brm(ls ~ income, data = dat)\n",
    "\n",
    "loo(fit1, fit2, fit3)\n",
    "\n",
    "\n",
    "prior4 <- prior(dirichlet(c(2, 1, 1)), class = \"simo\", coef = \"moincome1\")\n",
    "fit4 <- brm(ls ~ mo(income), data = dat,\n",
    "            prior = prior4, sample_prior = TRUE)\n",
    "\n",
    "fit5 <- brm(ls ~ mo(income)*age, data = dat)\n",
    "\n",
    "conditional_effects(fit5, \"income:age\")\n",
    "\n",
    "dat$city <- rep(1:10, each = 10)\n",
    "var_city <- rnorm(10, sd = 10)\n",
    "dat$ls <- dat$ls + var_city[dat$city]\n",
    "# With the following code, we fit a multilevel model assuming the intercept and the effect of income to vary by city:\n",
    "\n",
    "fit6 <- brm(ls ~ mo(income)*age + (mo(income) | city), data = dat)\n",
    "summary(fit6)\n",
    "\n",
    "\n",
    "data(\"BTdata\", package = \"MCMCglmm\")\n",
    "head(BTdata)\n",
    "fit1 <- brm(\n",
    "  mvbind(tarsus, back) ~ sex + hatchdate + (1|p|fosternest) + (1|q|dam),\n",
    "  data = BTdata, chains = 2, cores = 2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen in the model code, we have used mvbind notation to tell brms that both tarsus and back are separate response variables. The term (1|p|fosternest) indicates a varying intercept over fosternest. By writing |p| in between we indicate that all varying effects of fosternest should be modeled as correlated. This makes sense since we actually have two model parts, one for tarsus and one for back. The indicator p is arbitrary and can be replaced by other symbols that comes into your mind (for details about the multilevel syntax of brms, see help(\"brmsformula\") and vignette(\"brms_multilevel\")). Similarily, the term (1|q|dam) indicates correlated varying effects of the genetic mother of the chicks. Alternatively, we could have also modeled the genetic similarities through pedigrees and corresponding relatedness matrices, but this is not the focus of this vignette (please see vignette(\"brms_phylogenetics\")). The model results are readily summarized via"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit1 <- add_criterion(fit1, \"loo\")\n",
    "summary(fit1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
