{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are running Python 3. Good job :)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "if sys.version.startswith(\"3.\"):\n",
    "  print(\"You are running Python 3. Good job :)\")\n",
    "else:\n",
    "  print(\"This notebook requires Python 3.\\nIf you are using Google Colab, go to Runtime > Change runtime type and choose Python 3.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Descent: execution time=0.000 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = datetime.datetime.now()\n",
    "end_time = datetime.datetime.now()\n",
    "# Print result\n",
    "exection_time = (end_time - start_time).total_seconds()\n",
    "print(\"Gradient Descent: execution time={t:.3f} seconds\".format(t=exection_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_txt(path):\n",
    "    \"\"\"read text file from path.\"\"\"\n",
    "    with open(path, \"r\") as f:\n",
    "        return f.read().splitlines()\n",
    "\n",
    "\n",
    "def load_data(path_dataset, n=500):\n",
    "    \"\"\"Load data in text format, one rating per line, as in the kaggle competition.\"\"\"\n",
    "    data = read_txt(path_dataset)[1:]\n",
    "    return preprocess_data(data,n)\n",
    "\n",
    "def slice(ratings,n=None):\n",
    "    \"\"\"take the first n rows and n columns only\"\"\"\n",
    "    if n is not None:\n",
    "        ratings = ratings[:n,:n]\n",
    "    return ratings\n",
    "\n",
    "def preprocess_data(data, n = 500):\n",
    "    \"\"\"preprocessing the text data, conversion to numerical array format.\"\"\"\n",
    "    def deal_line(line):\n",
    "        pos, rating = line.split(',')\n",
    "        row, col = pos.split(\"_\")\n",
    "        row = row.replace(\"r\", \"\")\n",
    "        col = col.replace(\"c\", \"\")\n",
    "        return int(row), int(col), float(rating)\n",
    "\n",
    "    def statistics(data):\n",
    "        row = set([line[0] for line in data])\n",
    "        col = set([line[1] for line in data])\n",
    "        return min(row), max(row), min(col), max(col)\n",
    "\n",
    "    # parse each line\n",
    "    data = [deal_line(line) for line in data]\n",
    "\n",
    "    # do statistics on the dataset.\n",
    "    min_row, max_row, min_col, max_col = statistics(data)\n",
    "    # print(\"number of items: {}, number of users: {}\".format(max_row, max_col))\n",
    "    # build rating matrix.\n",
    "    ratings = np.zeros([max_row,max_col])\n",
    "    for row, col, rating in data:\n",
    "        ratings[row - 1, col - 1] = rating\n",
    "    # Reduce the size of the dataset\n",
    "    ratings = slice(ratings, n)\n",
    "    # Make the trace 1 by scaling all entries of matrix\n",
    "    ratings = ratings/np.trace(ratings)\n",
    "    print(\"number of items: {}, number of users: {}\".format(n, n))\n",
    "    return ratings\n",
    "\n",
    "def group_by(data, index):\n",
    "    \"\"\"group list of list by a specific index.\"\"\"\n",
    "    sorted_data = sorted(data, key=lambda x: x[index])\n",
    "    groupby_data = groupby(sorted_data, lambda x: x[index])\n",
    "    return groupby_data\n",
    "\n",
    "\n",
    "def build_index_groups(train):\n",
    "    \"\"\"build groups for nnz rows and cols.\"\"\"\n",
    "    nz_row, nz_col = train.nonzero()\n",
    "    nz_train = list(zip(nz_row, nz_col))\n",
    "\n",
    "    grouped_nz_train_byrow = group_by(nz_train, index=0)\n",
    "    nz_row_colindices = [(g, np.array([v[1] for v in value]))\n",
    "                         for g, value in grouped_nz_train_byrow]\n",
    "\n",
    "    grouped_nz_train_bycol = group_by(nz_train, index=1)\n",
    "    nz_col_rowindices = [(g, np.array([v[0] for v in value]))\n",
    "                         for g, value in grouped_nz_train_bycol]\n",
    "    return nz_train, nz_row_colindices, nz_col_rowindices\n",
    "\n",
    "\n",
    "def calculate_mse(real_label, prediction):\n",
    "    \"\"\"calculate MSE.\"\"\"\n",
    "    t = real_label - prediction\n",
    "    return 1.0 * t.dot(t.T)\n",
    "\n",
    "        \n",
    "def split_data(ratings, num_items_per_user, num_users_per_item,\n",
    "               min_num_ratings, p_test=0.2):\n",
    "    \"\"\"split the ratings to training data and test data.\n",
    "    Args:\n",
    "        min_num_ratings: \n",
    "            all users and items we keep must have at least min_num_ratings per user and per item. \n",
    "    \"\"\"\n",
    "    # set seed\n",
    "    np.random.seed(988)\n",
    "    \n",
    "    # select user and item based on the condition.\n",
    "    valid_users = np.where(num_items_per_user >= min_num_ratings)[0]\n",
    "    valid_items = np.where(num_users_per_item >= min_num_ratings)[0]\n",
    "    valid_ratings = ratings[valid_items, :][: , valid_users]  \n",
    "    \n",
    "    # init\n",
    "    num_rows, num_cols = valid_ratings.shape\n",
    "    train = np.zeros([num_rows, num_cols])\n",
    "    test = np.zeros([num_rows, num_cols])\n",
    "    \n",
    "    print(\"the shape of original ratings. (# of row, # of col): {}\".format(\n",
    "        ratings.shape))\n",
    "    print(\"the shape of valid ratings. (# of row, # of col): {}\".format(\n",
    "        (num_rows, num_cols)))\n",
    "\n",
    "    nz_items, nz_users = valid_ratings.nonzero()\n",
    "    \n",
    "    # split the data\n",
    "    for user in set(nz_users):\n",
    "        # randomly select a subset of ratings\n",
    "        row = valid_ratings[:, user].nonzero()[0]\n",
    "        selects = np.random.choice(row, size=int(len(row) * p_test))\n",
    "        residual = list(set(row) - set(selects))\n",
    "\n",
    "        # add to train set\n",
    "        train[residual, user] = valid_ratings[residual, user]\n",
    "\n",
    "        # add to test set\n",
    "        test[selects, user] = valid_ratings[selects, user]\n",
    "\n",
    "    print(\"Total number of nonzero elements in origial data:{v}\".format(v=np.count_nonzero(ratings)))\n",
    "    print(\"Total number of nonzero elements in train data:{v}\".format(v=np.count_nonzero(train)))\n",
    "    print(\"Total number of nonzero elements in test data:{v}\".format(v=np.count_nonzero(test)))\n",
    "    return valid_ratings, train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(sub_sample=True, add_outlier=False):\n",
    "    \"\"\"Load data and convert it to the metric system.\"\"\"\n",
    "    path_dataset = \"height_weight_genders.csv\"\n",
    "    data = np.genfromtxt(\n",
    "        path_dataset, delimiter=\",\", skip_header=1, usecols=[1, 2])\n",
    "    height = data[:, 0]\n",
    "    weight = data[:, 1]\n",
    "    gender = np.genfromtxt(\n",
    "        path_dataset, delimiter=\",\", skip_header=1, usecols=[0],\n",
    "        converters={0: lambda x: 0 if b\"Male\" in x else 1})\n",
    "    # Convert to metric system\n",
    "    height *= 0.025\n",
    "    weight *= 0.454\n",
    "\n",
    "    # sub-sample\n",
    "    if sub_sample:\n",
    "        height = height[::50]\n",
    "        weight = weight[::50]\n",
    "\n",
    "    if add_outlier:\n",
    "        # outlier experiment\n",
    "        height = np.concatenate([height, [1.1, 1.2]])\n",
    "        weight = np.concatenate([weight, [51.5/0.454, 55.3/0.454]])\n",
    "\n",
    "    return height, weight, gender\n",
    "\n",
    "\n",
    "def standardize(x):\n",
    "    \"\"\"Standardize the original data set.\"\"\"\n",
    "    mean_x = np.mean(x,axis = 0)\n",
    "    x = x - mean_x\n",
    "    std_x = np.std(x, axis = 0)\n",
    "    x = x / std_x\n",
    "    return x, mean_x, std_x\n",
    "\n",
    "\n",
    "def build_model_data(height, weight):\n",
    "    \"\"\"Form (y,tX) to get regression data in matrix form.\"\"\"\n",
    "    y = weight\n",
    "    x = height\n",
    "    num_samples = len(y)\n",
    "    tx = np.c_[np.ones(num_samples), x]\n",
    "    return y, tx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
